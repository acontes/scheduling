<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/css" href="../viewDocbook.css"?>
<chapter id="hands_on_programming">
  <title>Step by step tutorial</title>
<para>In this chapter we present a step by step introduction to
  programming with ProActive.</para>

  <para>The program that we will develop is a classic 'HelloWorld' example.As we
  progress through the example we 
  will increase the complexity of the example, so you get more familiar with
  different features of ProActive.</para>

  <itemizedlist>
    <listitem>
      <para>First, we will code a 'client-server' application, the server
      being an active object.</para>
    </listitem>

    <listitem>
      <para>Second, we will see how we can control the activity of an active
      object.</para>
    </listitem>

    <listitem>
      <para>Third, we will add mobility to this active object and have it migrate
      to another computer and say hello.</para>
    </listitem>

    <listitem>
      <para>In the last example we show how to compute the first N primes using several
      computers and the master-worker architecture.</para>
    </listitem>
  </itemizedlist>
		<para>
			We will also show the IC2D  view of the examples in this chapter. 
		</para>
	
	<para>
		Throughout the tutorial the classes from which we will instantiate active objects
		are represented in red in the UML diagrams.
	</para>

	<sect1 id="HelloWorld">
		<title> First Active Object Class</title>
	<para>
		Welcome to your first ProActive program! This is the simplest application that can be
		written. It is composed of two classes with a client-server structure. 
	</para>
	<figure> <title> Client-Server architecture</title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/hello/clientserver.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>
	<para>	
		The example illustrates the creation of an active object from the 
		<literal>HelloWorld</literal> class that will be
		used by the <literal>Main</literal> class to retrieve a string
		 and print it to the standard output.		
		The <literal>Main</literal> class corresponds to the client, and is
		 only a container for the <literal>main()</literal> method, while 
		the <literal>HelloWorld</literal> class corresponds to the server and its instance is an active object which provides a sayHello
		method as a remote service.
	</para>		
	<para>
		To safely use the <literal>HelloWorld</literal> class as an active object
		we have to meet three requirements.
	</para>
		<itemizedlist>
			<listitem><para><emphasis role="bold">no direct access to field variables</emphasis> - If
							<literal>public</literal> variables are used then the stub class generated from
							the original class may become decoupled from the original class. If a change is
							affected on the public field variable in the stub instance, the change will not be 
							 propagated to the the class instance from which the stub was generated. The safe
							 way to change variables is to set them as <literal>private</literal> and access
							 them through <literal>public get/set</literal> methods.   </para></listitem>
			
			<listitem><para><emphasis role="bold">provide a no-argument and preferably an empty constructor</emphasis> - A 
							no-argument constructor is necessary to create the stub class needed for communication.
							A stub cannot be created if there are only constructors with arguments since the 
							stub is only meant to abstract the communication from the active objects. 
							
							If there is no constructor defined, the Java compiler
							will automatically create a no-argument constructor that initializes all instance variables
							to the default value. However, if there is an already defined constructor with arguments 
							then no default no-argument constructor will be created by the compiler. In this case 							the definition of a no-argument constructor is mandatory for stub creation. The safest way is
							to always define a no-argument constructor.
							Also, the constructor should be empty so that on stub creation no 
							initialization is done on the stub.    
							 
						
						</para>	</listitem>
			<listitem><para><emphasis role="bold">provide remote functionalities as public methods with reifiable type</emphasis> - Since
			the stub is created through inheritance, the only methods it can use for communication are
			the inherited public methods from the superclass. The return types of the methods have to be 
			 reifiable  and therefore not final. ProActive provides several wrappers for Java types
			 that are final.The example uses the <literal>StringWrapper</literal> class in order to provide a wrapper for the 
			final <literal>String</literal> class.  Since ProActive uses a proxy mechanism and
			 the <literal>String</literal> class is final, it’s not
			possible to subclass a String and to perform asynchronous calls.	
			ProActive provides several wrappers for final classes: <literal>StringWrapper, BooleanWrapper, 
			IntegerWrapper, DoubleWrapper</literal> and <literal>FloatWrapper</literal>.
			 These have to be used in
			replacement of <literal>String, Boolean, Integer, Double</literal> and <literal>Float</literal>
			in classes which will be active objects. Since ProActive uses a proxy
			mechanism and theses classes are final, it’s not
			possible to subclass them and to perform asynchronous calls. The
			subclasses is necessary in order to create the stub class uses in 
			communication. 
			If you don’t use wrappers, method calls will be synchronous.
			</para>	
			<programlisting lang="java"><textobject><textdata fileref="code_snippets/helloworld_example/public_method.txt"></textdata></textobject></programlisting>
			
			</listitem>
		</itemizedlist>	
		
	<para>
		The following class meets all of the requirements above.
	</para>	
	 <programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/SimpleHelloWorld/src/active/HelloWorld.java" /></textobject></programlisting>
	
<para>We will now show how to create the server object. For now, we want the
<literal> HelloWorld</literal> active object 
 to be created on the current Node (we will see later how to distribute the program). To create an instance of
  a remotely accessible object we must use the <literal>ProActive.newActive</literal> primitive.
  <programlisting lang="java"><textobject><textdata fileref="code_snippets/helloworld_example/ao_creation.txt"></textdata></textobject></programlisting>
</para>
	<para>
		Invoking a method on a remote active object is transparent and is similar 
		for the user to  invoking a method on
		a local object of the same type. The user does not have to deal with catching exceptions
		related to the remote communication. The only modification brought to the code by ProActive
		is during the active objects creation. All the rest of the code can remain unmodified, 
		fostering software reuse.
		To invoke the sayHello method we execute:	
	<programlisting lang="java"><textobject><textdata fileref="code_snippets/helloworld_example/ao_invocation.txt" /></textobject></programlisting>

	</para>
	<para> The full code of the <literal>Main</literal> class is the following. </para>
	<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/SimpleHelloWorld/src/active/Main.java" /></textobject></programlisting>
	<sect2>
		<title>Running the HelloWorld application</title>
		<para>
		For now the application will be deployed on the local Node. To compile and run the application you need the 
		<literal> Main </literal>class, the <literal> HelloWorld </literal>class,  to
		include the following jar files: 
		  	<literal>ProActive/dist/lib/ProActive.jar</literal>,
          	<literal>ProActive/lib/javassist.jar</literal>,
          		<literal>ProActive/lib/log4j.jar</literal>, 
          		<literal>ProActive/lib/xercesImpl.jar</literal>, 
          		<literal>ProActive/lib/fractal.jar</literal>,  
          		and <literal>ProActive/lib/bouncycastle.jar</literal>
           and explicitly set the Java security policy with the  <literal>-Djava.security.policy=pathToFile</literal>
           and the logging policy with  <literal>-Dlog4j.configuration=file:proactive-log4j</literal>.
            The steps necessary are explained in <xref linkend="Installation"/>.
           
		</para>	
		<para>
			The command line for running the application is: 
			<screen>
java -Djava.security.policy=proactive.java.policy -Dlog4j.configuration=file:proactive-log4j Main 
			</screen>
		</para>
	</sect2>
	<sect2>
		<title>Monitoring The HelloWorld Application</title>
		<para>
			To see the the active object running start  IC2D and start 
			monitoring the local machine. To prevent the active object from stopping its
			thread remove from the 
			code above the line <literal>ProActive.exitSuccess();</literal>. IC2D will
			show the hostname, the node names, and the active objects running. 
		</para>
		<para>
			
			<figure>
      		<title> IC2D view of the SimpleHello example</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/screenshots/ic2d_simplehello.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
	</sect2>
	</sect1>

  <sect1>
    <title>Initialization of the active object activity</title>

    <para>Active objects, as their name indicates, have an activity of their
    own (an internal thread).By default the active object steps through
    the constructor, the <literal>initActivity</literal>, the <literal>runActivity</literal>,
     and when the <literal>terminate</literal> method is called on
    the <literal>Body</literal> of the active object through the <literal>endActivity</literal> method.
    It is possible to control the initialization, running, and ending phase of this
    thread by implementing three interfaces:<literal>InitActive</literal>,<literal>
    RunActive</literal>, and <literal>EndActive</literal>.These interfaces define the
    <literal>initActivity</literal>, <literal>runActivity</literal> and <literal>endActivity</literal>
    methods. One of the reasons for using <literal>initActivity</literal>
    method is the presence of the empty constructor in an active object. The <literal>initActivity</literal>
    method is automatically called on the creation of an active object in order to set up the 
    object without using the constructor. The <literal>runActivity</literal> method allows the user
    to control the active object request queue. By implementing the <literal>EndActive</literal> interface is also possible to 
    do clean up before the active object thread is stopped. </para>


    <para>The following example will help you to understand how and when you
    can initialize and clean the activity. The example will implement the <literal>InitActive</literal> and
    <literal>EndActive</literal> interfaces. To understand how to use the more complex
    <literal>RunActive</literal> interface read <xref linkend="ActiveObjectCreation"/> </para>


    <sect2>
      <title>Design of the application with Init activity</title>

      <para>The InitializedHelloWorld class extends the Hello class in the previous example, and implements
      the interfaces InitActive and EndActive.It acts as a server for the
      Main class.</para>

      <para><figure>
      		<title> Client-Server architecture with initialization</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/hello/initializedhello.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure></para>
    
    
    <para>
    	To implement the application we will create a class that inherits from the 
    	<literal>HelloWorld</literal> class and implements the EndActive and InitActive
    	interfaces. 
    	<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/InitializedSimpleHello/src/active/InitializedHelloWorld.java"></textdata></textobject></programlisting>
    </para>
    <para>
    	By default an active object has a never ending thread that should be stopped when the object is 
    	not needed anymore. The method <literal>terminate</literal> serves the purpose of destroying the 
    	object. However, if an explicit call to terminate the object is not made, ProActive has its own
    	distributed garbage collection system that is able to decide when an active object can be destroyed. 
    </para>
    <para>
    	In the <literal>Main</literal> class we will change the object created from <literal>HelloWorld</literal> to 
    	<literal>InitializedHelloWorld</literal> and also we will call the <literal>terminate </literal> method to 
    	destroy the object.
    	<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/InitializedSimpleHello/src/active/Main.java"></textdata></textobject></programlisting>
    	 
    </para>
    </sect2>

        
    
    <sect2>
      <title>Running the InitializedHelloWorld application</title>

      <para>To compile and run the application you need the
      	 HelloWorld class from the previous example, the new Main class, and the InitializedHelloWorld class.
      	To compile and run the application you need the 
		<literal> Main </literal>class, the <literal> HelloWorld </literal>class,  to
		include the following jar files: 
		  	<literal>ProActive/dist/lib/ProActive.jar</literal>,
          	<literal>ProActive/lib/javassist.jar</literal>,
          		<literal>ProActive/lib/log4j.jar</literal>, 
          		<literal>ProActive/lib/xercesImpl.jar</literal>, 
          		<literal>ProActive/lib/fractal.jar</literal>,  
          		and <literal>ProActive/lib/bouncycastle.jar</literal>
           and explicitly set the Java security policy with the  <literal>-Djava.security.policy=pathToFile</literal>
           and the logging policy with  <literal>-Dlog4j.configuration=file:proactive-log4j</literal>.
            The steps necessary are explained in <xref linkend="Installation"/>.
            </para>
 		<para>	The command line for running the application is: </para> 
	<para>
			<screen>
java -Djava.security.policy=proactive.java.policy -Dlog4j.configuration=file:proactive-log4j Main 
			</screen>
 	</para>
    </sect2>
  
  	<sect2>
		<title>Monitoring The InitializedHello Application</title>
		<para>
			To see the the active object running start  IC2D and start 
			monitoring the local machine. To prevent the active object from stopping its
			thread remove from the 
			code above the line <literal>ProActive.exitSuccess();</literal> and
			<literal>ao.terminate();</literal>. IC2D will
			show the hostname, the node names, and the active objects running - in
			this case InitializedHello. 
		</para>
		<para>
			<figure>
      		<title> IC2D view of the InitializedHello example</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/screenshots/ic2d_initialized_hello.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
	</sect2>
  
  
  </sect1>
  <sect1 id="deployment_guide">
  	<title>Application Deployment</title>
  	<para>
  		In the previous example the applications were deployed inside
  		the same JVM. This section will focus on showing how to deploy
  		the application on different nodes using deployment
  		descriptors.
  	</para>
  	<sect2>
  		<title>Deployment Related Concepts</title>
  		<para>
  			A first principle is to fully eliminate from the source
  			code the following elements:
  			<itemizedlist>
  				<listitem>
  					<para>machine names</para>
  				</listitem>
  				<listitem>
  					<para>creation protocols</para>
  				</listitem>
  				<listitem>
  					<para>registry lookup protocols</para>
  				</listitem>
  			</itemizedlist>
  		</para>
  		<para>
  			The goal is to deploy any application anywhere without
  			changing the source code. For instance, we must be able to
  			use various protocols, rsh, ssh, Globus, LSF, etc., for
  			the creation of the JVMs needed by the application. In the
  			same manner, the discovery of existing resources or the
  			registration of the ones created by the application can be
  			done with various protocols such as RMIregistry, Globus
  			etc. Therefore, we see that the creation, registration and
  			discovery of resources have to be done externally to the
  			application.
  		</para>
  		<para>
  			A second key principle is the capability to abstractly
  			describe an application, or part of it, in terms of its
  			conceptual activities. The description should indicate the
  			various parallel or distributed entities in the program.
  			For instance, an application that is designed to use three
  			interactive visualization nodes, a node to capture input
  			from a physics experiment, and a simulation engine
  			designed to run on a cluster of machines should somewhere
  			clearly advertise this information.
  		</para>
  		<para>
  			Now, one should note that the abstract description of an
  			application and the way to deploy it are not independent
  			piece of information. In the example just above, if there
  			is a simulation engine, it might register in a specific
  			registry protocol, and if so, the other entities of the
  			computation might have to use that lookup protocol to bind
  			to the engine. Moreover, one part of the program can just
  			lookup for the engine (assuming it is started
  			independently), or explicitly create the engine itself. To
  			summarize, in order to abstract away the underlying
  			execution platform, and to allow a source-independent
  			deployment, a framework has to provide the following
  			elements:
  			<itemizedlist>
  				<listitem>
  					<para>
  						an abstract description of the distributed
  						entities of a parallel program or component,
  					</para>
  				</listitem>
  				<listitem>
  					<para>
  						an external mapping of those entities to real
  						machines, using actual creation, registry, and
  						lookup protocols.
  					</para>
  				</listitem>
  			</itemizedlist>
  		</para>
  		<para>
  			To reach that goal, the programming model relies on the
  			specific notion of Virtual Nodes (VNs):
  			<itemizedlist>
  				<listitem>
  					<para>
  						a VN is identified as a name (a simple string)
  					</para>
  				</listitem>
  				<listitem>
  					<para>a VN is used in a program source</para>
  				</listitem>
  				<listitem>
  					<para>
  						a VN is defined and configured in a deployment
  						descriptor (XML)
  					</para>
  				</listitem>
  				<listitem>
  					<para>
  						a VN, after activation, is mapped to one or to
  						a set of actual ProActive Nodes
  					</para>
  				</listitem>
  			</itemizedlist>
  		</para>
  		<para>
  			Of course, distributed entities (Active Objects), are
  			created on Nodes, not on Virtual Nodes. There is a strong
  			need for both Nodes and Virtual Nodes. Virtual Nodes are a
  			much richer abstraction, as they provide mechanisms such
  			as set or cyclic mapping. Another key aspect is the
  			capability to describe and trigger the mapping of a single
  			VN that generates the allocation of several JVMs. This is
  			critical if we want to get at once machines from a cluster
  			of PCs managed through Globus or LSF. It is even more
  			critical in a Grid application, when trying to achieve the
  			co-allocation of machines from several clusters across
  			several continents.
  		</para>
  		<para>
  			Moreover, a Virtual Node is a concept of a distributed
  			program or component, while a Node is actually a
  			deployment concept: it is an object that lives in a JVM,
  			hosting Active Objects. There is of course a
  			correspondence between Virtual Nodes and Nodes: the
  			function created by the deployment, the mapping. This
  			mapping can be specified in an XML descriptor. By
  			definition, the following operations can be configured in
  			such a deployment descriptor:
  			<itemizedlist>
  				<listitem>
  					<para>
  						the mapping of VNs to Nodes and to JVMs
  					</para>
  				</listitem>
  				<listitem>
  					<para>the way to create or to acquire JVMs</para>
  				</listitem>
  				<listitem>
  					<para>the way to register or to lookup VNs</para>
  				</listitem>
  			</itemizedlist>

  		</para>
  	</sect2>

  	<sect2>
  		<title>Deployment Descriptor File</title>
  		<para>
  			The deployment descriptor is an XML file containing
  			information on the properties listed above. We will use a
  			simple XML file to deploy the Hello World application on a
  			remote The deployment XML file is composed of several
  			parts, each with different options. For our example we
  			will use a simple version. To find out more about
  			deployment and deployment descriptors reader
  			<xref linkend="XML_Descriptors" />
  			.
  		</para>
  		<para>
  			The document uses the
  			<ulink
  				url="http://www-sop.inria.fr/oasis/ProActive/schemas/deployment/3.3/deployment.xsd">
  				XML Schema
  			</ulink>
  			present at the site.
  		</para>
  		<para>
  			To avoid mistakes when building XML descriptors, ProActive
  			provides an XML Schema called DescriptorSchema.xsd. To
  			validate your file against this schema, the following line
  			must be put at the top of the XML document.
  		</para>

  		<programlisting lang="xml"><textobject><textdata
  					fileref="code_snippets/deployment_descriptor/schema_location.txt"></textdata></textobject></programlisting>
  		<para>
  			The XML file has a section for defining variables needed
  			later in the document. For our case, we define the
  			location of the ProActive and Java installations on the
  			local and remote machine. To start the JVM and use
  			ProActive on the remote machine, we need to define the
  			location of the Java and ProActive files. This can be done
  			by specifying the paths in the infrastructure section of
  			the deployment descriptor or by setting the CLASSPATH and
  			JAVA_HOME variables as described in
  			<xref linkend="Installation" />
  			.
  			<programlisting lang="xml"><textobject><textdata
  						fileref="code_snippets/deployment_descriptor/variable_definition.txt"></textdata></textobject></programlisting>
  		</para>
  		<para>
  			Next, we define the virtual nodes that will be used. In
  			our case we define a node that can contain several JVMs by
  			setting the multiple property.
  			<programlisting lang="xml"><textobject><textdata
  						fileref="code_snippets/deployment_descriptor/component_definition.txt"></textdata></textobject></programlisting>
  		</para>
  		<para>
  			The deployment part of the XML file specifies how the JVMs
  			are started and mapped on the Virtual Nodes It has two
  			parts one dealing with the mapping of the JVMs to the
  			Virtual Nodes and another related to how the JVMs are
  			created. In our case we map one JVM to the remote node and
  			define a process reference that will be used later in the
  			file (infrastructure section) to describe how the JVM is
  			started.
  			<programlisting lang="xml"><textobject><textdata
  						fileref="code_snippets/deployment_descriptor/jvms.txt"></textdata></textobject></programlisting>
  		</para>
  		<para>
  			Next is the infrastructure part that defines the paths to
  			the files needed, the hosts on which the JVMs are deployed
  			and which protocols are used for communication.

  			The process definition with the id
  			<literal>genericRemoteJVM</literal>
  			is necessary to tell the JVM machine how to start a node
  			on the machine that has a reference to it (
  			<literal>processReference</literal>
  			). It will use the paths provided to locate the Java and
  			ProActive files on the remote machine. Here we are using
  			rsh to start the JVM but several other protocols can be
  			used as described in
  			<xref linkend="XML_Descriptors" />
  			.
  			<programlisting lang="xml"><textobject><textdata
  						fileref="code_snippets/deployment_descriptor/infrastructure.txt"></textdata></textobject></programlisting>
  		</para>
  		<para>
  			To deploy on a remote machine you will need to change the
  			<literal>hostname</literal>
  			tag to fit your machine name. In our case the remote
  			machine needs to have the
  			<literal>rsh</literal>
  			service running.

  			The full deployment descriptor file:
  			<programlisting lang="xml"><textobject><textdata
  						fileref="guided_tour/examples/DeployedHelloWorld/src/active/deployment.xml"></textdata></textobject></programlisting>
  		</para>
  	</sect2>
  	<sect2>
  		<title>Application changes</title>

  		<para>
  			To be able to deploy on remote machines we just have to
  			use the deployment file and add a method that tells
  			ProActive to active the nodes used.
  			<figure>
  				<title>Deployed HelloWorld architecture</title>
  				<mediaobject>
  					<imageobject>
  						<imagedata contentwidth="100"
  							fileref="guided_tour/pics/hello/DeployedHelloWorld.png"
  							format="PNG" width="6in" />
  					</imageobject>
  				</mediaobject>
  			</figure>
  		</para>
  		<para>
  			We will change the
  			<literal>Main</literal>
  			class to declare and load the deployment descriptors to be
  			used. For this we will use a
  			<literal>static deploy</literal>
  			method that returns the Node on which we deploy the active
  			object. First, the method creates an object representation
  			of the deployment file, then activates all the nodes, and
  			then returns the first available node.
  		</para>
  		<programlisting lang="java"><textobject><textdata
  					fileref="code_snippets/deployed_hello_example/deploy_method.txt"></textdata></textobject></programlisting>


  		<para>
  			The
  			<literal>Main</literal>
  			class:
  		</para>
  		<programlisting lang="java"><textobject><textdata
  					fileref="guided_tour/examples/DeployedHelloWorld/src/active/Main.java"></textdata></textobject></programlisting>


  	</sect2>



  	<sect2>
  		<title>Running the DeployedHelloWorld application</title>

  		<para>
  			To compile and run the application you need the HelloWorld
  			class from the previous example, the new Main class, and
  			the InitializedHelloWorld class. To compile and run the
  			application you need the
  			<literal>Main</literal>
  			class, the
  			<literal>HelloWorld</literal>
  			class, to include the following jar files:
  			<literal>ProActive/dist/lib/ProActive.jar</literal>
  			,
  			<literal>ProActive/lib/javassist.jar</literal>
  			,
  			<literal>ProActive/lib/log4j.jar</literal>
  			,
  			<literal>ProActive/lib/xercesImpl.jar</literal>
  			,
  			<literal>ProActive/lib/fractal.jar</literal>
  			, and
  			<literal>ProActive/lib/bouncycastle.jar</literal>
  			and explicitly set the Java security policy with the
  			<literal>-Djava.security.policy=pathToFile</literal>
  			and the logging policy with
  			<literal>
  				-Dlog4j.configuration=file:proactive-log4j
  			</literal>
  			. The steps necessary are explained in
  			<xref linkend="Installation" />
  			.
  		</para>
  		<para>The command line for running the application is:</para>
  		<para><screen>java -Djava.security.policy=proactive.java.policy -Dlog4j.configuration=file:proactive-log4j Main deployment.xml</screen>
  		</para>
  	</sect2>

  	<sect2>
  		<title>Monitoring The DeployedHello Application</title>
  		<para>
  			To see the the active object running, start IC2D and start
  			monitoring the remote machine on which you deployed. To
  			prevent the active object from stopping its thread remove
  			from the code above the line
  			<literal>ProActive.exitSuccess();</literal>
  			and
  			<literal>ao.terminate();</literal>
  			. IC2D will show the hostname, the node names, and the
  			active objects running on the remote host - in this case
  			InitializedHello.
  		</para>
  		<para>
  			<figure>
  				<title>
  					IC2D view of the InitializedHello example
  				</title>
  				<mediaobject>
  					<imageobject>
  						<imagedata contentwidth="100"
  							fileref="guided_tour/pics/screenshots/ic2d_deployed_hello.png"
  							format="PNG" width="6in" />
  					</imageobject>
  				</mediaobject>
  			</figure>
  		</para>
  	</sect2>
  </sect1>

  <sect1>
    <title>A Simple Migration Example</title>

       <para>Our next example deals with migrating the active objects between 
    remote nodes. We will start the active object on one machine and then move it 
    to another one. We will need to change the descriptor file to specify the
    second virtual node and machine and add a method that enables us to 
    tell the active object to migrate. </para>
    
    <para>An active object must implement the Serializable interface (as it will be transferred
      through the network) in order to be able to migrate.
       For more information on the topic of object migration, check <xref linkend="Migration" /> .</para>
    


    <sect2>
      <title>Design of Migratable Hello</title>

      
      <para>We create a MigratableHello class, that derives from
      InitializedHello. This class will implement all the non-functional
      behavior concerning the migration, for which this example is created.
      The Hello and InitializedHello classes are left unmodified.</para>

      <para>The migration has to be initiated
      by the active object itself. We will have to write the migrate method in the code of MigratableHello -
      i.e. a method that contains an explicit call to the migration primitive.
      </para>
    
      <para>The class diagram for the application is the following:</para>

      <para><figure>
      	<title>Migratable HelloWorld architecture</title>
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/hello/MigratableHelloWorld.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure></para>
    </sect2>

    <sect2>
      <title>Deployment descriptor change</title>
      <para>
      	In the deployment descriptor file we will define a new virtual node,
      </para>
      <para>	
      	<programlisting lang="xml"><textobject><textdata fileref="code_snippets/migratable_hello/component_definition.txt"></textdata></textobject></programlisting>
      </para>
      <para>	
      	another JVM to be started in the virtual node,
      </para>
      <para>
      	<programlisting lang="xml"><textobject><textdata fileref="code_snippets/migratable_hello/jvms.txt"></textdata></textobject></programlisting>
      </para>	
      <para>
      	 and a host on which the new virtual node will be located. 
	 
      </para>	 
      		<programlisting lang="xml"><textobject><textdata fileref="code_snippets/migratable_hello/infrastructure.txt"></textdata></textobject></programlisting>
      <para>
    	The full deployment descriptor file is:
		</para>
	<programlisting lang="xml"><textobject><textdata fileref="guided_tour/examples/MigratableHelloWorld/src/active/deployment.xml"></textdata></textobject></programlisting>
	</sect2>
	
<sect2>
	<title> Application changes </title>
	<para> We will extend the <literal>InitializedHelloWorld</literal> class and add a method that
	makes the active object instantiated from the new class able to migrate. The new class also
	has to implement the <literal>Serializable</literal> interface in order to be sent over
	the network.</para>
	<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/MigratableHelloWorld/src/active/MigratableHello.java"></textdata></textobject></programlisting>
	
	<para>
		We also have to change the <literal>Main</literal>class to retrieve the node
		to which the active object will migrate. For this we will add a method that
		returns the node contained in the virtual node on the second remote machine. 
	</para>
      	<programlisting lang="java"><textobject><textdata fileref="code_snippets/migratable_hello/node_retrieving_method.txt"></textdata></textobject></programlisting>
	<para>
		The full new <literal> Main </literal> class is: 
	</para>	
		<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/MigratableHelloWorld/src/active/Main.java"></textdata></textobject></programlisting>
	

        <para>Note that the call to the ProActive primitive
        <literal>migrateTo</literal> is the last one of the method <literal>packUpMyVariablesAndHitTheRoad </literal>.
        See   <xref linkend="Migration" /> for more information.</para>

      <para>During the execution the JVMs are started according to the descriptor and one active
      object is started on the first JVM. The active object is then migrated to the first node on each virtual node
      created, each time returning Hello and the computer on wich is located. 
    </para>
    </sect2>
    
    
       <sect2>
      <title>Running the MigratableHello application</title>

      <para>To compile and run the application you need the
      	 HelloWorld class from the previous example, the InitializedHelloWorld class, the 
      	 MigratableHello class,and the new Main class,.
      	To compile and run the application you need the 
		<literal> Main </literal>class, the <literal> HelloWorld </literal>class,  to
		include the following jar files: 
		  	<literal>ProActive/dist/lib/ProActive.jar</literal>,
          	<literal>ProActive/lib/javassist.jar</literal>,
          		<literal>ProActive/lib/log4j.jar</literal>, 
          		<literal>ProActive/lib/xercesImpl.jar</literal>, 
          		<literal>ProActive/lib/fractal.jar</literal>,  
          		and <literal>ProActive/lib/bouncycastle.jar</literal>
           and explicitly set the Java security policy with the  <literal>-Djava.security.policy=pathToFile</literal>
           and the logging policy with  <literal>-Dlog4j.configuration=file:proactive-log4j</literal>.
            The steps necessary are explained in <xref linkend="Installation"/>.</para>
 		<para>	The command line for running the application is: </para> 
	<para>
			<screen>java -Djava.security.policy=proactive.java.policy -Dlog4j.configuration=file:proactive-log4j Main deployment.xml</screen>
 	</para>
    </sect2>
    
    <sect2>
		<title>Monitoring The MigratableHello Application</title>
		<para>
			To monitor the movement of the active object between hosts,
			we will add a small change to the  <literal>Main</literal> class
			in the <literal>for</literal> loop. Just add <literal> System.in.read()</literal>
			before <literal>ao.packUpMyVariablesAndHitTheRoad(node);</literal>.
			Now on each Enter press the object will migrate to the next node. 
		</para>
		<para>
			To see the the active object migrating start  IC2D and start 
			monitoring the remote machines on which the JVMs were started. On pressing Enter
			the active object will migrate from machine to machine
		</para>

		<para>
			<figure>
      		<title> IC2D view of the MigratableHello example</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/screenshots/ic2d_migratable_hello_started.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
		<para>
			With this example it is also possible to migrate the active object using IC2D.
			All you have to do is drag the active object from its node to a node on another
			JVM. The active object will migrate and then continue running.  
		</para>
		<para>
			<figure>
      		<title> IC2D view of the MigratableHello example after migration</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100"
                         fileref="guided_tour/pics/screenshots/ic2d_migratable_hello_final.png"
                         format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
		
	</sect2>
	    
    </sect1><sect1>
      		<title>An Application To Find The First N Primes</title>
  		<para>In the next section we will write a  Master-Worker application to find the first N primes. </para>
	  	<sect2>
	  		<title>Application architecture </title>
			<para>
			In the application each worker knows a set of prime numbers, with zero
			numbers on creation, and learns
			new ones gradually. To determine if a number is prime or not, the master asks to each worker if
			the number can be prime according to the worker's memory. If all workers say this number
			can be prime then it is. If a number is prime is then sent randomly to one of the workers.
			The same process is used for the next number. 
	 	</para>
	 	<para><figure>
      	<title>DistributedPrimes architecture</title>
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100" fileref="guided_tour/pics/hello/DistributedPrimes.png" format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure></para>
        
	 	<para> 
			When trying to decide if 2 is prime or not, the question is asked to each worker.
			Since their local memory is empty, all will respond it can be a prime. Receiving all yes,
			the master concludes that 2 is prime and adds randomly it to the memory of one worker.
		</para>
		<figure>
			<title>Bootstrap process</title>
		  <mediaobject>
            <imageobject>
              <imagedata contentwidth="100" fileref="guided_tour/pics/hello/distributed_primes_bootstrap.png" format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>

		<para>
			When trying to determine if 15 is prime or not the master asks all of the workers and at least one
			of them answers that it is not. The master discards the number and repeats the process with 16 
			which will also be discarded and then with 17 which will be prime. 17 will be sent randomly to one
			of the workers.  
		</para>
		<figure>
			<title>Prime checking process</title>
		  <mediaobject>
            <imageobject>
              <imagedata contentwidth="100" fileref="guided_tour/pics/hello/distributed_primes_regular.png" format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
        
		<para>
			This architecture is efficient at computing big sieves. If it computes only 200 primes, communication overhead
			will be big compared to computation time, but if it computes the first 10 000 000 primes,
			then this approach is effective. Distribution allows you to compute more numbers because memory
			consumption is balanced between workers and it also allows you to compute faster since solution space is explored in parallel.
		</para>
		
		
		<para>
		The worker and master classes have several methods implementing the mechanism described above. The
		master class has a method for adding workers to its list - <literal> addWorker</literal>,
		one for randomly sending primes to 	one of the workers in the list - <literal> sendPrime</literal>,
		 and a method that sends messages to the workers and prints out the primes - <literal> startComputation</literal>.
		 The worker class has a method that checks if a number is prime <literal>isPrime</literal> and a method
		 that adds a prime to its list of numbers <literal>addPrime</literal>.
		
		For this example the master and worker classes without code look like this. Try to 
		fill in the code for the methods. An example implementation is also provided below.  
		</para>
		<programlisting lang="java"><textobject><textdata fileref="code_snippets/distributed_primes/code_stub_master.txt"></textdata></textobject></programlisting>
		
		<programlisting lang="java"><textobject><textdata fileref="code_snippets/distributed_primes/code_stub_worker.txt"></textdata></textobject></programlisting>
		
		</sect2>
		<sect2> <title>DistributedPrimes Implementation </title>
		<para>
		This is one of the possible implementations. We use a simple algorithm for the <literal> isPrime </literal> method in 
		the workers, however more efficient implementations can be used. 
		In the main class we will create a master active object and several workers active objects deployed one on each machine specified in the 
		deployment descriptor. 
		</para>
		<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/DistributedPrimes/src/active/Main.java"></textdata></textobject></programlisting>
		
		<para>
		In the <literal>startComputation</literal> methode in the <literal>PrimeManager</literal> class we use a special way of calling
		the <literal>isPrime </literal> method on the workers so the answers to the requests can be received in any  order. First
		we create a Vector <literal> answers</literal>  which contains the futures from the workers. We use the static method
		 <literal> ProFuture.waitForAny(Vector)</literal> method which blocks the call until one of the futures
		stored in the Vector is updated. When one of the futures is updated we check if it is true or not and then remove it from the Vector.
		When the Vector is empty all the workers have sent their response. 
		</para>
		<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/DistributedPrimes/src/active/PrimeManager.java"></textdata></textobject></programlisting>
		<para>
		PrimeWorker class:
		</para>
		<programlisting lang="java"><textobject><textdata fileref="guided_tour/examples/DistributedPrimes/src/active/PrimeWorker.java"></textdata></textobject></programlisting>
		</sect2> 
 		<sect2><title>Deployment Descriptor</title>
 			<para> The deployment descriptor for the DistrbutedPrimes application is similar to the
 			one from the previous examples. If you want to deploy on more machines the only change necessary
 			is adding the needed definitions for JVMs, protocols, and host in the deployment descriptor.
 			</para>  
 		</sect2>
 		    <sect2>
      <title>Running the DistributedPrimes application</title>

      <para>To compile and run the application you need the
      	 HelloWorld class from the previous example, the InitializedHelloWorld class, the 
      	 MigratableHello class,and the new Main class,.
      	To compile and run the application you need the 
		<literal> Main </literal>class, the <literal> HelloWorld </literal>class,  to
		include the following jar files: 
		  	<literal>ProActive/dist/lib/ProActive.jar</literal>,
          	<literal>ProActive/lib/javassist.jar</literal>,
          		<literal>ProActive/lib/log4j.jar</literal>, 
          		<literal>ProActive/lib/xercesImpl.jar</literal>, 
          		<literal>ProActive/lib/fractal.jar</literal>,  
          		and <literal>ProActive/lib/bouncycastle.jar</literal>
           and explicitly set the Java security policy with the  <literal>-Djava.security.policy=pathToFile</literal>
           and the logging policy with  <literal>-Dlog4j.configuration=file:proactive-log4j</literal>.
            The steps necessary are explained in <xref linkend="Installation" />.</para>
 		<para>	The command line for running the application is the following the second
 		 parameter being the number of primes compute: </para> 
	<para>
			<screen>
java -Djava.security.policy=proactive.java.policy -Dlog4j.configuration=file:proactive-log4j Main deployment.xml  10000
			</screen>
 	</para>
    </sect2>

    <sect2>
		<title>Monitoring The Distributed Primes</title>
        <para>
			To see the the DistributePrimes example running  start IC2D and start 
			monitoring the remote machines on which the JVMs were started. IC2D will show the
			active objects and the communication between them. You will see that the communication
			only takes place between the PrimeManager and the PrimeWorkers. 
		</para>
		
		<para>
			<figure>
      		<title> IC2D view of the DistributedPrimes example</title> 
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100" fileref="guided_tour/pics/screenshots/ic2d_primes.png" format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
		<para>
			It is possible to migrate workers to other machines while the example is running.
			Bellow is an example of how all of the workers were moved on the same machine. 
			Because of the way the PrimeManager is designed it is impossible to move it to another machine.
			Migration happens after the current task of the active object is finished.
			Since the task of the PrimeManager is  continously running until the end of the computation,
			it is impossible to 
			move the PrimeManager to another machine.
		</para>	
	<para>
			<figure>
      		<title> IC2D view of the DistributedPrimes example after migration</title> 
          
          <mediaobject>
            <imageobject>
              <imagedata contentwidth="100" fileref="guided_tour/pics/screenshots/ic2d_primes_migrated.png" format="PNG" width="6in" />
            </imageobject>
          </mediaobject>
        </figure>
		</para>
	</sect2>
	
  </sect1>
  
  	<sect1 id="MWPI">
		<title>Master-Worker DistributedPrimes Application</title>
	<para>
		In the previous Distributed Primes example, we have used 
		a basic master-worker architecture in order to distribute the
		computation. However, the algorithm used is very inefficient as
		the master has to wait for all the workers to finish the computation
		before sending a new number to be computed. In this chapter we will rewrite the 
		algorithm to take advantage of the Master-Worker API already included
		in ProActive. 
		</para>
		<para>
		The Master-Worker API aims to simplify the distribution of computations 
		which are embarrassingly parallel. The Master-Worker API hides the active object details from
		the user allowing the distribution of computation without explicitly specifying 
		the creation and deployment of active objects.  
		
	</para>
	<para>
		We will rewrite the Primes example to take advantage of the Master-Worker 
		API. Each Worker will check if a number is prime by using the simple Euclid's 
		sieve algorithm. We are not aiming for a efficient algorithm, as there are much
		faster and more complex methods of checking for primes, but for an illustration
		of how the Master-Worker API works.   
	</para>

      <para> The Master-Worker API use a logical partition of computations and resources: </para>
      <itemizedlist>
      	<listitem> <para><emphasis> task </emphasis> - a task is logical partition of the 
	      	computation. The computation will be split into several tasks that will
	      	be assigned to workers. </para></listitem>
      	<listitem> <para> <emphasis>worker</emphasis> - a worker is logical partition of the 
	      	resources available. The workers retrieve tasks, compute them and send
	      	the results back to the master.</para>
      	</listitem>
      </itemizedlist>
      
      	<figure> <title> Architecture of Distributed Primes  Using Master-Worker API </title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/masterworker/DistributedPrimesMW.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>
     <sect2>
      	<title>Application components</title>
      	<para>
      		The general simple algorithm for using the Master-Worker API is the following:
      	</para>
      		<orderedlist>
	      		<listitem><para>Define the resources</para></listitem>
      			<listitem><para>Define the master</para></listitem>
      			<listitem><para>Define the tasks</para></listitem>
      			<listitem><para>Tell the master to solve the tasks</para></listitem>
      			<listitem><para>Retrieve the results from the workers</para></listitem>
      		</orderedlist>
      <para>
      	While this is the basic structure possible with the Master-Worker API, 
     	more complex algorithms are of course possible. 
      </para>
    <para>
		We follow this algorithm in our simple example.
	</para>	
	<para>
		First we define the resources to be used by specifying a deployment  descriptor:
	</para>
	
	 <programlisting lang="java"><textobject><textdata 
	 fileref="guided_tour/code_snippets/masterworker/acquire_resources.txt" /></textobject></programlisting>
	
	
	<para>To learn how deployment descriptors work read <xref linkend="deployment_guide"/>
	and <xref linkend="XML_Descriptors"/>. </para>
	
	<para>After specifying the resources we need to create a master to coordinate the
	computation: </para>
	
	<programlisting lang="java"><textobject><textdata 
	 fileref="guided_tour/code_snippets/masterworker/master.txt" /></textobject></programlisting>
	
	<para>The master has as a type <literal>ComputePrime</literal> which is a
	inner class that extends the <literal>Task</literal> interface. To create
	the master we need to specify a task the master will control and the return
	type of the method <literal>run()</literal> in the task (in our case <literal>
	Long</literal>).</para>
	
	 <programlisting lang="java"><textobject><textdata 
	 fileref="guided_tour/examples/DistributedPrimesMW/src/active/DistributedPrimesMW.java" /></textobject></programlisting>
	<para>some more info and code</para>	
		<title>Running My Great Application</title>
		<para>
			Information on running
		</para>	
		<para>
			The command line for running the application is: 
		</para>
	</sect2>
	<sect2>
		<title>Monitoring Of My Great Application</title>
		<para>
			Info on monitoring
		</para>
		<para>
			Screenshot of monitored app
		</para>
	</sect2>
	
	 </sect1>
	
  
  
  
  	 <sect1>
			<title> GCM Components Tutorial </title>

	<sect2> 
		<title>Introduction</title>
		<para>
			This section introduces the ProActive/GCM implementation
			 and presents a short user guide which explains how to use it. The section will not explain how to 
			  program with components but instead focus on the particularities of the GCM implementation for ProActive. 
		</para>
	</sect2>
	<sect2>
		<title>	 Key features of the ProActive/GCM Implementation </title> 
			 <itemizedlist>
			 <listitem>	 <para>Creation/usage of primitive and composite components</para></listitem>
			 <listitem><para> Client, server and non-functional interfaces </para>
					<para>In addition to single/collection cardinalities,
				 the ProActive/GCM implementation also provides multicast and gathercast cardinalities.</para>
				 </listitem> 
			<listitem><para>ADL support </para></listitem> 
			<listitem><para>Deployment descriptor files describing components deployment</para>
						<para>
							Several	components in an assembly can be distributed on 
							different nodes on several computers using transparent remote communication.
							Such an arhitecture is presented in the figure below. 
						</para>
						
				


      	<figure> <title> Component with inner component distributed </title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/gcm/gcm_nodes.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>
		</listitem>
		</itemizedlist>
		<sect3>
		<title> Primitive and composite components </title>
		<para>
			The GCM component  model is hierarchical, so components
			 can be either primitives or composites. A composite
			 can contain one or many inner components (primitive or
			 composite). Non functional and functional interfaces can be defined. 
			</para>
			<para>
			ProActive/GCM provides the following defaults
			 non functional interfaces thanks to the following controllers:
			  binding-controller, name-controller, lifecycle-controller,
			   super-controller, content-controller as specified by
			 the GCM specification. In addition, there are other
			 specific controllers in our implementation, namely
			migration-controller, multicast-controller, gathercast-controller
			and component-parameters-controller. In the current implementation,
			the non functional part of a component can also be customized and extended.
			</para>
			<para>
			Furthermore, ProActive/GCM allows developers to
			 define what a component needs and provides with its client and server interfaces. 
			 <!--  TODO These
			  interfaces are defined by Java interfaces like non functional. what ?-->
			  </para> 
			   </sect3>
			  <sect3>
			  	<title> Collective Interfaces </title>
			  	<para>
			  	By using collective interfaces, component systems designers
			  	are able to specify parallelism, synchronization and
			  	data distribution. Collective communications refer
			  	to multipoint interactions between software entities.
			  	Collective interfaces have two types of cardinalities, multicast and gathercast.
			  	</para>
			  	<para>
			  	A collective interface gives the possibility to
			  	manage a group of interfaces as a single entity.
			  	This entity is itself an interface and viewed likewise.
			  	The role and usage of multicast and gathercast interfaces are complementary.
			  	</para>
			  	<sect4>
			  		<title> Multicast Interfaces </title>
			  		<para>Multicast interfaces are used for parallel
			  		 invocations, parameters dispatching and results gathering. 
			  		 A multicast interface is an abstraction for 
			  		 1-to-n communications. When a single invocation is
			  		 transformed into a set of invocations, these invocations 
			  		 are forwarded to a set of connected server interfaces. Both
			  		 the propagation of the invocation and the distribution of 
			  		 the invocation parameters are customizable (through Java
			  		 annotations in the Java interfaces definitions). 
			  		 The result of an invocation, if it isn’t a void return 
			  		 type, on a multicast interface will be a list of results wherever applicable.
			  		 </para>
			  		 <para>
					If some parameters in a given method of a
					 multicast interface are lists of values, these values can
					 be distributed in various ways through method invocations to
					 the server interfaces connected to the multicast interface
					 (see Figure 2). The default behaviour –namely broadcast – is
					 to send the same parameters to each of the connected server
					  interfaces (see Figure 2.a). In case some parameters are list
					  of values, copies of the lists are sent to each receiver. 
					  However, similar to what SPMD programming model offers, 
					  it may be adequate to strip some of the parameters so that 
					  the bounded components will work on different data. In
					  MPI, for instance, this can be explicitly specified by 
					  stripping a data buffer and using the scatter primitive. In
					  this case, you will use scatter or one-to-one dispatch mode (see Figure 2.b).
					  </para>
					  

      	<figure> <title> Component parameters </title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/gcm/gcm_parameters.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>


			<para>GCM also specify result aggregation,
			 but in the current state of the ProActive/GCM implementation
			 the only available behaviour is the aggregation of results as list.
			 </para>
			 </sect4>
			 <sect4>
			 	<title>Gathercast interfaces</title>
			<para>
				Gathercast interfaces are used for synchronization, parameter gathering and result dispatching.
				A gathercast interface is an abstraction for n-to-1 communications. 
				It handles data aggregation for invocation parameters, as well 
				as process coordination. It gathers incoming data, and can also
				 coordinate incoming invocations before continuing the invocation 
				 flow, by defining synchronization barriers. Invocation parameters are simply
				 gathered into lists of parameters as showed in the Figure 3.
      	<figure> <title> Invocation parameter with a gathercast interface </title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/gcm/gcm_gathercast_invocation.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>
		<para> The following table summarizes the possible distribution
		 policies based on parameters and return type. </para>

      	<figure> <title> Distribution policies </title>
		  <mediaobject>
          <imageobject>
            <imagedata contentwidth="100"
                       fileref="guided_tour/pics/gcm/distribution_policies.png"
                       format="PNG" width="6in" />
          </imageobject>
        </mediaobject>
      </figure>
	</para>
	</sect4>
	</sect3>		 
	<sect3>
		<title>ADL file</title>
		<para> The Architecture Description Language (ADL) is used to 
		define component type, configure and deploy component systems. You
		 can define component and interface types, describe component
		  membrane, and declare on which Virtual Node and you
		   want deploy each component. The architecture of the system
		    is described in one or many XML file.</para>
		    <para>
			Components are defined in files ending with the <literal>.fractal</literal> extension.
			 The syntax of the document is validated against a DTD retrieved from
			  the classpath  <literal>classpath://org/objectweb/proactive/core/component/adl/xml/proactive.dtd </literal>.
			   This DTD extends the Fractal ADL DTD and the implementation reuses
			    and extends the FractalADL project
			     [2].  You can find tutorial and document on
			      ADL in this project1. The GCM specification [1]
			       adds some keywords in the ADL definition which are supported by ProActive/GCM.
			        The following section illustrates how you can use these files
			         to describe a component assembly, and how you can use it with the Fractal/GCM API.
			         </para>
			         </sect3>
			         </sect2>
		<sect2>
			<title>Components User Guide</title>
 			<para> Along this short user guide, we will show how
 			 to use concretely the features described previously: how to
 			  create primitive and composite components, how to assemble
 			   them using Fractal/GCM API and Fractal API files, how
 		  	to interoperate with components, and then how to describe
 			the deployment of components using deployment descriptor file.
 			</para>
 			<sect3><title>	Creating and using components in a programatic way</title>
 				<para> The first step of this user guide explains how
 				 to create a single primitive component. Next, we will use an
 				  assembly of two primitive components in a composite one.</para>
 				  <sect4>
 				  	<title>
 					The first component </title>
				
					<para>We want to create a primitive component, 
					called PrimitiveComputer. It exposes one server interface 
					called computer-itf which provides the two following
					 methods: compute and doNothing. To do that, we need to write the two following classes.
					 	</para>
					 <programlisting><textobject><textdata fileref="automatic_snippets/simple_composite_interface"></textdata></textobject></programlisting>

					 <programlisting><textobject><textdata fileref="automatic_snippets/primitive_computer"></textdata></textobject></programlisting>
					 
				<para>Now, we will discuss on the different ways to use this component.
					First, we must create the component with
					the ProActive/GCM framework. Two kinds of component
					instantiation are shown. In the first case, we can
					do all these steps in the application. However, in
					the second case, we will show how we can use the ADL
					files to simplify the application and create it in a simpler way.
					</para>
					<para>
					In order to illustrate these different ways,
					a new class, Main, containing the possible main
					method of our application (see the source code below), 
					is written. In this main method, four different methods
					are called and will be described in the following parts
					of this document, launchFirstPrimitive,
					launchWithoutADL, launchWithADL, and finally
					the last launchAndDeployWithADL. To launch this
					class, you must put in your classpath all
					the libraries contained in the lib directory
					 and subdirectories and the ProActive jar. And finally,
					 you must set the three Java properties 
					 (fractal.provider, java.security.policy, log4j.configuration) as shown in the command line:
					 
					</para>
					 <programlisting><textobject><textdata fileref="guided_tour/code_snippets/components/simple_component_run.txt"></textdata></textobject></programlisting>


					 <programlisting><textobject><textdata fileref="automatic_snippets/simple_composite_main"></textdata></textobject></programlisting>
					<para> If we want to create and call components in
					 a standard Java application, we need to use the GCM API [1].
					 The method launchFirstPrimitive shows all the steps
					 to create and use our first primitive component.
					 Firstly, define the type of the component. Secondly,
					 create component using a factory. Thirdly,
					 start the component. And finally, retrieve the component’s
					 interface and use it as a standard Java object to access our component.
					 </para>
					 <!-- TODO launchFirstPrimite Method -->
				
				<para> Uncomment the line calling the <literal>launchFirstPrimitive</literal>
				 method in the main method, launch it and see
				  below the expected output. The first lines are ProActive
				  log, and at the end, information printed in the component and in the Main class is visible.
				  </para>
				  <!--  TODO launcPrimitive output -->
			</sect4>
			<sect4>
				<title>Define an assembly</title>
					<para> Now that we succeeded to create and use
					 a primitive component, we will learn how to use
					  it in a component assembly. First of all, we want
					   use the previous shown primitive component with another
					    primitive component to explain how to define, implement and
					     use client interfaces. Moreover, in order to use composite
					      component, we put the two primitive components in
					       a composite. The Figure 4 shows this assembly. 
					       </para>
			
	      	<figure> <title>Component assembly </title>
			  <mediaobject>
	          <imageobject>
	            <imagedata contentwidth="100"
	                       fileref="guided_tour/pics/gcm/component_assembly.png"
	                       format="PNG" width="6in" />
	          </imageobject>
	        </mediaobject>
	      </figure>
			<para> To implement this assembly we need one more class,
			 PrimitiveMaster. This class implements the following Java interfaces: 
			 java.lang.Runnable and moreover the BindindController to allow binding
			 on the compute-itf client interface. In the run method we
			 put the call to the PrimitiveComputer component, we
			 don’t need to retrieve the compute-itf interface since the assembling
			 it’s done in the launchWithoutADL method or in the following part using ADL.
			  </para>
			 <programlisting><textobject><textdata fileref="automatic_snippets/primitive_master"></textdata></textobject></programlisting>
			   <para> In the launchWithoutADL method, we extend component type definition
			    and component creation parts. And we add one more part, 
			    the component assembling. In this part, at first 
			    we put the two primitives, PrimitiveComputer and PrimitiveMaster 
			    in the composite component. Next, we make the binding between each component interfaces.
			    </para>
			 <programlisting><textobject><textdata fileref="automatic_snippets/launch_without_ADL"></textdata></textobject></programlisting>
			    <para> This way isn’t the simplest one to create and use
			     component. There is a lot of code to write, that
			      could introduce mistakes or errors in an assembly. We will show an easier one next.
			      </para>
			      </sect4>
			      </sect3>
			<sect3>
			<title>Create and use components using ADL</title>
				<para> We want create the same component directly using
				 ADL capabilities. The source code of the method launchWithADL shows
				  how to use it. Another factory is used, and we can create
				   directly the component without defining at first its
				    type. Utilization of the created component is still the same. You can
				     see that we don’t need to define
				      and assemble parts any more. Moreover, we need to create only one
				       component, the other ones are automatically created.
				       </para>
			 <programlisting><textobject><textdata fileref="automatic_snippets/launch_with_ADL"></textdata></textobject></programlisting>
				<para> ADL allows describing a component assembly through a text
				 file. In our case, we have defined fives files. These
				 files need to be in the classpath of
				 the application, for instance the PrimitiveComputer.fractal
				 file needs to be in the <literal>org/objectweb/proactive/examples/components/userguide/adl</literal>
				 directory in the classpath. The first one, PrimitiveComputerType.fractal, 
				 describes the component type, in particular the interface and
				 the membrane with the tags interface and controller. The second one, 
				 PrimitiveComputer.fractal, adds two necessary information: the 
				 implementation class with the content tag and a virtual node
				  with the virtual-node tag. These tags are explained in the following section.
				  </para>
			 <programlisting><textobject><textdata fileref="automatic_snippets/primitive_computer_type_fractal"></textdata></textobject></programlisting>
					<para> 		It is quite the same for the
					PrimitiveMaster component; just the name
					 and definition class change, and there is one more interface, a client one.
					 </para>
					 <!-- TODO PrimitiveMasterType.fractal-->

				<para>And finally, there is the composite one. It
				 defines one interface, and include the two primitive
				  described previously. The binding tag is new; it describes
				   the binding between the interface from composite and inner components.
				   </para>
				   <!--  TODO CompositeWrapper.fractal
				    -->
				
				<para>Now, we can run the example; uncomment the line calling the
				 launchWithADL method in the main and then you can see the same output as in the previous section.
				 </para>
				 </sect3>
				 <sect3>
				 <title>Creating, using and deploying components using ADL </title>
				 	<para>To deploy components on a specific virtual node, we need
				 	 to use ADL files. Just before we saw that the tag
				 	 virtual-node allows to specify which virtual node to
				 	 use for a component. The virtual node is defined in a separate
				 	 file: a deployment descriptor. You can find more information on how to write a
				 	 deployment descriptor file in the ProActive documentation, 
				 	 <!-- TODO add xref -->chapter 21, XML Deployment Descriptors. 
				 	 The deployment descriptor file used in this example is in the Appendix: <literal>deploymentDescriptor.xml.</literal>
				 	 </para>
				 	 <para>Furthermore, we need to inform the factory how
				 	  to use this deployment descriptor; we do
				 	   this in the launchPrimitiveADLAndDeployment method :
				 	   </para>
				 	   <itemizedlist>
				 	   <listitem><para>We create a ProActiveDescriptor object</para></listitem> 
						<listitem><para>We put this object in the context HashMap</para></listitem>
						<listitem><para>We give this HashMap to the factory</para></listitem>
						</itemizedlist>
							<para>Thus, the factory can retrieve the virtual node defined, 
							and use it as described in the ADL files. </para>
							<para> There is another specific point in the
							 end of this method with the 
							 <literal>deploymentDescriptor.killall(false);</literal> call.
							This method kills all the JVM deployed using the
							original deployment descriptor file. Before this call, we need 
							to suspend the program since the method calls in GCM
							 are asynchronous, in order to not kill JVM before the end of the component execution.
							 </para>
				<!-- TODO launchAndDeployWithADL method
				 -->
				 <para> Now we can run this example; uncomment the
				  line calling the launchPrimitiveADLAndDeployment method, launch it and see
				   below the expected output. The first lines are
				    ProActive log; it’s more verbose than during previous 
				    execution because we deploy the two JVMs defined in the
				     deployment descriptor file. After that, you can see information
				      printed from the component and the Main class
				      . And finally, the ProActive log again when the created JVMs are killed.
				      </para>
				      
				      <!--  TODO  launchPrimitiveADLAndDeployment Output
Launch primitive component example
Launch component assembly example
Launch component assembly example with ADL
Launch and deploy component assembly example with ADL
				      -->
				      </sect3>
				      <sect3>
				      <title>Component interface Cardinality</title>
				      <para> Client and server also support multicast and gathercast
				       interface cardinality. The GCM [1] explains which constraints
				        the server and client interfaces must respect
				         and we discuss previously in the section 2.2 on their principles.
				         </para>
				         <para> For multicast interfaces you can specify the parameter dispatching
				          mode thanks to Java annotations available in
				           the org.objectweb.proactive.core.component.type.annotations.multicast package.
				           </para>
				           </sect3>
				   <sect3>
				   <title>Additional examples</title>
				   <para> Two component applications are included in ProActive the HelloWorld and C3D example.
				   </para>
				   <para>A Hello World example is provided. It shows the
				    different ways of creating a component system programmatically and using
				     ADL. You can find the code for this example in the package 
				     <literal>org.objectweb.proactive.examples.components.helloworld </literal> of the CFI prototype distribution. 
				     </para>
				     <para>The example code can either be compiled and run manually or using scripts
				      (hello-world_fractal.sh (or .bat) in the scripts/unix/components directory) can
				       be used to launch it. If you choose the first solution, do not forget to set the fractal.provider system property.
				       </para>
				       <para> The other example, C3D application — a parallel, distributed and collaborative
				        3D renderer, is in the org.objectweb.proactive.examples.components.c3d package.
				        </para>
				        </sect3>
				        </sect2>
				        <sect2> 
				        	<title>Conclusion</title>
				        	<para>We have demonstrated that the main features of
				        	 the GCM are implemented in ProActive and can be
				        	  used to design and implement grid applications. Also the short
				        	   user guide shows how we can start using it.</para>
				        	 <para>
				        	 Bibliography
						[1] GCM, D.CFI.01 - Component model presentation and specification (XML schema or DTD), GridCOMP deliverable
						[2] FractalADL, The Architecture Description Language of the Fractal component model, http://fractal.objectweb.org/fractaladl/index.html
						[3] ProActive, Professional Open Source Middleware for Parallel, Distributed, Multi-threaded Programming,  http://www-sop.inria.fr/oasis/ProActive/
						</para>
			<!-- TODO deployment.xml -->
			</sect2>
		</sect1>
<sect1 id="Sched_tuto">
<title>ProActive Scheduler Tutorial</title>
	<sect2 id="intro">
		<title>introduction</title>
		<para>
		This document aims to present in a practical way the ProActive Scheduler. 
		Scheduler is a tool which administer deployment and maintenance of a jobs queue 
		over various platforms and infrastructures (Grid or P2P infrastructure) 
		following one of many set of rules regarding the job management.
		<itemizedlist>
		<listitem>
			Scheduler architecture <xref linkend="sched_archi"/>
		</listitem>
		<listitem>
			Task flow concept : <xref linkend="taskflow_concept"/>
		</listitem>
<!--		
		<listitem>
			We will create our first Scheduler job : <xref linkend="first_job"/>
		</listitem>
		<listitem>
			Then we will launch the scheduler and submit the job created :<xref linkend="launching"/>
		</listitem>
		</itemizedlist>	
		<para>
		After we will see some additional functionalities and different kinds of job runnable on the scheduler :
		</para>
		<itemizedlist>
		<listitem>
			Adding init parameters to a task : <xref linkend="add_parameters"/>
		</listitem>		
		<listitem>
			How to pass result of a task to another task : <xref linkend="result_passing_mechanism"/>
		</listitem>
-->	
		<listitem>
			Schedule a native executable : <xref linkend="native_job"/>
		</listitem>
		<listitem>
			Launch Scheduler and submit a job :<xref linkend="launching"/>
		</listitem>		
		<listitem>
			Node selection mechanism : <xref linkend="add_sel_script"/>
		</listitem>
		<listitem>
			PreScript and PostScript features : <xref linkend="pre_post"/>
		</listitem>
		<listitem>
			How to generate dynamically a native command to execute, depending to the node architecture : <xref linkend="command_generator"/>
		</listitem>
		<listitem>
			Exported Environment variables introduced into the task's execution environment    : <xref linkend="tasks_env_var"/>
		</listitem>		
		</itemizedlist>

		</para>
		<sect3 id="prerequisites">
		<title>Prerequisites and conventions :</title>
		<itemizedlist>
		<listitem>
			<para>
			You must have an Eclipse 3.2 IDE installed, and the ProActive Project open in your Eclipse. 
			</para>
		</listitem>
		<listitem>			
			<para>
			The directory of ProActive project in your system is represented by the tag : <literal>[ProActive_dir]</literal>.
			</para>
		</listitem>
		<listitem>			
			<para>
			You need  a working directory in your system, represented here by <literal>[working_dir]</literal>.
		 	</para>
		</listitem>
		</itemizedlist>				 	
		</sect3>
	</sect2>
	<sect2 id="sched_archi">
		<title>Scheduler architecture</title>
		<para>
			The scheduler is made of two main components : the Scheduler and the Resource Manager.  
			Each of them has its own functionality :
		<itemizedlist>			
		<listitem>
			<para>
			The scheduler is in charge of registering jobs submitted 
			and put them in a queue according to a scheduling policy. 
			Then it is charged to ask Resources at the Resource Manager, 
			and execute jobs on those retrieved resources.
			</para>
		</listitem>
		<listitem>			
			<para>
			The Resource Manager (RM) handle a set of resources available for scheduling jobs.
			It takes benefits of the Proactive Library, so it can handle resources from LAN, 
			cluster of workstations,  P2P desktop Grids, or on Internet Grids. 
			Resource Manager provides the scheduler in resources, according to criteria (Operating System, dynamic libraries,
			Memory...). Resources, at ProActive point of view, are called nodes,
			so Resource Manager supplies scheduler in ProActive nodes.
			</para>
		</listitem>
		</itemizedlist>
		</para>
		<figure id="scheduler_archi_img">
				<title>Scheduler architecture</title>
				<mediaobject>
					<imageobject>
						<imagedata align="center"
							fileref="scheduler/pics/tuto/arch.jpg" format="JPG" />
					</imageobject>
				</mediaobject>
	</figure>
	<para>
		These two components (Scheduler and IM) are independent and run as non GUI daemon/service.
		So they can run on two different hosts.
	</para>
</sect2>
<sect2 id="taskflow_concept">
	<title>Task-flow Concept</title>
	<para> Submit a job to the ProActive Scheduler means submitting a <emphasis role="bold">task flow</emphasis>,
	which is a set of tasks. A task can be defined as a part of the job, a step to execute in the job.
	Jobs can also be made of different tasks, i.e. different steps to execute.
	Task is most little part of a job, the smallest schedulable entity. ProActive Scheduler has 
	computing nodes to execute jobs, basically it launches on each node an execution
	of a task, and when task is ended, launches another etc...
	</para>
	<sect3 id="task_flow_illust">
	<title>Parallel tasks,  predecessor tasks</title>
	<para>
		When you build your job, you create a graph of tasks, with a definition of predecessor/successor between tasks :
	</para>
	<figure id="scheduler_archi_img">
				<title>Scheduler architecture</title>
				<mediaobject>
					<imageobject>
						<imagedata align="center"
							fileref="scheduler/pics/core/schedulerJob.jpg" format="JPG" />
					</imageobject>
				</mediaobject>
	</figure>
	<para>
	In this tasks graph, we see that task 4 is preceded by task 1, that means scheduler waits end of task 1 execution 
	before launching task 4. In a more concrete way, task 1 could be calculation of a part of the problem to solve, 
	and task 4 takes result provided by task 1 and compute another step of the calculation. 
	We introduce here concept of <emphasis role="bold">result passing</emphasis> between tasks, explained later. 
	This relation is called a dependence, and we say that task 4 <emphasis role="bold">depends</emphasis> on task 1. 
	</para>
	<para>
	We see that task 1, 2 and 3 are not linked, so these three tasks can be executed in <emphasis role="bold">parallel</emphasis>, 
	because there are independent from each other.
	</para>
	<para>	
	Finally we see task 7 and 8 are at end of the oriented graph, These are task which produce final
	results of the job expected by the user, we call these final results <emphasis role="bold">Precious result</emphasis>.
	</para>
	<para>
	Definition of the task-flow graph is made at job's definition, before scheduling, and cannot be modified during
	execution of the job, this kind of work flow is called a <emphasis role="bold">static work flow</emphasis>.
	A Task flow job is described in XML language.
	</para>
	</sect3>
</sect2>

<!--



<sect2 id="first_job">
	<title>Developing my first job</title>	
	<para>
	In this part we will build a basic job 's example which can be submitted to the scheduler. 
	For the first example we will create a job containing just one task. We have two files to provide :
		<itemizedlist>
		<listitem>
			a Java Class file representing the computing code of the task.
		</listitem>
		<listitem>
			an XML file describing the job (tasks composing the job).
		</listitem>
		</itemizedlist>
	</para>

		<sect3 id="Task_Code.">
			<title>Task Code</title>
			<para>
				We will create a Java class derived from JavaExecutable and containing the primitive execute. 
				This function should be declared to implement the "business code" of the task. 
				When the task is deployed on a resource (a node), this function is called to complete task's objective. 
				Open ProActive project in your Eclipse IDE and create a new Java class called HelloTask.java 
				in the the src/Extensions/org/objectweb/proactive/extensions/scheduler/examples directory. 
				Type in the file the code below :
			</para>
			<para>
			 <emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>src/Extensions/org/objectweb/proactive/extensions/scheduler/examples
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>HelloTask.java
			</para>
			<programlisting lang="java">			
package org.objectweb.proactive.extensions.scheduler.examples;

import org.objectweb.proactive.core.util.ProActiveInet;
import org.objectweb.proactive.extensions.scheduler.common.task.TaskResult;
import org.objectweb.proactive.extensions.scheduler.common.task.executable.JavaExecutable;

public class HelloTask extends JavaExecutable{

	public Object execute(TaskResult... results) {
		  	String result= "HelloWorld task, host : ";
            result += ProActiveInet.getInstance().getHostname();
            System.out.println(result);
      		return result;
	  }
}						
			</programlisting>
	<para>
	In this example, the task says Hello, and display host address of the resource (node) where the task is executed.
	We see that primitive execute() have TaskResult objects in arguments, and must return an Object, 
	which is considered as the result of the task. these two aspects of the primitive are made 
	for the result passing mechanism between tasks, and will be explained later.
	</para>
	<para>
	Compile these file. You can compile with your eclipse IDE,  or type this command (For Unix systems) :
	</para>
	<para>
	<literal>
	[ProActive_dir]/compile/build compile
	</literal> 
	</para>
	<para>
	If your a are on a windows system, type :
	</para>
	<para>
	<literal>
	[ProActive_dir]/compile/build.bat compile
	</literal> 
	</para>			
	</sect3>
	<sect3 id="XML_description">
	<title>XML job description</title>
		<para>
		Now we need to write an XML file which describe the job.
		In this XML file we specify tasks composing the job, and the "predecessor/successor" orders in tasks. 
		Create a file job_HelloWorld.xml in your [working_dir], 
		and type the XML description of our simple Hello World job example.	
		</para>
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>
		<para>			 
		<emphasis role="bold">file : </emphasis>job_HelloWorld.xml
		</para>
		<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/java_job_1_task.xml"></textdata></textobject>	
		</programlisting>
		<para>
	<emphasis role="bold">Job tag :</emphasis>
	</para>
	<para>
	Specifies XML schema related to a job descriptor : schedulerjob.xsd
	Job have a specified name (here "Job_Hello").
	We specify the scheduling priority of the job, there are tree priority levels : lowest, low, normal (for the user, actually there are five levels, 
	but the two other levels, high and highest, can only be setted by scheduler's administrator).
	We specify a log file for the Job (don't forget to replace <literal>[working_dir]</literal> by the path of your “real” working directory. standard and error outputs of All tasks are written in this file.
	</para>
	<para>
	<emphasis role="bold">Description tag of the job: </emphasis>
	</para>
	<para>
	A literary description of the job.
	</para>
	<para>
	<emphasis role="bold">Taskflow tag :</emphasis>
	</para>
	<para>
	Specifies that the job is made of tasks that need to be executed in a certain order.
	This is not very interesting here because we have just one task ! (This Scheduler tutorial presents only this kind of job).
	</para>
	<para>
	<emphasis role="bold">Task tag :</emphasis>
	</para>
	<para>
	specifies task of the job. The task name (here "hello") is used to 
	identify the task from each other in the job, this parameter is mandatory 
	and must be unique for each task in the XML job descriptor. 
	Parameter preciousResult="true" is here to said that the task's result 
	is needed and have to be recoverable at end the of the job.
	Taskflow specification in job descriptor will be explained later.
	</para>
	<para>
	<emphasis role="bold">Description tag of the task :</emphasis>
	</para>
	<para>
	A literary description of the task.
	</para>
	<para>
	<emphasis role="bold">javaExecutable tag :</emphasis>
	</para>
	<para>
	In this tag we will define the kind of the task to schedule, 
	and where is "the business code", developed earlier. 
	So our task is a Java process and the class name of the task is 
	org.objectweb.proactive.extensions.scheduler.examples.HelloTask.
	</para>
	<para>
	Now our job is defined and ready to be scheduled !
	</para>
	</sect3>
</sect2>
<sect2 id="add_parameters">
	<title>Adding init parameters to the task</title>	
	<para>
	We can specify “init" parameters for a task, these parameters are specified in the XML descriptor,
	and are then available for the task. Let's add to our example an integer parameter 
	which specify how many times the task has to say “hello”.
	</para>	
	<sect3 id="xml_desc_add_para">
		<title>XML job description</title>	
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>
		<para>			 
		<emphasis role="bold">file : </emphasis>job_HelloWorld.xml
		</para>
		<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/java_job_1_task_with_param.xml"></textdata></textobject>	
		</programlisting>
		<para>
	 	We can see the new tag <emphasis role="bold">&lt;Parameters&gt;</emphasis> with its child “parameter”, 
	 	included in the javaExecutable tag. A parameter is made of a name (identifier) and a value.
	 	You can specify as parameters as you need. 
		</para>
	</sect3>
	<sect3 id="get_params">
		<title>Getting parameters in the task code</title>
	<para>
		Complete java code of the task as below :
	</para>
	<para>
			<emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>src/Extensions/org/objectweb/proactive/extensions/scheduler/examples
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>HelloTask.java
			</para>
			<programlisting lang="java">
package org.objectweb.proactive.extensions.scheduler.examples;

import java.util.Map;

import org.objectweb.proactive.core.util.ProActiveInet;
import org.objectweb.proactive.extensions.scheduler.common.task.TaskResult;
import org.objectweb.proactive.extensions.scheduler.common.task.executable.JavaExecutable;

public class HelloTask extends JavaExecutable{

	private int hello_number;

	public void init(Map&lt;String, Object&gt; args) {
	   if (args.containsKey("hello_number")){
	       try {
			hello_number =
			Integer.parseInt(args.get("hello_number").toString());
	       } catch (NumberFormatException e) {
	       }
	   }
	}

	public Object execute(TaskResult... results) {
		String result="";
		for(int i=0; i&lt;this.hello_number; i++)
		{	   
			result += "HelloWorld task, host : "+
			ProActiveInet.getInstance().getHostname()+"\n";
		}
        System.out.println(result);
		return result;
	  }
}
			</programlisting>
			<para>	
			We have implemented the init() function, which have in argument a Java HashMap object 
			containing init parameters, so parameters are available by their names given in the XML descriptor.
			</para>
			
	</sect3>		
</sect2>
<sect2 id="result_passing_mechanism">
	<title>result passing mechanism</title>
	<para>
	Now we will complete our HelloWorld example, we will create a task flow made of two tasks
	(called "Hello1" and "Hello2"), and the second task Hello2, will be executed after the termination
	of the Hello1 task. We will see the mechanism of results passing between two tasks,
	for example the Hello1 task will give a String with its execution date to the Hello2 task.
	</para>
	<sect3 id="task_flow_job_desc">
		<title>XML job description</title>
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>
		<para>			 
		<emphasis role="bold">file : </emphasis>job_HelloWorld.xml
		</para>
		<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/java_job_2_task.xml"></textdata></textobject></programlisting>
		<para>
		The job is made of two tasks. We can see that first task Hello1 hasn't got a precious 
		result anymore, but task Hello2  has it. A task-flow job must have at least one task
		with a preciousResult parameter set true. We can see in Hello2 task description a new Tag
		called <emphasis role="bold">&lt;depends&gt;</emphasis> which specify a list of tasks that have to be executed and terminated before task execution. So here, Hello2 task can be launched only if Hello1 task is terminated.
		</para>
		<para>
		We can see a new parameter in job tag : cancelOnException="false". The job continues even
		if a problem occurred on a task. With this parameter set to true, the whole job is aborted 
		if an error occurs on a task.
		</para>
		<para>
		The two tasks launch the same Java process. Let's complete our HelloTask.java file.
		</para>
</sect3>
<sect3 id="result_passing_task_code">
		<title>Task Code </title>
	<para>
		Complete java code of the task as below :
	</para>
	<para>
			 <emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>src/Extensions/org/objectweb/proactive/extensions/scheduler/examples
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>HelloTask.java
			</para>
			<programlisting lang="java">		
package org.objectweb.proactive.extensions.scheduler.examples;

import java.util.Date;

import org.objectweb.proactive.core.util.ProActiveInet;
import org.objectweb.proactive.extensions.scheduler.common.task.TaskResult;
import org.objectweb.proactive.extensions.scheduler.common.task.executable.JavaExecutable;

public class HelloTask extends JavaExecutable{
	
	public Object execute(TaskResult... results) throws Throwable{
		String predecessor_result=null;
		String result="";

		try{
			//get results of predecessors tasks
			for (TaskResult res : results)
				predecessor_result = ((String)res.value());
			}
			catch (Throwable e){
				   throw new Throwable("getting task input failed",e);
			}

			if(predecessor_result !=null)
				result= "my predecessor has send  : "+ predecessor_result + "\n";

			result+= "HelloWorld task, "+ new Date().toString() + " host : "
			+ProActiveInet.getInstance().getHostname()+"\n";
			System.out.println(result);
			return result;
		  } //execute()
}			
			</programlisting>
			<para>				
			We access to results of predecessor tasks by the TaskResult array in input of execute() primitive. 
			This array have a size corresponding to the number of predecessor tasks defined in the job.
			Each member of this array is a Java Object, and is accessible by the TaskResult.value() primitive.
			</para>
			<para>
			It's interesting to see the "throw Throwable" added to the primitive execute, 
			and the try/catch blocks. When we access to result of the previous task, 
			this result could be result of a task which has failed on its execution. When an error occurs on a task,
			task 's result is a Java Throwable object. That's why we have added a try/catch block for accessing 
			to the TaskResult array, because one these results could be an error. 
			The method which throws a Throwable is TaskResult.value(), you can verify if result is an exception
			by using TaskResult.hadException() method which returns a boolean, set to true if result is an error.
			</para>
			<para>
			So the catch block here is the way to implement what to do when a predecessor task has failed.
			We have chosen here to throw again a Throwable which wrap the first Throwable received.
			</para>
			<para>
			If you don't want to be annoyed with error management, you can just let the "throw Throwable" clause
			in the execute primitive, and suppress the try/catch block. If your access to a value of the TaskResult object
			(input of the primitive) which throws any Throwable, this Throwable will be automatically forwarded to the next tasks.
			</para>
			<para>
			If you set cancelOnException="true" in the XML descriptor of the job, any Throwable (or exception)
			launched by the primitive execute of a task will cancel the whole job.
			</para>				
	</sect3>
</sect2>
-->

<sect2 id="native_job">
	<title>Schedule a native task</title>
	<para>
	ProActive scheduler provides the possibility to launch jobs containing tasks which are native executables,
	like a C/C++ program. Now we will launch a native Unix executable called nativTask, 
	this executable displays ten dots an waits (a number of seconds given in argument) between each dot's display.
	</para>
	<sect3 id="native_c_code">
		<title>Native C code of the task</title>
	<para>
		Complete native C code of the task as below :
	</para>
	<para>
			<emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>descriptors/deployments/scheduler/jobs/job_native_linux
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>nativTask.c
			</para>
			<programlisting lang="c"><textobject><textdata
  						fileref="scheduler/job_descriptors/native_code_c.txt"></textdata></textobject></programlisting>
			<para>	
			You have also an unix compiled version of this program named nativTask in the same directory. Compile the native code above (or take the already compiled version), and place the executable in your <literal>[working_dir]</literal>.		
			Now we need to write an XML file which describes the job.
			</para>
	</sect3>
	<sect3 id="native_job_desc">
		<title>XML job description</title>
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>
		<para>
		In this XML file we specify tasks composing the job, and the "predecessor/successor" orders in tasks. 
		Create a file job_native.xml in your [working_dir], and write the code below :
		</para>
		<para>
		<emphasis role="bold">file : </emphasis>job_native.xml
		</para>
		<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/native_job.xml"></textdata></textobject></programlisting>
		<para>		
		<emphasis role="bold">Job tag :</emphasis>
		</para>
		<para>
		Specifies XML schema related to a job descriptor : schedulerjob.xsd.
		Job has a specified name (here "job_nativ").
		We specify the scheduling priority of the job, there are tree priority levels : lowest, low, normal (for the user, actually there are five levels, 
		but the two other levels, high and highest, can only be setted by scheduler's administrator).
		We specify a log file for the Job. standard and error outputs of All native programs launched are written in this file.
		you can see ${EXE_PATH}, it's a  XML variable, and is explained below. 
		</para>
		<para>		
		<emphasis role="bold">Variables tag :</emphasis>
		</para>
		<para>
		Here we define the directory path variable called “EXEC_PATH”. 
		So we have just to put ${EXEC_PATH} if we want to reuse the string defined by this variable. 
		This a way for not repeating strings and doing changes rapidly. 
		</para>			
		<para>
		<emphasis role="bold">Description tag of the job: </emphasis>
		</para>
		<para>
		A literary description of the job.
		</para>
		<para>
		<emphasis role="bold">Taskflow tag :</emphasis>
		</para>
		<para>
		Specifies that the job is made of tasks that need to be executed in a certain order 
		(This Scheduler tutorial presents only this kind of job).
		</para>
		<para>
		<emphasis role="bold">Task tag :</emphasis>
		</para>
		<para>
		specifies task that compose the job. The task name is used to 
		identify the task from each other in the job, this parameter is mandatory 
		and must be unique for each task in the XML job descriptor. 
		Parameter preciousResult="true" is here to said that the task's result 
		is needed and have to be recoverable at end the of the job.
		We can see in 'task2 task description a Tag
		called <emphasis role="bold">&lt;depends&gt;</emphasis> which specify a list of tasks that have to be executed
		and terminated before task execution. So here, task2 can be launched only if Hello1 task is terminated.
		</para>
		<para>
		<emphasis role="bold">Description tag of the task :</emphasis>
		</para>
		<para>
		A literary description of the task.
		</para>
		<para>
		<emphasis role="bold">nativeExecutable tag :</emphasis>
		</para>
		<para>
		This tag is used in order to specify that task is execution of a native program. 
		This tag have an under tag called staticCommand with a value ;
		the path of executable file to launch. We see here utilization of EXE_PATH variable. 
		We have arguments tag under staticCommand, which permits to give parameters to the executable.
		So that you can specify parameters for execution as if you write parameters in a command line.		
		</para>
		<para>
		Now our job is defined and ready to be scheduled !
		</para>
	</sect3>
</sect2>
<sect2 id="launching">
	<title>Launching the scheduler and submit a job.</title>
	<para>
	Now in this part we will launch scheduler program and submit our job made of two native tasks.
	These actions are performed by scripts in directory :
	</para>
	<para>
	<literal>[ProActive_dir]/scripts/[OS]/scheduler/</literal>
	</para>
	<para>
	(we assume below we are working with a Unix system, but script for windows with .bat extension are available too).
	</para>
		<sect3 id="launch_RM">
		<title>Launching the Resource manager</title>
	Launch Resource manager with script RMlauncher.sh, it takes one argument,the path of an XML file which describes 
	the grid infrastructure on which the Resource Manager (RM) will book resources (nodes) tasks execution. 
	For the moment, launch this script without arguments, so Resource manager will
	launch 4 Java virtual machines (4 nodes) on your computer  (RM deploy by default
	<literal>[ProActive_dir]/descriptors/scheduler/deployment/Local4JVM.xml</literal>) :
	<para>
	<literal>$ RMlauncher.sh</literal>
	</para>
	<para>
	(you must refer to the ProActive documentation at http://proactive.inria.fr/release-doc/html/index.html to have more information about deployment/acquisition of nodes with the ProActive library).
	</para>
	<para>
	You can see on the standard output that RMlauncher.sh have created Resource Manager service at the URL :
	</para>
	<para>
		<literal>//localhost/RMCORE</literal>
	</para>
	</sect3>
	<sect3 id="laucnh_sched">
		<title>Launching the scheduler</title>
	<para>
	Type on the same directory (on another console):
	</para>
	<para>
	<literal>$ scheduler.sh //localhost</literal>
	</para>
	<para>
	Parameter of this shell specifies hostname of a running Resource Manager. 
	Type a hostname that has a running RM (if you don't specify an URL for the RM, scheduler creates itself a Resource Manager). 
	This script will launch the scheduler service, and the scheduler will connect 
	to Resource Manager previously launched. You can see in the standard output the line :
	</para>
	<para>
	<literal>[SCHEDULER] Scheduler has just been started !</literal>
	</para>
	</sect3>
	<sect3 id="submission">
		<title>Submitting the job</title>
	<para>
	Last we submit our hello World example :
	</para>
	<para>
		<literal>$ jobLauncher.sh  -j [working_dir]/Job_native.xml -l user1</literal>
	</para>
	<para>
		-j option specifies the xml file specififying the job. -l option specifies the username.
		By default a username "user1" exists and its password is "pwd1". Type password on the command line.
	</para>
	<para>
		This script will submit the job to the scheduler.
	</para>
	<para>
	On the standard output you see a short summary of the job, tasks and relevant parameters. 
	Important parameter is the job's ID, unique identifier of the job in scheduler. 
	This ID will be used for retrieve result of the job.
	If you return to standard output of Scheduler service, you see the main operations of the scheduling ; 
	the new job incoming, node request to Resource Manager, node acquisition, 
	beginning of the job (with its scheduling ID), start and end of the task, and finally end of the job.
	</para>
	</sect3>
	<sect3 id="retrieve_result">
		<title>Retrieving the result</title>
	<para>
	When the scheduling of a job is finished, scheduler stores job's result and wait for the user to retrieve it.
	Now we will retrieve job's result thanks to its ID, launch on scheduler host this command 
	(always in <literal>[ProActive_dir]/scripts/[OS]/scheduler/</literal> directory) :	
	</para>
	<para>
		<literal>$ getResult.sh -l user1</literal> 
	</para>
	<para>
		Type the user1's password, and enter the job ID (displayed in jobLauncher standard output).
		So the job's result is displayed. Here result is just a String :
	</para>
	<para>
	<literal>
	$Job 1 Result =>
         task1 : 0
         task2 : 0
    </literal>
	</para>
	<para>
	You have two return codes of the native programs.
	</para>
	<para>
	You can open the job's log file ; <literal>[working_dir]/nativTask.log </literal>, and see the standard output of our task.
	</para>
	</sect3>		
	<sect3 id="sched_gui">
	<title>Using GUI client application for job submission</title>	
	<para>
		An RCP graphical user interface exists for jobs submition and results consultation. 
		Uncompress the application, go to Scheduler directory of uncompressed files, and launch the program : 
	</para>
	<para>
	<literal> Scheduler $ ./Scheduler 	</literal>
	</para>
	<para>
	You should have a window like this :
	</para>
	<figure id="rcp_startup">
		<title>Scheduler GUI Client on statup</title>
		<mediaobject>
		<imageobject>
		<imagedata align="center"
			fileref="scheduler/pics/tuto/rcp_startup.png" format="png" />
		</imageobject>
	</mediaobject>
	</figure>
	<para>
	Right click to open connection dialog, and fill fields like below :
	</para>
	<figure id="rcp_connect">
		<title>connection window of Scheduler GUI</title>
		<mediaobject>
		<imageobject>
		<imagedata align="center"
			fileref="scheduler/pics/tuto/connect.png" format="png" />
		</imageobject>
	</mediaobject>
	</figure>
	<para>
	Your are correctly connected to the Scheduler. You can see a first 
	glimpse of the Scheduler activity. You have on the top left, list of pending jobs, 
	on the top middle, list of currently running jobs with a progress bar, and on the top right,
	list of finished jobs which are waiting to be retrieved by their submitters.
	</para>
	<para>
	Now Launch again your job developped earlier, 
	right click in a blank area and <emphasis role="bold">choose submit a job : </emphasis> 
	</para>
	<figure id="rcp_submit">
		<title>Context menu</title>
		<mediaobject>
		<imageobject>
		<imagedata align="center"
			fileref="scheduler/pics/tuto/context_menu.png" format="png" />
		</imageobject>
	</mediaobject>
	</figure>
	</sect3>
	<para>
	This action creates a file explorer window, go to your <literal>[working_dir]</literal>,
	and double click on <literal>job_native.xml</literal>. The job is submitted.
	</para>
	<para>
	You can see your job staying in pending jobs area, which corresponds to the waiting queue,
	then your see your job's execution and finally job comes to finished jobs list.
	Execution is also terminated. You can submit several jobs at the same time.
	</para>
	<para>
	If you click on the job line, you have at the bottom right of the interface, 
	a description of the job, its execution time and a brief description. 
	There is also in the task tab, list of tasks composing the jobs. 
	Click on task's line and you will see on tab right below, result obtained by the task.
	</para>
	<para>
	You can right click to your job's line, and select <emphasis role="bold">get job output</emphasis>, 
	then you have at the bottom left a tag containing all standard and error outputs of your job.
	</para>
</sect2>
<sect2 id="add_sel_script">
		<title>Adding a selection script to the task</title>
		<para>
		A very useful functionality is possibility to add a selection script to a task. 
		This selection script provides ability for the scheduler to find and select a node 
		respecting criteria for the good execution of a task. Let's complete our previous nativ
		job example with a verification script, specifying that the executable nativTask must be
		executed on a Unix/Linux system (so must not be executed on a Windows System).
		</para>
		<sect3 id="add_sel_script_xml_code">
		<title>XML job description</title>
		<para>
		Complete your xml job descriptor as below :
		</para>			
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>job_native.xml
		</para>		
		<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/job_native_with_s_script.xml"></textdata></textobject></programlisting>
		<para>
		We can see in the two tasks definitions, after the task's description, 
		there is a new “selection” tag which contains a path to a Javascript file.
		When the task has to be executed, the scheduler launchs this script on nodes,
		and selects a node that has answered "yes" at the execution of this script,
		then executed the task on this node.
		</para>
		</sect3>
		<sect3 id="select_script_js">
		<title>Code of the node selection Javascript</title>
		<para>
		Create in your <literal>[working_dir]</literal> a file as below :
		</para>		
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>check_unix_os.js
		</para>						
			<programlisting lang="java">			
importPackage(java.lang);

if(System.getProperty("os.name").contains("Windows"))
	script_result=false;
else
	script_result=true;
			</programlisting>
		<para>
		There is just one rule to know for verifying scripts creation, script must a have a variable 
		named "script_result", and must have a true or false value at the end of script execution. 
		Node selection mechanism is simple; Scheduler ask to resource manager one or several nodes that verify that script. 
		So Resource Manager will execute this script on its nodes, if after execution, one of its node has script_result variable set to true,
		Resource manager considers that node verifies selection script, and gives the node to scheduler,
		which will execute the task on this node.
		If a node return script_result variable set to false,
		Resource manager will try to provide to scheduler in another node, which validates this selection script.
		</para>				
		</sect3>
		
</sect2>
<sect2 id="pre_post">
<title>PreScript and PostScript</title>
		<para>
		Another functionality is possibility to define pre and post scripts.
		For a given task (Java task or native task), it is possible to launch a script before
		and after its execution. This possibility can be useful to copy files to a node,
		or clean a directory before or after task execution, for example. This a way to separate from business code the preparation of execution environment and its cleaning. Here an XML sample of a task defining preTask and postTask scripts. So we will add to our native job example a script which remove a list of files from a specified directory.
		</para>
		<sect3 id="pre_post_script_xml_code">
		<title>XML job description</title>
		<para>
		Complete your xml job descriptor as below :
		</para>	
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>job_native.xml
		</para>		
				<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/pre_post_script.xml"></textdata></textobject>	
		</programlisting>
		</sect3>
		<sect3 id="pre_post_script_xml_code">
		<title>code of the removing files Javascript</title>
		<para>
		Create in your <literal>[working_dir]</literal> a file as below :
		</para>		
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>remove_files.js
		</para>						
			<programlisting lang="java">			
importPackage(java.io);
print("clean working directory \n");
for(i=0; i&lt;args.length;i++)
{
	var f= new File(args[i]);
	if(f["delete"]()) {
		print(args[i] +" deleted\n");
	} else {
		print("deleting "+ args[i] +" failed\n");
        }
}
			</programlisting>
		<para>
		So create in your [working_dir] 1.tmp and 2.tmp, and execute the job.
		You will see that 1.tmp is removed just  before task starting, and 2.tmp is removed at task's end.
		</para>					
		</sect3>
</sect2>
<sect2 id="command_generator">
	<title>Command generator Script</title>
	<para>
	We have seen that a native task can be launched by the scheduler on different operating systems, 
	unix or Windows for example. That's because Resource Manager can handle nodes from different computer
	architectures. We have seen the possibility to select nodes compatible with the native task to execute.
	But we can also adapt the native command to execute, corresponding to the node that Resource manager has provided.
	 ProActive Scheduler has possibility to generate dynamically the native command to launch for a task. 
	 This functionality is practical if you have versions of your native program for different OS,
	 or different versions of the native executable, optimized for dynamic libraries which differ from a host to another.
	</para>
	<para>
	Now we develop a job with a task able to launch our native executable “nativTask” on windows system or 
	on a UNIX system. First compile and build nativTask.c on a windows system in order to have a Windows specific 
	version. Let's implement a task with a command generator.
	</para>
		<sect3 id="cmd_generator_code">
		<title>XML job description</title>
		<para>
		Complete your xml job descriptor as below :
		</para>	
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>job_native.xml
		</para>	
			<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/command_generator.xml"></textdata></textobject></programlisting>
		</sect3>
		<sect3 id="cmd_generator_code">
		<title>Code of the command generator script</title>
		<para>
		Create in your <literal>[working_dir]</literal> a file as below :
		</para>		
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>commandGenerator.js
		</para>				
			<programlisting lang="java">
importPackage(java.lang);

if(System.getProperty("os.name").contains("Windows"))
command="c:\nativTask.exe"
else
command="[working_dir]/nativTask"
		</programlisting>
		<para>
		The script get the OS type, a build a command corresponding to the OS type.
		A generation script must define a variable named “command” which contains the native 
		command to execute. That's the only rule to know. After scheduler will get this variable
		and execute the native command defined by the Javascript.
		</para>					
		</sect3>
</sect2>

<sect2 id="tasks_env_var">
	<title>Using exported environment variables</title>
	<para>
	We have seen that each job have a  specified name in its deployment descriptor and a unique job ID given at the moment of job's submission.
	All tasks have these two same parameters specifid at the same time. You can acces to these values in task's execution environment, during task's execution.
	When a native task is launched, the task have also 4 exported environment variables :
	<itemizedlist>
		<listitem>
			<emphasis role="bold">$PAS_JOB_NAME</emphasis>: Job's name defined in its XML descriptor
		</listitem>
		<listitem>
			<emphasis role="bold">$PAS_JOB_ID</emphasis>: unique job's ID given at submission time.
		</listitem>
		<listitem>			
			<emphasis role="bold">$PAS_TASK_NAME</emphasis>: name of the task currently launched (name defined in XML descriptor).
		</listitem>
		<listitem>			
			<emphasis role="bold">$PAS_TASK_ID</emphasis>: unique task's ID.
		</listitem>
	</itemizedlist>
	</para>
	<para>
	Now we will submit a native executable which produces a file in output.
	We want to launch in parallel 4 execution of a native c executable, which takes an integer in parameter, 
	and produces a file named output.txt in its current (launching) directory. 
	If we launch simultaneously several executions instances, it will produce a collision in file output, because the different execution instances 
	will create and write into the same file in the same directory. We don't want to be annoyed by creation of
	directories for each execution instance, So this job provides a launcher.sh Unix shell which performs
	these operations automatically. launcher.sh creates before launching the executable, a temporary  dir for each task,
	its name corresponds to current task's ID environment exported variable. So this job is made of a XMl job descriptor, a native executable,
	and shell script which performs the launching.
	</para>
	<sect3 id="xml_file_output">
		<title>XML job description</title>
		<para>
		Create a new  xml job descriptor,and complete as below :
		</para>	
		<para>
		<emphasis role="bold">directory : </emphasis><literal>[working_dir]</literal>.
		</para>		
		<para>			 
		<emphasis role="bold">file : </emphasis>job_file_output.xml
		</para>	
			<programlisting lang="xml"><textobject><textdata fileref="scheduler/job_descriptors/job_file_output.xml"></textdata></textobject></programlisting>
	</sect3>
	<sect3 id="native_c_code">
		<title>Native C code of the executable which produces an output file</title>
	<para>
		Create your native C executable with the code below :
	</para>
	<para>
			<emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>descriptors/deployments/scheduler/jobs/job_native_linux_file_output
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>nativTask.c
			</para>
			<programlisting lang="c"><textobject><textdata
  						fileref="scheduler/job_descriptors/file_output_exe.txt"></textdata></textobject></programlisting>
			<para>	
			You have also an unix compiled version of this program, named task_with_output, in the same directory.
			</para>
	</sect3>
	<sect3 id="native_c_code">
		<title>Launching shell script</title>
	<para>
			finally write your launching Shell : 
	</para>
	<para>
			<emphasis role="bold">project : </emphasis>ProActive
			</para>
			<para>			 
			 <emphasis role="bold">directory : </emphasis>descriptors/deployments/scheduler/jobs/job_native_linux_file_output
			</para>
			<para>			 
			 <emphasis role="bold">file : </emphasis>launcher.sh
			</para>
			<programlisting lang="c"><textobject><textdata
  						fileref="scheduler/job_descriptors/launcher_sh.txt"></textdata></textobject></programlisting>
			<para>
			Copy your compiled executable (task_with_output) and your launching shell script, and submit this job.
			You will see, after job's execution, 4 directories created in your <literal>[working_dir]</literal> named by the 4 tasks ID of youtr execution,
			and directories contains a file, output.txt, corresponding to outputs of the 4 execution instances launched by the job.
			</para>
	</sect3>	
</sect2>
</sect1>
</chapter>
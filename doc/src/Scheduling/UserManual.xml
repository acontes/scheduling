<?xml version="1.0" encoding="utf-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0" xml:id="user_manual"><info><title>User guide</title></info>
	<section xml:id="Create_job"><info><title>Create a job</title></info>
		<para>
			A job is the entity that will be submitted to the ProActive Scheduler. As it has been explained in the <xref linkend="what_is_job"/>, it is currently possible to create one type of job. A job can be created using an XML descriptor or the provided ProActive Scheduler Java API or also with a simple flat file.
		</para>
		<section xml:id="Create_job_xml"><info><title>Job XML descriptor</title></info>
			<para>
			The  Job  XML descriptor is created
			following the schema given in appendix (<xref linkend="XSDJobSchema" />).
			</para>
			<para>
				Several parameters can be set for a job:
				<itemizedlist>
					<listitem>
						<para>
							<emphasis>name</emphasis> - name of the job.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>projectName</emphasis> (optional) - name of the project.
							This information provide a way to gather different jobs.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>priority</emphasis> (optional - normal by default) - scheduling priority level of the job.
							A user can only set the priority of his jobs and can only use the values 'lowest', 'low', or 'normal'.
							There are two higher priority levels
							'high' and 'highest' which can be only set by the administrator.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>cancelJobOnError</emphasis> (optional - false by default) - defines whether
							the job must continue when a user exception or
							error occurs during the job process.
							This property can also be defined in each task.
							If the value of this property is defined at the job level, each cancelJobOnError property of each task
							will have this value as the default one (excepted if this property has been set at the task level).
							'True' implies for the job to immediately stop every remaining running tasks if an error occurs in one of
							the tasks. It is useful when there is no need to go further after a task failure.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>restartTaskOnError</emphasis> (optional - anywhere by default) - defines whether tasks that have to be restarted
							will restart on an other resource.
							Defining this property will set the restartTaskOnError property of each task
							to this value as the default one (excepted if this property has been set at the task level).
							Possible values are 'anywhere' or 'elsewhere' meaning respectively
							that the concerned task will be restart on any available resources or especially on a different one.
							A task can be restarted when an exception occurred (Java Task) or an error code is returned (Native Task).
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>maxNumberOfExecution</emphasis> (optional - 1 by default) - defines how many times tasks are allowed to be restarted.
							Defining this property will set the nbMaxOfExecution property of each task to this value as the default one
							(excepted if this property has been set at the task level).
							The value has to be a non-negative and non-null integer.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>logFile</emphasis> (optional) - path of a log file.
							Set it if you want to save the job generated logs (STDOUT and STDERR) in a file.
							<emphasis>As this file is created and filled by the scheduler server, the path must be
							also reachable from the scheduler server (not only from the client).</emphasis>
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>variables</emphasis> (optional) - variables which can be reused throughout the descriptor file.
							Inside this tag, each variable can be reused (even in another following variable definition)
							by using the syntax ${name_of_variable}.
							Note that you can also refer to variables defined in the JVM properties.
							For instance, if the JVM that starts the Job parser (JobFactory)
							has been started with the option -Dtoto=helloWorld, the variable ${toto} in the XML descriptor file would have 'helloWorld' as value.
							This way is not commonly used but can be very useful to manage your relative path.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>description</emphasis> (optional) - human readable description of the job.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>genericInformation</emphasis> (optional) - defines some information inside your job.
							These information can be read by the policy of the Scheduler and can be used
							to modify the scheduling behavior. As an example, the administrator can set the policy
							to be influenced by this information.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>jobClasspath</emphasis> (optional) - equivalent to the Java classpath.
							All classes in this path can be loaded by
							Java tasks contained in this job. The jobClasspath can either contain class directories or jar files.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>inputSpace</emphasis> (optional) - URL that defines the INPUT space of the job.
							The INPUT space URL represents an abstract (or real) link to a real dataSpace.
							It is used for data transfer and offers a way to get files to be computed
							on the task execution side. (see <xref linkend="Dataspace" /> for details)
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>outputSpace</emphasis> (optional) - URL that define the OUTPUT space of the job.
							The OUTPUT space URL represents an abstract (or real) link to a real dataSpace.
							It is used for data transfer and offers a way to put produced files from the task
							execution side to this OUTPUT space. (see <xref linkend="Dataspace" /> for details)
						</para>
					</listitem>
				</itemizedlist>
			</para>
				<warning><para> The jobClasspath mechanism relies on the file transfer. The size of the jobClasspath
				files therefore has an impact on performances, especially on the time spent on submitting jobs.</para></warning>

			<para>Here is an example of a job descriptor:</para>

			<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/job.xml"/></textobject></programlisting>

			<para>This example does not contain the job type definition. We detail the job type definition in the next sections.</para>
			<para>
				To create a TaskFlow Job, please refer to the next part.
			</para>
		</section>

		<section xml:id="Create_TaskFlow_job_xml"><info><title>Create a Task Flow job using an XML descriptor</title></info>
			<para>
				A Task Flow job is a job that can
				contain one or several task(s) with optional dependencies.
				To specify that a job is a Task Flow Job, you have to add the 'taskFlow' tag.
				The previous would therefore be written as follows:
			</para>
			<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/taskFlow_job.xml" /></textobject></programlisting>
			<para>
				The creation and addition of tasks is described in <xref linkend="Create_add_task" />.
			</para>
		</section>

		<section xml:id="Create_TaskFlow_job_java"><info><title>Create a Task Flow job using the Java API</title></info>
			<para>
				To make a new instance of a TaskFlow job, you have to create a new
				<code>TaskFlowJob</code> object:
			</para>
			<programlisting language="java"> <textobject><textdata fileref="automatic_snippets/task_flow_job_creation.snip" /></textobject></programlisting>
		</section>

		<section xml:id="Parameters_job_java"><info><title>Set job parameters using the Java API</title></info>
			<para>
				Job parameters created through the Java API are identical to those created through
				XML files (see <xref linkend="Create_job_xml"/>).
				The example below creates a TaskFlow job using the Java Scheduler API and sets some parameters for the job:
			</para>
<!--			<programlisting language="java"><textobject><textdata fileref="automatic_snippets/taskflow_params.snip"/></textobject></programlisting>-->
			<programlisting language="java">
TaskFlowJob job = new TaskFlowJob();
job.setName("job name");
job.setPriority(JobPriority.NORMAL);
job.setCancelJobOnError(false);
job.setLogFile("path/to/a/log/file.log");
job.setDescription("Job description");
job.addGenericInformation("var1","val1");
job.addGenericInformation("var2","val2");
JobEnvironment je = new JobEnvironment();
je.setJobClasspath(new String[]{"/path/to/my/classes/","/path/to/my/jarfile.jar"});
job.setEnv(je);
			</programlisting>
			<para>
				To create and add tasks to your job, please refer to <xref linkend="Create_add_task"/>.
			</para>
		</section>

		<section xml:id="flat_file_job"><info><title>Create a job from a simple flat file</title></info>
			<para> ProActive Scheduler provides a way to define a job with a simple plain text file. This method is simpler than an XML file but presents less features.
			</para>
			<para>
			If you just need to launch a set of native tasks in parallel, <emphasis>without dependancies between tasks</emphasis>, you can create a simple text file
			and write a list of native commands to submit:
			</para>
			<programlisting language="sh">
# a flat text file containing native commands to launch
# one command per line
#
# One rule to know:
# command paths must be absolute paths

/path/to/my/exec/myCmd.sh 1
/path/to/my/exec/myCmd.sh 2
/path/to/my/exec/myCmd.sh 3
/path/to/my/exec/myCmd.sh 4
			</programlisting>
			<para>
			This file represents a job made of 4 native tasks, i.e. 4 native commands to launch. Each line beginning with a '#' is a comment, and is not taken into account.
			You have to put one native command per line, and commands must be absolute paths. Contrary to a job definition in XML, you cannot specify any dependencies between tasks.
			This job definition is useful for embarrassingly parallel jobs. Many features of job are not available at creation time, but can be specified at submission time: log file, job name, and selection scripts.
			</para>
			<para>
			To see how to submit this kind of job descriptor, see <xref linkend="Submit_a_job_sh" />.
			</para>
		</section>
	</section>
	<section xml:id="Create_add_task"><info><title>Create and add a task to a job</title></info>
		<para>
			As it has been said, it is possible to create 3 types of tasks. Native and
			Java tasks can be add to TaskFlow Job, and one ProActive Task to one ProActive Job.
		</para>
		<section xml:id="Create_java_task"><info><title>Create and add a Java task</title></info>
			<para>
				<emphasis>Note</emphasis> : A java task can only be added to a TaskFlow Job.
			</para>
			<para>
				To learn how to create a TaskFlow job,
				pleas refer to <xref linkend="Create_TaskFlow_job_xml"/> or <xref linkend="Create_TaskFlow_job_java"/>.
				Once your TaskFlow job created, you can add as many Java tasks as needed to perform an application.
			</para>
			<section xml:id="define_executable_java"><info><title>Define your own Java executable</title></info>
				<para>
					You can create your own java executable by implementing scheduler executable interfaces.
					In this sens, 'executable' means the executed process (that is a Java class in this case).
					Here is an example on how to create your own Java executable:
				</para>
				<programlisting language="java">
public class WaitAndPrint extends JavaExecutable {

	@Override
	public Serializable execute(TaskResult... results) throws Throwable {
		String message;

		try {
			System.err.println("Démarrage de la tache WaitAndPrint");
			System.out.println("Parameters are : ");

			for (TaskResult tRes : results) {
				if (tRes.hadException()) {
					System.out.println("\t " + tRes.getTaskId() + " : " + tRes.getException().getMessage());
				} else {
					System.out.println("\t " + tRes.getTaskId() + ": " + tRes.value());
				}
			}

			message = URIBuilder.getLocalAddress().toString();
			Thread.sleep(10000);

		} catch (Exception e) {
			message = "crashed";
			e.printStackTrace();
		}

		System.out.println("Task terminated");

		return (message + "\t slept for 10 sec");
	}
}
				</programlisting>
				<para>
					This executable will print an initial message, then check if there are results from previous tasks
					and if so, print the value of these "parameters". It will then return a message
					containing what the task did. The return value will be store in the job result.
				</para>
				<para>
					It is also possible to get a list of arguments that you can give to the executable at its start by
					overriding the init method on a Java executable. The way to give arguments to the task will be explain
					later.
					Let's see how you can give a foo, a bar and a test argument to the previous example:
					<programlisting language="java">
private boolean foo;
private int bar;
private String test;

@Override
public void init(Map&lt;String, Serializable&gt; args) {
	foo = (Boolean)args.get("foo");
	bar = (Integer)args.get("bar");
	test = args.get("test");
}
					</programlisting>
				</para>
				<para>
					The previous code is given as an example. The default behavior of the init() method is to associate declared
					Java variables to their value, assuming that the variable names given in arguments (in the map) are the same as the Java declared ones.
					Thus, The following code behaves exactly like the previous one :
					<programlisting language="java">
private boolean foo;
private int bar;
private String test;

//1
@Override
public void init(Map&lt;String, Serializable&gt; args) {
	super.init(args);
}
//2
//commenting from 1 to 2 is also the same of course
					</programlisting>
				</para>
				<para>
					To sum up, create an executable is just extending the <code>JavaExecutable</code> abstract class, and filling
					the execute method. The given <code>TaskResult... results</code> argument enables to get the results from
					previous dependent tasks that have finished their execution.
				</para>
				<para>
					As shown in the following lines, the given array of TaskResults (<emphasis>results</emphasis>)
					will be an array of two results (TaskResult 2 and 3) in this order
					if the dependences of Task 5 is Task 2 and Task 3 in this order.
					Therefore you can use them to perform Task 5 process.
					<programlisting language="java">
@Override
public Serializable execute(TaskResult... results) throws Throwable {
	//TaskResult
	tResult2 = results[0];
	//TaskResult
	tResult3 = results[1];
	//...
}
					</programlisting>
				</para>
				<para>
					Finally, overriding the <code>init()</code> method can be useful if you want to retrieve personal arguments or do some
					operations before starting the real execution of the task.
				</para>
				<para>
					Moreover, the <code>getNodes()</code> method retrieves the list of nodes define in the description of the task.
					It is a way to make MPI or ProActive application on the given resources.
					Here's an example of a ProActive application made in a multi-nodes <code>JavaExecutable</code> :
				</para>
				<programlisting language="java">
public class ProActiveExample extends JavaExecutable {

	private int numberToFind = 5003;

	@Override
    public Serializable execute(TaskResult... results) {
        System.out.println("Multi-node started !!");

        ArrayList&lt;Node&gt; nodes = getNodes();

        // create workers (on local node)
        Vector&lt;Worker&gt; workers = new Vector&lt;Worker&gt;();

        for (Node node : nodes) {
            try {
                Worker w = (Worker) PAActiveObject.newActive(Worker.class.getName(), new Object[] {}, node);
                workers.add(w);
            } catch (ActiveObjectCreationException e) {
                e.printStackTrace();
            } catch (NodeException e) {
                e.printStackTrace();
            }
        }

        // create controller
        Controller controller = new Controller(workers);
        int result = controller.findNthPrimeNumber(numberToFind);

        System.out.println("last prime : " + result);

        return result;
    }

    private class Controller {
        // Managed workers
        private Vector&lt;Worker&gt; workers;

        /**
         * Create a new instance of Controller.
         *
         * @param workers
         */
        public Controller(Vector&lt;Worker&gt; workers) {
            this.workers = workers;
        }

        // start computation
        /**
         * Find the Nth prime number.
         *
         * @param nth the prime number to find
         * @return the Nth prime number.
         */
        public int findNthPrimeNumber(int nth) {
            long startTime = System.currentTimeMillis();
            BooleanWrapper flase = new BooleanWrapper(false);
            int found = 0;
            int n = 2;

            while (found &lt; nth) {
                Vector&lt;BooleanWrapper&gt; answers = new Vector&lt;BooleanWrapper&gt;();

                // send requests
                for (Worker worker : workers) {
                    BooleanWrapper resp = worker.isPrime(n);
                    answers.add(resp);
                }

                PAFuture.waitForAll(answers);

                if (!answers.contains(flase)) {
                    workers.get(found % workers.size()).addPrimeNumber(n);
                    System.out.println("---&gt;" + n);
                    found++;
                }

                n++;
            }

            long stopTime = System.currentTimeMillis();
            System.out.println("Total time (ms) " + (stopTime - startTime));

            return n - 1;
        }
    }

}
				</programlisting>
			</section>

			<section xml:id="Create_java_task_xml"><info><title>Create and add a Java task using an XML descriptor</title></info>
					<para>
						The task is the entity that will be scheduled by ProActive Scheduler.
						As it has been explained in <xref linkend="what_is_task"/>,
						it's possible to create and add Java tasks to your TaskFlow Job.
						A Java task can either be created using an XML descriptor or using the provided ProActive Scheduler Java API.
						This section deals with the creation of a task and its addition to a job.
					</para>
				<para>
					Take a look at the following example to understand the syntax of a task:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/java_task_simple.xml"/></textobject></programlisting>
				<para>
					The Java task is composed of a 'javaExecutable' tag which specifies the Java executable class to be used.
					A set of parameters can also be defined as it has been done for this example. These parameters will be
					available into the <code>Map</code> of the <code>init(Map)</code> method into your <code>JavaExecutable</code>.
					This example also shows the definition of two tasks with dependencies. We can easily see that 'task 2' depends on
					'task 1'. So 'task 2' will be executed only once 'task 1' has finished.
					To put these two tasks inside your TaskFlow job, just put it between the 'taskFlow' tags.
					You may also notice that the 'task 2' will use 3 nodes to be started. So the 'task 2' have to wait for
					'task 1' to be terminated and 3 available nodes.
					Here is a complete ready-to-be-scheduled TaskFlow job:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/taskFlow_job_complete.xml"/></textobject></programlisting>
				<para>
					It is obviously possible to mix Java (with one or more nodes) and Native task inside a taskFlow Job.
					Some other parameters and options can be set into a Java task. The two following examples expose some of them:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/java_task_script.xml"/></textobject></programlisting>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/java_task_fork.xml"/></textobject></programlisting>
				<para>
					To have an exhaustive list of available options and theirs functions, please refer to
					the task explanation section (see <xref linkend="Create_task_explanation"/>).
				</para>
			</section>
			<section xml:id="Create_java_task_java"><info><title>Create and add a Java task using the Java API</title></info>
				<para>
					To <emphasis>create a Java task</emphasis>, you first have to instantiate a
					<emphasis>JavaTask</emphasis> object and, then, to specify the class you want to be executed by this task (To make your own executable, please refer to the
					proper section <xref linkend="define_executable_java"/>).
					In addition, you can add arguments with which the task will be launched.
					These launching arguments will be given to the Java executable as a Map.
					Take a look at the example hereafter so as to see how to use the Java API to create a Java task
					(also see the Java Documentation of the Scheduler to learn more):
				</para>
				<programlisting language="java">
//create a Java Task with the default constructor
JavaTask aTask = new JavaTask();
//add executable class or instance
aTask.setExecutableClassName("org.ow2.proactive.scheduler.examples.WaitAndPrint");
//then, set the desired options
aTask.setName("task 1");
aTask.setDescription("This task will do something...");
aTask.addGenericInformation("key","value");
aTask.setMxNumberOfExecution(3);
aTask.setRestartTaskOnError(RestartMode.ELSEWHERE);
aTask.setCancelJobOnError(false);
aTask.setResultPreview(UserDefinedResultPreview.class);
//add arguments (optional)
aTask.addArgument("foo",new Boolean(true));
aTask.addArgument("bar",new Integer(12));
aTask.addArgument("test","test1");

//SCRIPTS EXAMPLE
//If the script to use is in a file or URL
String[] args = new String("foo","bar");
File scriptFile = new File("path/to/script_file");
//URL scriptURL = new URL("url/to/script_file");
Script script = new SimpleScript(scriptFile, args);
// Script script = new SimpleScript(scriptURL, args);
aTask.setPreScript(script);
//If the script to use is in a Java string for example
Script script = new SimpleScript("Script_content", "type_of_language");
//where type_of_language can be any language supported by the underlying JRE
aTask.setPreScript(script);

//same construction for the post script
aTask.setPostScript(script);

//same construction for the cleaning script
aTask.setCleaningScript(script);

//same construction for the  selection script
//the last parameter is still not used in the current implementation
SelectionScript selScript = new SelectionScript(script, true);
aTask.setSelectionScript(selScript);
				</programlisting>
				<para>
					Once this done, you still have to add your task to your job:
				</para>
				<programlisting language="java">
//add the task to the job
job.addTask(aTask);
				</programlisting>
				<para>
					Here are some other features than can be performed on tasks such as dependencies or wallTime :
				</para>
				<programlisting language="java">
//admitting task 2 and task 3 has been create just before
//we have to create task 5.
//create a new task
JavaTask task5 = new JavaTask();
//... (fill task5 as described above)
//then specify dependencies by using the addDependence(Task) method
task5.addDependence(task2);
task5.addDependence(task3);
//or use the addDependences(list&lt;Task&gt;) method as shown
//task5.addDependences(new ArrayList&lt;Task&gt;(task2,task3));

//set this task as forked
aTask.setFork(true);
//set a walltime
aTask.setWallTime(10000);
//you can also define a fork environment
ForkEnvironment env = new ForkEnvironment();
env.setJavaHome("Your/java/home/path");
env.setJVMParameters("-d12");
aTask.setForkEnvironment(env);
				</programlisting>
				<para>
					If the fork attribute is 'true', the java executable will be started on a brand new JVM
					with new environment. If fork remains unset and a walltime is define, so the task will
					automatically be forked. This allows the Scehduler to kill the java process at the end of walltime.
				</para>
				<para>
					To have an exhaustive list of available options and theirs functions, please refer to
					the task explanation section (see <xref linkend="Create_task_explanation"/>).
				</para>
			</section>
		</section>

		<section xml:id="Create_native_task"><info><title>Create and add a native task</title></info>
			<para>
				<emphasis>Note</emphasis>: A native task can only be added to a TaskFlow Job.
			</para>
			<para>
				To learn how to create a TaskFlow Job,
				please refer to <xref linkend="Create_TaskFlow_job_xml"/> or <xref linkend="Create_TaskFlow_job_java"/>.
				Once your TaskFlow Job has been created, you can add as many native tasks as needed to perform your application.
				A native task can be any native application such as programs, scripts, processes...
			</para>
			<section xml:id="Create_native_task_xml"><info><title>Create and add a native task using an XML descriptor</title></info>
				<para>
					Take a look at the following example to understand the syntax of a native task:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/native_task_simple.xml"/></textobject></programlisting>
				<para>
					The native task is composed of one 'nativeExecutable' tag that specified the executable process to use.
					A set of parameters has also be defined to provide the executable with some arguments. These arguments will be
					appended (according to the Runtime.exec() method) to the command line starting by your native executable.
					This example also shows the definition of two tasks with dependencies. We can easily see that 'task2_native' depends on
					'task1_native'. So 'task2_native' will be executed only once 'task1_native' has finished.
					To put these two tasks inside your TaskFlow job, just put that piece of code into 'taskFlow' tags.
					Here is a complete ready-to-be-scheduled TaskFlow Job:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/taskFlow_job_complete_with_native.xml"/></textobject></programlisting>
				<para>
					To have an exhaustive list of available options and theirs functions, please refer to
					the task explanation section (see <xref linkend="Create_task_explanation"/>).
				</para>
				<para>
					As it has been said in <xref linkend="Create_java_task_xml"/>, it is possible to mix Java and Native task inside a taskFlow Job.
					Please refer to this section for more information.
				</para>
			</section>
			<section xml:id="Create_native_task_java"><info><title>Create and add a native task using the Java API</title></info>
				<para>
					To <emphasis>create a native task</emphasis>, you first have to instantiate a
					<emphasis>NativeTask</emphasis> object and, then, to specify the command corresponding to
					your native task. This command is actually a String array whose first element is the path to the command
					and the following ones represent its arguments.
					Take a look at the following example to see how to create a native task using the Java API
					(see also Java Documentation of the ProActive Scheduler to learn more):
				</para>
				<programlisting language="java">
//create a native task with the default constructor
NativeTask aTask = new NativeTask();
//set the command line with its parameters
aTask.setCommandLine(new String[]{"/path/to/command/cmd","param1","param2");
//then, set the desired options:
aTask.setName("task 1");
aTask.setDescription("This task will do
something...");
aTask.addGenericInformation("key","value");
aTask.setPreciousResult(true);
aTask.setMaxNumberOfExecution(3);
aTask.setRestartTaskOnError(RestartMode.ELSEWHERE);
aTask.setResultPreview(UserDefinedResultPreview.class);

//SCRIPTS EXAMPLE
//If the script to use is in a file or URL
String[] args = new String("foo","bar");
File scriptFile = new File("path/to/script_file");
//URL scriptURL = new URL("url/to/script_file");
Script script = new SimpleScript(scriptFile, args);
// Script script = new SimpleScript(scriptURL, args);
aTask.setPreScript(script);
//If the script to use is in a Java string for example
Script script = new SimpleScript("Script_content", "type_of_language");
//where type_of_language can be any language supported by the underlying JRE
aTask.setPreScript(script);

//same construction for the post script
aTask.setPostScript(script);

//same construction for the cleaning script
aTask.setCleaningScript(script);

//same construction for the  selection script
//the last parameter is used to specified whether the script is static
//or dynamic
SelectionScript selScript = new SelectionScript(script, true);
aTask.setSelectionScript(selScript);
				</programlisting>
				<para>
					Once this done, you still have to add your task to your job:
				</para>
				<programlisting language="java">
//add the task to the job
job.addTask(aTask);
				</programlisting>
				<para>
					Here are some other features than can be performed on tasks such as dependencies or wallTime :
				</para>
				<programlisting language="java">
//admitting task 2 and task 3 has been create just before
//we have to create task 5.
//create a new task
NativeTask task5 = new NativeTask();
//... (fill task5 as describe above)
//then specify dependencies by using the addDependence(Task) method
task5.addDependence(task2);
task5.addDependence(task3);
//or use the addDependences(list&lt;Task&gt;) method as shown
//task5.addDependences(new ArrayList&lt;Task&gt;(task2,task3));

//set a walltime to stop the process after the given time even it is not finish
aTask.setWallTime(10000);
				</programlisting>
				<para>
					Here is a last example that describes how to create a native task with a
					<emphasis>dynamic command</emphasis>, that is, a command generated by a script called a
					generation script. The generation script can only be associated to a
					<emphasis>native</emphasis> task: the execution of a generation
					script must set the string variable <literal>command</literal>.
					The value of this variable is the command line that will be executed by
					the ProActive Scheduler as a task execution. The returned string will be parsed
					and transform as a String array according to this example ( '%' is the escape character ):
					<itemizedlist>
						<listitem><para>the string "/path/to/cmd arg1 arg 2 arg% 3 arg%%% 4 5"</para></listitem>
						<listitem><para>will generate : [/path/to/cmd,arg1,arg,2,arg 3,arg% 4,5]</para></listitem>
					</itemizedlist>
					where the first element is the command.
				</para>
				<programlisting language="java">
//create a new native task
NativeTask task2 = new NativeTask();
//create a generation script with a script as shown above
GenerationScript gscript = new GenerationScript(script);
//set the command to execute as a string
task2.setGenerationScript(gscript);
				</programlisting>
				<para>
					To have an exhaustive list of available options and theirs functions, please refer to
					the task explanation section (see <xref linkend="Create_task_explanation"/>).
				</para>
			</section>
		</section>

		<section xml:id="Create_task_explanation"><info><title>Tasks options and explanations</title></info>
				<para>
					As it has been shown in the different examples, it is possible to create 2 types of tasks.
					These 2 types have some common features like name, description, scripts and so on.
					Here are details on each of these common features:
				</para>
				<itemizedlist>
					<listitem>
						<para>
							<emphasis>name</emphasis> -
							name of the task.
							It can be whatever you want.
							This name must be unique.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>description</emphasis> (optional) -
							human readable description of the task.
							It is for human use only. This field is optional but it is better to set it.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>genericInformation</emphasis> (optional) -
							defines some information inside your task.
							This information could be read inside the policy (similar to job's one).
							It can be useful to add new complex scheduling behavior.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>inputFiles</emphasis> (optional) -
							selects files to be transfered to the task execution side.
							It is possible to add a set of files to be copied from the
							INPUT or OUTPUT space to the worker side. Files can be selected one by one or
							through regular expressions. For each selected files, an access mode specify
							if the files has to be transfered from INPUT, OUTPUT space or if transfer is
							not needed. (see <xref linkend="Dataspace"/> for more details).
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>outputFiles</emphasis> (optional) -
							selects files to be transfered to the OUTPUT space.
							It is possible to add a set of files to be copied from
							the worker side to the OUTPUT space of the job. Files can be selected one by one or
							through regular expressions. For each selected files, an access mode specify
							if the files has to be transfered to OUTPUT space or if no transfer is
							needed. (see <xref linkend="Dataspace"/> for more details).
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>preciousResult</emphasis> (optional - false by default) -
							defines whether a result of a task is important.
							For example, in a job result, you could have to retrieve only some task results that are
							important for you. By setting the precious result option to 'true', you will be able
							to retrieve them easily.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>cancelJobOnError</emphasis> (optional - false by default or set to the cancelJobOnError value of its job) -
							defines whether your job must continue if a user exception or an
							error occurs during this task process.
							True means that the job
							will immediately stop every remaining running tasks if an error occurs in this task.
							It is useful when there is no need to go further if this task fails.
							If true, the job will be canceled if the maximum number of execution for this task has been reached.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>maxNumberOfExecution</emphasis> (optional - 1 by default or set to the maxNumberOfExecution value of its job) -
							defines how many times a task will run if it ends with an exception
							or an error code.
							If the task ends in a normal way, this property has no effect.
							If the task has an exception or an error more than defined in this property, there are 2 possibilities:
							<itemizedlist>
								<listitem>
									<para>
									cancelJobOnError=true: then, the job is canceled.
									</para>
								</listitem>
								<listitem>
									<para>
									cancelJobOnError=false: then, the task ends and the job continues in a normal way.
									</para>
								</listitem>
							</itemizedlist>
							In Both cases, the result is the representation of the error (Exception in Java, error code in native).
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>restartTaskOnError</emphasis> (optional - anywhere by default or set to the restartTaskOnError value of its job) -
							defines whether this task has to restart on an other resource.
							Possible values are 'anywhere' or 'elsewhere' meaning respectively
							that the concerned task will be restart on any available resources or on a different one.
							A task can be restarted when an exception occurred (Java Task) or when an error code is returned (Native Task) and
							if the maximum number of execution has not been reached yet. Each time an error occurred, the task is placed in
							a Faulty(n/m) status and the numberOfExecutionLeft count is decreased. 'n' is the current number of executions and
							'm' is the maximum number of executions.
						</para>
						<para>
							Here is a table that sum-up the different possible executions, that can be useful to know the behavior of your job :
						</para>
						<para>
							<figure xml:id="cancel_restart"><info><title>CancelJobOnError and RestartTaskOnError behavior</title></info>
								<mediaobject>
									<imageobject>
										<imagedata scalefit="1" width="70%" contentdepth="70%" align="center" fileref="images/png/user_manual/cancel-restart.png" format="PNG"/>
									</imageobject>
								</mediaobject>
							</figure>
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>numberOfNodes</emphasis> (optional, default 1) -
							number of nodes needed by the task.
							<itemizedlist>
								<listitem>
									<para>
										For a java task, one node among the specified number is used to start the task. The other
										are available through the <code>getNodes()</code> method in the java executable.
										So, if you need 4 nodes to make your application worked, just ask for 5 nodes. (numberOfNodes="5")
									</para>
								</listitem>
								<listitem>
									<para>
										For Native task, every asked nodes are available through environment variables :
										<itemizedlist>
											<listitem>
												<para>
													'PAS_CORE_NB' : contains the number of nodes available for the task.
												</para>
											</listitem>
											<listitem>
												<para>
													'PAS_NODEFILE' : is the path to a file that contains every available nodes URL (one URL by line)
												</para>
											</listitem>
										</itemizedlist>
										Use this environment variable in your own native process to get these informations back.
									</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>Walltime</emphasis> (optional) -
							maximum time for the task execution (timeout).
							It can be specified for any task, irrespectively of its type.
							If a task does not finish before its walltime it is terminated by the ProActive Scheduler.
							An example has been given above with the walltime specified. Note that, the walltime
							is defined in a task, thus it can be used for any type of a task.
							The general format of the walltime attribute is [hh:mm:ss], where h is hour, m is minute and s is second.
							The format still allows for more flexibility. We can define the walltime simply as “5”
							which corresponds to 5 seconds, “10” is 10 seconds, “4:10” is 4 minutes and 10 seconds, and so on.

							The walltime mechanism is started just before a task is launched. If a task does finish before its walltime,
							the mechanism is canceled. Otherwise, the task is terminated. Note that the tasks are terminated without
							any prior notice.

							If the walltime is specified for a Java task (as in the example), it enforces the creation of
							a forked Java task instead.

							When this property is defined and execution exceeds this time, the task ends with an exception.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>fork and forkEnvironment</emphasis> (optional, only for Java Task) -
							defines respectively whether a task has to be forked and if so, defines the fork environment.
							The purpose of a Forked Java Task is to gain more flexibility with
							respect to the execution environment of a task.
							A new JVM is started with an inherited classpath and (possibly) redefined Java home path and JVM properties.
							It allows to use a JVM from a different provider and specify options to be passed to JVM (like memory usage).

							A Forked Java Task is defined as a Java Task with a forkEnvironment element.

							A forkEnvironment element aims at providing javaHome and jvmParameters attributes.
							For any undefined attribute a default environment value will be applied. Note that, the javaHome
							attribute points only to the Java installation directory and not the Java application itself.

							If the javaHome is not specified then the ProActive Scheduler will execute simply a Java command assuming
							that it is defined in the user path. The 'jvmParameters' attribute is a string composed of a sequence
							of Java options separated by spaces.
							See <xref linkend="Create_java_task"/> for an illustration of their usage.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>parameters</emphasis> (optional, only for Java and ProActive Task) -
							defines some parameters to be transfered to the executable.
							This is best explained
							in <xref linkend="define_executable_java"/>. Each parameter is define with a name and a value
							and will be passed to the Java Executable as an <code>Map</code>.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>arguments</emphasis> (optional, only for native Task) -
							defines arguments for your native process.
							Each argument is define by a value
							that will be appended to the process name to create a String array command line.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>resultPreview</emphasis> (optional) -
							allows to specify how the result of a task should be displayed in the
							Scheduler graphical client.
							The user should implement a result preview class
							(extending the
							<literal>
								org.objectweb.proactive.extensions.scheduler.common.task.ResultPreview
							</literal>
							abstract class) which specifies result rendering in two different manners:
						</para>
						<itemizedlist>
							<listitem>
								<para>
									a textual manner, by implementing
									<literal>
										public abstract String getTextualDescription(TaskResult result);
									</literal>.
									This method, similarily to
									<literal>
										String Object.toString()
									</literal>
									should return a <literal>String</literal> object that describes the result.
								</para>
							</listitem>
							<listitem>
								<para>
									a graphical manner, by implementing
									<literal>
										public abstract JPanel getGraphicalDescription(TaskResult result);
									</literal>.
									This method should return a Swing
									<literal>JPanel</literal>
									object that describes the result.
								</para>
							</listitem>
						</itemizedlist>
						<para>
							Some useful methods to create a specific preview class can be found in
							<literal>
								org.objectweb.proactive.extensions.scheduler.common.task.util.ResultPreviewTool
							</literal>,
							such as automatic display of an image file, or automatic translation between
							windows and unix path.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>runAsMe</emphasis> (optional, default is false) -
							specifify if your task must be executed under your user account or not.
							If this property is set to 'true', the node on which it will be executed must be configured
							to accept the fact you can executre a task in your own process. Ask your administrator
							for more details about the behavior of the nodes.
							This property also implies you have a valid system account on the execution targeted node machine and you have made your connection
							to the scheduler using your system password and/or your ssh key if required by the node configuration.
							See <xref linkend="Submit_a_job_java"/> for more details about job submission.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scripts</emphasis> (optional) -
							The ProActive scheduler supports portable script execution through the
							JSR 223 Java Scripting capabilities. Scripts can be written in any language
							supported by the underlying Java Runtime Environment. They are used in the
							ProActive Scheduler to:
						</para>
						<itemizedlist>
							<listitem>
								<para>
									Execute some simple Pre, Post and Cleaning processing: optional pre-script,
									post-script, and cleaning-script
								</para>
							</listitem>
							<listitem>
								<para>
									Select among available resources the node that suits the execution: optional
									selection-script can be associated to a task.
								</para>
							</listitem>
							<listitem>
								<para>
									Dynamic building of a command line for a native task: optional
									generation-script (detailed in next section).
								</para>
							</listitem>
						</itemizedlist>
						<para>
							Here are some details and examples:
						</para>
						<itemizedlist>
							<listitem>
								<para>
									<emphasis>selection script</emphasis> -
									a selection script is always executed before the task itself
									on any candidate node: the execution of a selection script
									must set the boolean variable <literal>selected</literal>
									, that indicates if the candidate node is suitable for
									the execution of the associated task.
									A java helper (org.ow2.proactive.scripting.helper.selection.SelectionUtils)
									is provided for allowing user to simply make some kind of selections.
									(script samples are available in 'samples/scripts/selection' directory.)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>pre-script</emphasis> -
									the pre-script is always executed on the node that has
									been selected by the Resource Manager <emphasis>before</emphasis>
									the execution of the task itself.
									Java helper (org.ow2.proactive.scripting.helper.filetransfer package) is also available
									for file transfer purposes to manage file copies.
									Some script samples are available in 'samples/scripts/filetransfer' directory.
								</para>
								<para>
									Another helper is provided for transmitting Java properties to either forked environment (native
									or forked Java task) or to all dependent tasks, namely the org.ow2.proactive.scripting.helper.PropertyUtils
									class. The exportProperty(String name) method makes the property available in the native environment as a
									system variable (renamed like my.java.property becomes MY_JAVA_PROPERTY). The propagateProperty(String name)
									makes the property available in the java environment as a Java property (not renamed) of all the dependent tasks.
									Note that if several value for a single property a propagated to a single task (i.e. a task with several parents),
									the resulting value is not specified and can be any of the propagated value.

								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>post-script</emphasis>  - the post-script is executed on the same node
									<emphasis>after</emphasis> the task itself in any case.
									A boolean variable named "success" is available in this script in order to
									inform user about the success of the task execution. if success is true, the execution
									has finished successfully, if not, execution has generated an exception.
									The same helpers than for pre-script can be used in the post-script, except the
									org.ow2.proactive.scripting.helper.PropertyUtils.exportProperty(String name) which has no effect
									since no process can be forked after the post-script.
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>cleaning-script</emphasis> - the cleaning-script is always
									executed by the Resource Manager <emphasis>after</emphasis> the execution
									of the task itself or after the post-script (if used).
									The same helper than for pre-script can be used in the cleaning-script.
								</para>
							</listitem>
						</itemizedlist>
						<para>
							For pre, post and cleaning script, you can use the file transfer helper classes. It provides easier
							way to copy, paste, transfer files from a host to another. (Examples are available in
							'samples/scripts/filetransfer' directory)
						</para>
						<para>
							To use your favorite script language, you just have to add the two needed jars (engine and implementation)
							in the nodes, Resources Manager and Scheduler classpath.
						</para>
						<para>
							Note: For any script engine or script implementation used in this package or brought by you,
							you have to notice that:
						</para>
						<para>
							THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS
							OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
							AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
							CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
							DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
							DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
							IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
							OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
						</para>
					</listitem>
				</itemizedlist>
				<para>
					Once your job created, next step is to submit it to the ProActive Scheduler.
				</para>
			</section>
		</section>
		<section xml:id="Dataspace"><info><title>Handling data and files using Data Spaces</title></info>
			<para>
				The Scheduler infrastructure allows user to handle files during the scheduling process.
				Based on the ProActive DataSpace, It is now possible to describe from where to pick files,
				and where to put eventual produced files. This ability supports protocol such as FTP, HTTP, File system,
				and also distributed file System using the ProActive Provider Server. Here is a brief explanation
				around the file handling mechanism:
			</para>
			<figure xml:id="dataspaces"><info><title>Handling data during scheduling</title></info>
				<mediaobject>
					<imageobject>
						<imagedata width="70%" align="center" fileref="images/png/user_manual/dataspace.png" format="PNG"/>
					</imageobject>
				</mediaobject>
			</figure>
			<para>
				The Scheduler (0) is always connected to default INPUT(1) and OUTPUT(6) spaces, defined by the administrator or in you own job.
				INPUT space (read-only) is used to store every files and data needed by a job. Each task should be able to
				read and/or write data in the OUTPUT space (read-write).
				As there are default INPUT/OUTPUT spaces, users can also define theirs own data spaces by specifying them
				in the job descriptor. User can define INPUT and/or OUTPUT spaces. If a space is not defined,
				the default one is used.
			</para>
			<para>
				As an example and as shown in the image above, an Executable (5) can get files (2) from the INPUT
				space (1). Once files are located in the LOCAL space, Executable can read and write from/to
				the LOCAL space. At the end of the task, files will be sent (9) to the OUTPUT (8) FTP space.
				An other task could read (3) the default OUTPUT space (6), while another could write (4) to
				the same space (6). Users has to take care about concurrent access in the OUTPUT space.
			</para>
			<para>
				If using the default spaces, user's data has to be stored into a directory named as his login. This directory will
				be the root of the space. Ask your administrator if you cannot locate the default targeted spaces.
			</para>
			<para>
			  OUTPUT and INPUT are configured by the user that submits the job, or when not specified by the user, by the Scheduler administrator.
			  Each job execution has an unique INPUT and OUTPUT definition.
			  In addition to these, the GLOBAL space is an input/output space that is always configured by the Scheduler administrator,
			  and is accessible by all nodes. The GLOBAL space can be used as a intermediary storage available for all nodes that is
			  cheaper to acces than the OUTPUT space.
			</para>
			<para>
			  GLOBAL space has to be set by the Scheduler administrator through the <emphasis>pa.scheduler.dataspace.globalurl</emphasis> property.
			  The value to use needs to be an URL to a writable space: ie file:/example.com/ or ftp:/example.com/ (HTTP cannot be used as it is read only).
			</para>
			<para>
				Let's continue with an example of use through a job containing a native task and a Java task.
			</para>
			<section xml:id="Dataspace_job"><info><title>Using data spaces in a job</title></info>
				<para>
					A job can define INPUT and/or OUTPUT spaces. To set up a space in the XML descriptor,
					just proceed as follows:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/job_dataspace.xml"/></textobject></programlisting>
				<para>
					This example shows how to define both INPUT and OUTPUT spaces. The INPUT space is defined on a HTTP server whereas
					the OUTPUT one is defined on a remote file system provided by the ProActive data server.
					The only constraint to take care about is to be sure that the OUTPUT space is a writable space.
					(for example, it cannot be HTTP protocol).
				</para>
				<para>
					In the above example, a ProActive data server should be started. To do so, just go into the <literal>bin</literal> directory
					and launch the <emphasis>pa-dataserver[.bat]</emphasis> script that takes a mandatory argument and a optional one:
					<itemizedlist>
						<listitem>
							<para>
								<emphasis>path</emphasis>: an absolute path pointing on the local file system directory
								that will be the root of the started space. (mandatory)
							</para>
						</listitem>
						<listitem>
							<para>
								<emphasis>name</emphasis>: the name of the server to be started. Can be useful
								if more than one server is started on the same host. ('myOutputSpace' in the example).
							</para>
						</listitem>
					</itemizedlist>
				</para>
				<para>
					The same description is abviously possible in job java API:
				</para>
				<programlisting language="java">
//...
//job is created above ...
job.setInputSpace("http://myserver/directory");
job.setOutputSpace("paprmi://host:1099/myOutputSpace?proactive_vfs_provider_path=/");
//...
				</programlisting>
				<para>
					From now on, every files that will be picked or put in those spaces has to be represented
					by a "virtual" path whose root is "http://myserver/directory" for the INPUT space,
					and the path passed (to pa-dataserver) as first argument for the OUTPUT space.
				</para>
				<para>
					Let's continue with the description of the tasks.
				</para>
			</section>
			<section xml:id="Dataspace_tasks"><info><title>Specifying data spaces in the tasks</title></info>
				<para>
					A task can define a set of input and output files. Input files can be picked from
					the job INPUT, OUTPUT or GLOBAL space. To specify a file to be transfered, it is necessary to set
					two mandatory fields. A third is also useful but is not mandatory:
					<itemizedlist>
						<listitem>
							<para>
								<emphasis>includes</emphasis>: is a file or a regular expression targeting the abstract relative
								path to the file you want to select in the job space. For example, "bin/toto*.xml" will target
								every files starting with 'toto' and ending with '.xml' in the 'bin' directory relative to the chosen space.
								(mandatory)
								Note: for read-only and non listable INPUT space (as HTTP), includes files must not be regular expression.
							</para>
						</listitem>
						<listitem>
							<para>
								<emphasis>accessMode</emphasis>: specify if the selected files has to be transfered from
								INPUT or OUTPUT or GLOBAL, to OUTPUT or GLOBAL, or not transfered. (mandatory)
								Possible values for the input files are: 'transferFromInputSpace', 'transferFromOutputSpace', 'transferFromGlobalSpace', 'none'.
								Possible values for the output files are: 'transferToOutputSpace','transferToGlobalSpace',  'none'.
							</para>
						</listitem>
						<listitem>
							<para>
								<emphasis>excludes</emphasis>: describes a file or every files that must not be targeted among
								the selected includes files. In our example, if "excludes" is "bin/toto123.xml", the file
								'toto123.xml' in the 'bin' directory will finally not be selected. (optional)
								Note: for read-only (as HTTP) INPUT space, excludes files must not be regular expression.
							</para>
						</listitem>
					</itemizedlist>
				</para>
				<para>
					To set up input and/or output files in the XML descriptor, just proceed as follows:
				</para>
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/task_dataspace.xml"/></textobject></programlisting>
				<para>
					Until now, LOCALSPACE will be used as the root of the space local to the task execution (green data space on the picture above).
					In this example, the file 'tata' located at the root of the INPUT space will be transfered from INPUT
					space to LOCALSPACE and every 'toto*.txt' files excepted 'toto*2.txt' in the 'txt' directory will be transfered from OUTPUT space
					to LOCALSPACE. Additionally, files matching 'tutu*.txt' excepted 'tutu*2.txt' in the 'dat' directory will be transfered from GLOBAL space to LOCAL space.
				</para>
				<para>
					At the end of the execution, every produced files 'titi*.dat' excepted the 'titi*1.dat' files will be transfered
					from LOCALSPACE to OUTPUT space. Additionally, the 'titi*.bak' excepted 'titi*1.bak' will be transferred from LOCAL space to GLOBAL space.
					The 'titi*.txt' files won't be transfered, it is just identified as an output file by the Scheduler.
				</para>
				<para>
					Here's the same description using the java API:
				</para>
				<programlisting language="java">
//task is created above...
//add input files
task.addInputFiles("tata",InputAccessMode.TransferFromInputSpace);
FileSelector fs = new FileSelector(new String[]{"txt/toto*.txt"}, new String[]{"txt/toto*2.txt"});
task.addInputFiles(fs,InputAccessMode.transferFromOutputSpace);
FileSelector fs2 = new FileSelector(new String[]{"dat/tutu*.txt"}, new String[]{"dat/tutu*2.txt"});
task.addInputFiles(fs2,InputAccessMode.transferFromGlobalSpace);
//...
//add output files
fs = new FileSelector(new String[]{"titi*.dat"}, new String[]{"titi*1.dat"});
task.addOutputFiles(fs,OutputAccessMode.TransferToOutputSpace);
fss = new FileSelector(new String[]{"titi*.bak"}, new String[]{"titi*1.bak"});
task.addOutputFiles(fs,OutputAccessMode.TransferToGlobalSpace);
task.addOutputFiles("titi*.txt",OutputAccessMode.none);
//...
				</programlisting>
				<para>
					Now, let's explain how to get files in the executable.
				</para>
				<section xml:id="Dataspace_native"><info><title>Retrieving files in a native task</title></info>
					<para>
						To retrieve files as argument in a native task, you have to use the special variable <literal>$LOCALSPACE</literal>.
						<literal>$LOCALSPACE</literal> will be replaced by the real path to the LOCAL space ensuring that your selected
						input files will be there. To produce files and copy them to the OUTPUT space,
						just put them at a relative to LOCALSPACE path and select them in the output files list.
					</para>
					<para>
						The example below shows how to make such a behavior:
					</para>
					<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/task_dataspace_with_native.xml"/></textobject></programlisting>
					<para>
						In this example, the 'myExec' native executable takes one file and one directory as arguments.
						Every selected input files will be copied into the LOCALSPACE.
						Once the execution terminated, every produced file in the third argument (LOCALSPACE root)
						will be copied to the OUTPUT space except the 'titi*.txt' files.
					</para>
					<para>
						To do the same in java, just proceed as follows:
					</para>
					<programlisting language="java">
NativeTask t = new NativeTask();
//add input files
t.addInputFiles("tata",InputAccessMode.TransferFromInputSpace);
FileSelector fs = new FileSelector(new String[]{"txt/toto*.txt"}, new String[]{"txt/toto*2.txt"});
t.addInputFiles(fs,InputAccessMode.transferFromOutputSpace);
//add output files
fs = new FileSelector(new String[]{"titi*.dat"}, new String[]{"titi*1.dat"});
t.addOutputFiles(fs,OutputAccessMode.TransferToOutputSpace);
t.addOutputFiles("titi*.txt",OutputAccessMode.none);
t.setName("native_java");
t.setCommandLine(new String[]{"myExec", "$LOCALSPACE/tata", "$LOCALSPACE/txt", "$LOCALSPACE"});
//...
//job.addTask(t);
					</programlisting>
					<para>
						<emphasis>IMPORTANT</emphasis> : At the end of the task, LOCALSPACE is cleared, every files deleted.
					</para>
				</section>
				<section xml:id="Dataspace_java"><info><title>Retrieving spaces and files in a java task</title></info>
					<para>
						For java task, everything can be done using the dataspace API inside the javaExecutable.
						Transferring files works as well, but it is also possible to handle non-transfered files.
						6 methods are available in the JavaExecutable to retrieve Spaces or files:
						<itemizedlist>
							<listitem>
								<para>
									<emphasis>getInputSpace()</emphasis>: retrieves the root of INPUT space.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getOutputSpace()</emphasis>: retrieves the root of OUTPUT space.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getGlobalSpace()</emphasis>: retrieves the root of GLOBAL space.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getLocalSpace()</emphasis>: retrieves the root of the LOCAL space.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getInputFile(pathName)</emphasis>: selects the file located at "pathName" in the INPUT space.
									"pathName" has to be relative to the root of the INPUT.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									Files can be moved, copied or read.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getOutputFile(pathName)</emphasis>: selects the file located at "pathName" in the OUTPUT space.
									"pathName" has to be relative to the root of the OUTPUT.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									File can be moved, copied, read or written.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getGlobalFile(pathName)</emphasis>: selects the file located at "pathName" in the GLOBAL space.
									"pathName" has to be relative to the root of the GLOBAL.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									File can be moved, copied, read or written.
									(Warning ! Files are probably not on the node host)
								</para>
							</listitem>
							<listitem>
								<para>
									<emphasis>getLocalFile(pathName)</emphasis>: selects the file located at "pathName" in the LOCAL space.
									"pathName" has to be relative to the root of the LOCALSPACE.
									You will get a DataSpacesFileObject on which it is possible to perform some file operations.
									File can be moved, copied, read or written. (local copy)
								</para>
							</listitem>
						</itemizedlist>
					</para>
					<para>
						Here's a complete JavaExecutable example using the data spaces:
					</para>
					<programlisting language="java">
public class DSTest extends JavaExecutable {

	@Override
	public Serializable execute(TaskResult... args) throws Throwable {
		//create titi1.dat from tata in the LOCALSPACE as it is copied
		getLocalFile("titi1.dat").copyFrom(getLocalFile("tata"),FileSelector.SELECT_SELF);
		//create titi2.dat -> will be transfered to OUTPUT space at the end
		getLocalFile("titi2.dat").createFile();
		//list toto*.txt in txt dir from LOCALSPACE as they are copied
		//toto*2.txt is not printed as it is exclude
		for (DataSpacesFileObject dsfo : getLocalFile("txt").getChildren()){
			System.out.println(dsfo.getRealURI());
			System.out.println(dsfo.getVirtualURI());
		}
		//create titi3.dat -> will be transfered to OUTPUT space at the end
		getLocalFile("titi3.dat").createFile();
		//create titi12.txt -> won't be transfered to OUTPUT space
		getLocalFile("titi12.txt").createFile();
		//create titi123.txt directly in the OUTPUT space as it won't be transfered
		getOutputFile("titi123.txt").copyFrom(getInputFile("txt/toto12.txt"), FileSelector.SELECT_SELF);
		//as expected, OUTPUT space will contain :
		//titi2.dat : copied automatically
		//titi3.dat : copied automatically
		//titi123.txt : copied manually by the code above
		return "helloWorld";
	}

}
					</programlisting>
					<para>
						As we can see, java executable can read, copy, move files from/to every spaces.
						At the end of the task, LOCALSPACE is cleared, every files deleted.
					</para>
				</section>
				<section xml:id="Dataspace_scripts"><info><title>Retrieving files in a script</title></info>
				  <para>
					Similarly to what is achieved in <xref linkend="Dataspace_java" /> in Java tasks, Dataspace objects are
					available in the scripted environments of pre, post and flow scripts (flow scripts are similar to
					pre/post scripts introduced in <xref linkend="scheduler_workflow" />).

					This allows taking decisions in scripts based, for instance, on the input available to the task
					or the output that was produced.
				  </para>
				  <para>
					A DataSpacesFileObject is bound to the script environment for inputspace, outputspace, globalspace and localspace.
					The exported variables are respectively <emphasis>input</emphasis>, <emphasis>output</emphasis>, <emphasis>globalspace</emphasis> and
					<emphasis>localspace</emphasis>. Here is an usage example:
				  <programlisting language="java"><![CDATA[
importPackage(org.objectweb.proactive.extensions.dataspaces.api);
importPackage(java.io);
// output here is a DataSpacesFileObject representing this job's OutputSpace
var f = output.resolveFile("out.dat");
var br = new BufferedReader(new InputStreamReader(f.getContent().getInputStream()));
var line;
while ((line = br.readLine()) != null) {
   if (line.match(regex) != null) {
      // ... do stuff
   }
}
					]]></programlisting>
				</para>
				</section>
			</section>
		</section>
		<section xml:id="scheduler_workflow"><info><title>Enabling Workflows in a Task Flow job</title></info>
		  <para>
			Workflows in Scheduling is a set of Control Flow operations and syntactical constructs that
			allow any valid Task Flow job to gain expressiveness and dynamic properties.
		  </para>
		  <section xml:id="scheduler_workflow_use_case"><info><title>Use-cases</title></info>
			<para>
			  <xref linkend="scheduler_workflow_uc_img" /> demonstrates the simplest use-case in which Workflows are needed in Scheduling.
			  Without workflows, 6 (split, join, plus one per split image) tasks have to be written statically in the descriptor to achieve this behaviour.
			  <figure xml:id="scheduler_workflow_uc_img"><info><title>Simple Workflow use-case</title></info>
				<mediaobject>
				  <imageobject>
					<imagedata width="100%" align="center" fileref="images/png/user_manual/workflow_uc.png" format="PNG"/>
				  </imageobject>
				</mediaobject>
			  </figure>
			  With Workflows, this job should be composed of only three tasks, and the number of actual split task should be dynamic, and dependant on the size of the input, here an image.
			  The goal of Workflows is, in the end, to provide tools to program logic inside a job for parts that are obviously factorisable.
			</para>
		  </section>
		  <section xml:id="scheduler_workflow_spec"><info><title>Specification</title></info>
			<para>
			  Workflows provide three main features: the ability to replicate tasks, the ability to loop on a set of tasks, and the ability to choose between two paths in the flow.
			  These features are defined and restricted by syntactic and semantic rules, in order to ensure the correctness of the job prior to submission.
			</para>
			<section xml:id="scheduler_workflow_spec_common"><info><title>Common rules</title></info>
			  <para>
				<itemizedlist>
				  <listitem>
					<para>
					  A <emphasis>dependency</emphasis> between tasks refers exclusively to an explicit &lt;depends&gt; tag in the descriptor.
					  Other types of links introduced by workflows will use proper vocabulary.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  If a task <emphasis>t</emphasis> is started, every task having <emphasis>t</emphasis> as dependency should eventually be started.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  A control flow operation is always activated on the compute node, just after the actual task is executed.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The control flow operation's activation is controlled by a dynamic script using the task's result as input.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The task on which the action is embedded is called the <emphasis>initiator</emphasis>, if a task is used as parameter for
					  an action, it is called a <emphasis>target</emphasis>.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  A <emphasis>task block</emphasis> is a set of tasks delimited by two tasks tagged <emphasis>start block</emphasis> and <emphasis>end block</emphasis>,
					  forming a semantic scope.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>Task blocks</emphasis> can be nested: each <emphasis>end block</emphasis> task matches the last defined <emphasis>start block</emphasis>
					  task up in the dependency chain.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  A <emphasis>Task blocks</emphasis> can consist of one single task, provided it is neither tagged as <emphasis>start block</emphasis> of <emphasis>end block</emphasis>.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  Walking up the dependency chain of an <emphasis>end block</emphasis> task must always lead to the same <emphasis>start block</emphasis>
					  task. Walking down the dependency chain of a <emphasis>start block</emphasis> task must always lead to the same <emphasis>end block</emphasis>
					  task.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  Three distinct operations are defined: <emphasis>replicate</emphasis> (parallelization),
					  <emphasis>if</emphasis> (branching) and <emphasis>loop</emphasis> (looping).
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_spec_replicate"><info><title>Parallelization</title></info>
			  <para>
				The &lt;replicate&gt; action allows the execution of multiple tasks in parallel when only one task is written in the descriptor,
				and the number of parallel runs is not statically known.
				<figure xml:id="scheduler_workflow_spec_replicate_img"><info><title><emphasis>Replicate</emphasis> control flow action</title></info>
				  <mediaobject>
					<imageobject>
					  <imagedata width="100%" align="center" fileref="images/png/user_manual/flow_spec_duplicate.png" format="PNG"/>
					</imageobject>
				  </mediaobject>
				</figure>
				<itemizedlist>
				  <listitem>
					<para>
					  The target is the direct child of the task initiator.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The initiator can have multiple children; each child is replicated.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  If the target is a <emphasis>start block</emphasis>, the whole block is replicated.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The target must have the initiator as only dependency: the action is performed when the initiator task terminates. 
					  If the target has an other pending task as dependency, the behaviour cannot be specified.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  There should always be a merge task after the target of a replicate: if the target is not a start block,
					  it should have at least one child, if the target is a start block, the corresponding end block should have at least one child.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The last task of a replicated task block (or the replicated task if there is no block) cannot perform
					  a <emphasis>branching</emphasis> or  <emphasis>replicate</emphasis> action.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The target of a <emphasis>replicate</emphasis> action can not be tagged as <emphasis>end block</emphasis>.
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_spec_if"><info><title>Branching</title></info>
			  <para>
				The <emphasis>If</emphasis> action provides the ability to choose between two alternative task flows, with the possibility to merge back to a common flow.
				<figure xml:id="scheduler_workflow_spec_if_img"><info><title><emphasis>If</emphasis> control flow action</title></info>
				  <mediaobject>
					<imageobject>
					  <imagedata width="100%" align="center" fileref="images/png/user_manual/flow_spec_if.png" format="PNG"/>
					</imageobject>
				  </mediaobject>
				</figure>
				<itemizedlist>
				  <listitem>
					<para>
					  There is no explicit dependency between the initiator and the <emphasis>if/else</emphasis> targets.
					  These are <emphasis>optional links</emphasis> (ie. A -> B or E -> F in Figure <xref linkend="scheduler_workflow_spec_if_img"/>) defined in the <emphasis>if</emphasis> task.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The <emphasis>if</emphasis> and <emphasis>else</emphasis> flows can be merged by a <emphasis>continuation</emphasis> task referenced in the <emphasis>if</emphasis> task,
					  playing the role of an <emphasis>endif</emphasis> construct. After the branching task, the flow will either be that of the <emphasis>if</emphasis> or the 
					  <emphasis>else</emphasis> task, but it will be continued by the <emphasis>continuation</emphasis> task.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>If</emphasis> and <emphasis>else</emphasis> targets are executed <emphasis>exclusively</emphasis>. The initiator however can be
					  the dependency of other tasks, which will be executed normally along the <emphasis>if</emphasis> or the <emphasis>else</emphasis> target.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  A <emphasis>task block</emphasis> can be defined across <emphasis>if</emphasis>, <emphasis>else</emphasis> and <emphasis>continuation</emphasis> links,
					  and not just plain dependencies
					  (i.e. with <emphasis>A</emphasis> as <emphasis>start</emphasis> and <emphasis>F</emphasis> as <emphasis>end</emphasis> in <xref linkend="scheduler_workflow_spec_if_img" />).
					</para>
				  </listitem>
				  <listitem>
					<para>
					  If using no continuation task, the if and else targets, along with their children, must be strictly distinct.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  If using a continuation task, the if and else targets must be strictly distinct and valid task blocks.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>if</emphasis>, <emphasis>else</emphasis> and <emphasis>continuation</emphasis> tasks (B, D and F in <xref linkend="scheduler_workflow_spec_if_img" />)
					  cannot have an explicit dependency.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>if</emphasis>, <emphasis>else</emphasis> and <emphasis>continuation</emphasis> tasks
					  cannot be entry points for the job, they must be triggered by the <emphasis>if</emphasis> control flow action.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  A task can be target of only one <emphasis>if</emphasis> or <emphasis>else</emphasis> action.
					  A <emphasis>continuation</emphasis> task can not merge two different <emphasis>if</emphasis> actions.
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_spec_loop"><info><title>Looping</title></info>
			  <para>
				<figure xml:id="scheduler_workflow_spec_loop_img"><info><title><emphasis>Loop</emphasis> control flow action</title></info>
				  <mediaobject>
					<imageobject>
					  <imagedata width="100%" align="center" fileref="images/png/user_manual/flow_spec_loop.png" format="PNG"/>
					</imageobject>
				  </mediaobject>
				</figure>
				<itemizedlist>
				  <listitem>
					<para>
					  The target of a <emphasis>loop</emphasis> action must be a parent of the initiator following the dependency chain;
					  this action goes back to a previously executed task.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  Every task is executed at least once; <emphasis>loop</emphasis> operates in a <emphasis>do...while</emphasis> fashion.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The target of a <emphasis>loop</emphasis> should have only one explicit dependency.
					  It will have different parameters (dependencies) depending if
					  it is executed for the first time or not. The cardinality should stay the same.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The <emphasis>loop</emphasis> scope should be a <emphasis>task block</emphasis>: the target is a <emphasis>start block</emphasis> task,
					  and the initiator its related <emphasis>end block task</emphasis>.
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
		  </section>
		  <section xml:id="scheduler_workflow_create"><info><title>Create a Workflow enabled job</title></info>
			<para>
			  The following section demonstrates the combined use of task replication, branching and looping.
			  <figure xml:id="scheduler_workflow_create_img"><info><title>A job combining all control flow actions</title></info>
				<mediaobject>
				  <imageobject>
					<imagedata width="100%" align="center" fileref="images/png/user_manual/workflow_example.png" format="PNG"/>
				  </imageobject>
				</mediaobject>
			  </figure>
			  This job can express the following algorithm:
				<programlisting language="java">
for i in parallel:
   var result
   do:
      if condition:
         result := f1 (result, i)
      else
         result := f2 (result, i)
      endif
   while result > epsilon
done</programlisting>
			  In <xref linkend="scheduler_workflow_create_img" />), it can be noted that:
			  <itemizedlist>
				<listitem>
				  <para>
					Task A performs a <emphasis>replicate</emphasis> control flow action.
					This means all tasks that depend on task A will be replicated.
				  </para>
				</listitem>
				<listitem>
				  <para>
					Task B will be replicated, as it depends on task A, but so will
					tasks C, D and E as they are included in the same <emphasis>task block</emphasis>.
					Tasks B and E are resepectively the start and end block tasks.
				  </para>
				</listitem>
				<listitem>
				  <para>
					Task B performs an <emphasis>if</emphasis> action. The <emphasis>if</emphasis> and <emphasis>else</emphasis> targets are tasks C and D,
					and a <emphasis>continuation</emphasis> is performed on task E. An if with continuation operates on task blocks targets, which tasks C and D are,
					being single tasks.
				  </para>
				</listitem>
				<listitem>
				  <para>
					Task E performs a <emphasis>loop</emphasis> action with task B as target. This action is valid as tasks B (the target)
					and E (the initiator) form a task block.
				  </para>
				</listitem>
			  </itemizedlist>
			</para>
			<section xml:id="scheduler_workflow_blocks"><info><title>Task blocks</title></info>
			  <para>
				One important notion that can be extracted from the specification detailed in <xref linkend="scheduler_workflow_spec" />
				is the existence of <emphasis>Task Blocks</emphasis>.
			  </para>
			  <para>
				Task blocks are defined by pairs of <emphasis>start</emphasis> and <emphasis>end</emphasis> tags.
				<itemizedlist>
				  <listitem>
					<para>
					  Each task of the flow can be tagged either <emphasis>start</emphasis> or <emphasis>end</emphasis>
					</para>
				  </listitem>
				  <listitem>
					<para>
					  Tags can be nested
					</para>
				  </listitem>
				  <listitem>
					<para>
					  Each <emphasis>start</emphasis> tag needs to match a distinct <emphasis>end</emphasis> tag
					</para>
				  </listitem>
				</itemizedlist>
				Task blocks are very similar to the parenthesis of most programming languages: anonymous and nested start/end tags. The
				only difference is that a parenthesis is a syntactical information, whereas task blocks are semantic.
				All combinations of task blocks are syntactically valid, but only those allowed by <xref linkend="scheduler_workflow_spec" />
				are semantically valid and can be submitted to the scheduler.
			  </para>
			  <para>
				The role of Task Blocks is to restrain the expressiveness of the system so that a workflow can be statically
				checked and validated. A treatment that can be looped or iterated will be isolated in a well-defined task block.
				<itemizedlist>
				  <listitem>
					<para>
					  A <emphasis>loop</emphasis> flow action only applies on a Task block: the initiator of the loop must be the end of the block, and the target must be the beginning.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  When using a <emphasis>continuation</emphasis> task in an <emphasis>if</emphasis> flow action, the <emphasis>if</emphasis> and <emphasis>else</emphasis> branches must be task blocks.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  If the child of a <emphasis>replicate</emphasis> task is a task block, the whole block will be replicated and not only the child of the initiator.
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_script"><info><title>Control Flow Scripts</title></info>
			  <para>
				To perform a control flow action such as if, replicate or loop, a <emphasis>Control Flow Script</emphasis> is executed on the execution node.
				This script takes the result of the task as input; meaning a Java object if it was a Java task, or nothing if it was a native task.
			  </para>
			  <para>
				The script is executed on the compute node, just after the task's executable. If the executable is a JavaExecutable and returns a result,
				the variable <emphasis>result</emphasis> will be set in the script's environment so that dynamic decisions can be taken with the task's result
				as input. Native Java objects can be used in a Javascript script using the following syntax:
				<programlisting language="java"><![CDATA[
importPackage(java.io);
// the result variable is the TaskResult.value() if it exists
var resFile = new File("/path/to/data/" + new java.lang.String(result));
if (! resFile.exists()) {
   loop = false;
} else {
   loop = true;
   var input = new BufferedReader(new FileReader(f));
   // this variable will determine the number of parallel runs
   runs = java.lang.Integer.parseInt(input.readLine());
   input.close()
} ]]></programlisting>
				Similarly to how parameters are passed through the <emphasis>result</emphasis> variable to the script,
				the script needs to define variables specific to each action to determine what action the script will lead to.
			  </para>
			  <para>
				<itemizedlist>
				  <listitem>
					<para>
					  A <emphasis>replicate</emphasis> control flow action needs to define how many parallel runs will be executed,
					  by defining the variable <emphasis>runs</emphasis>:
				<programlisting language="java"><![CDATA[
// assuming result is a java.lang.Integer
runs = result % 4 + 1;
]]></programlisting>
				The assigned value needs be a strictly positive integer.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  An <emphasis>if</emphasis> control flow action needs to determine whether the if or the else branch is selected,
					  it does this by defining the boolean variable <emphasis>branch</emphasis>:
				<programlisting language="java"><![CDATA[
// assuming result is a java.lang.Integer
if (result % 2) {
  branch = "if";
} else {
  branch = "else";
} ]]></programlisting>
				The assigned value needs to be the string value "if" or "else".
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The <emphasis>loop</emphasis> control flow action requires setting the <emphasis>loop</emphasis>,
					  which will determine wheter looping to the statically defined target is performed,
					  or if the normal flow is executed as would a continue instruction do in a programming language:
				<programlisting language="java"><![CDATA[
loop = new java.lang.Boolean(result);
]]></programlisting>
				The assigned valuee needs to be a boolean.
					</para>
				  </listitem>
				</itemizedlist>
				Failure to set the required variables or the provide a write a valid control flow script
				will not be treated gracefully and will result in the failure of the task.
			  </para>
			</section>
			<section xml:id="scheduler_workflow_create_xml"><info><title>Using an XML descriptor</title></info>
			  <para>
				The following job is an XML implementation of the job described in <xref linkend="scheduler_workflow_create_img" />).
				<programlisting language="xml"><textobject><textdata fileref="code_snippets/job_descriptors/workflow_1.xml" /></textobject></programlisting>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_create_api"><info><title>Using the Java API</title></info>
			  <para>
				This section takes the same example as in <xref linkend="scheduler_workflow_create_img" /> but focuses on using exclusively the Java API. The code is as follows:
				<programlisting language="java">
TaskFlowJob job = new TaskFlowJob();

JavaTask split = new JavaTask();
split.setName("split");
split.setExecutableClassName("net.example.Split");
FlowScript dup = FlowScript.createReplicateFlowScript(dupScriptContent);
split.setFlowScript(dup);

JavaTask processing_1 = new JavaTask();
processing_1.setName("processing_1");
processing_1.addDependence(split);
processing_1.setExecutableClassName("net.example.Processing_1");
processing_1.setFlowBlock(FlowBlock.START);
FlowScript ifScript = FlowScript.createIfFlowScript(ifScriptContent,
  processing_2_a.getName(), processing_2_b.getName(), processing_3.getName());
processing_1.setFlowScript(ifScript);

JavaTask processing_2_a = new JavaTask();
processing_2_a.setName("processing_2_a");
processing_2_a.setExecutableClassName("net.example.Processing_2_a");

JavaTask processing_2_b = new JavaTask();
processing_2_b.setName("processing_2_b");
processing_2_b.setExecutableClassName("net.example.Processing_2_b");

JavaTask processing_3 = new JavaTask();
processing_3.setName("processing_2");
processing_3.addDependence(processing_1);
processing_3.setExecutableClassName("net.example.Processing_2");
processing_3.setFlowBlock(FlowBlock.END);
FlowScript loop = FlowScript.createLoopFlowScript(loopScriptContent, processing_1.getName());
processing_3.setFlowScript(loop);

JavaTask join = new JavaTask();
join.setName("join");
join.addDependence(processing_3);
join.setExecutableClassName("net.example.Join");</programlisting>
				The most relevant method calls are the one used to tag tasks as <emphasis>start</emphasis> or <emphasis>end block</emphasis>, 
				as well as the ones used to set the Control Flow Script on tasks.
			  </para>
			  <para>
				To see how the Control Flow operations can be used and composed within a job, refer to <xref linkend="scheduler_workflow_spec" />
			  </para>
			</section>
		  </section>
		  <section xml:id="scheduler_workflow_awareness"><info><title>Iteration and replication awareness</title></info>
			<para>
			  When Control Flow actions such as <emphasis>replicate</emphasis> or <emphasis>loop</emphasis> are performed, some tasks are replicated.
			  To be able to identify replicated tasks uniquely, each replicated task has an <emphasis>iteration index</emphasis> and <emphasis>replication index</emphasis>.
			</para>
			<section xml:id="scheduler_workflow_awareness_names"><info><title>Task names</title></info>
			  <para>
				First, those indexes are reflected inside the names of the tasks themselves. Indeed, task names must be unique inside a job.
				The indexes are added to the original task name as a suffix, separated by a special character.
				<itemizedlist>
				  <listitem>
					<para>
					  If a task named "T" is replicated after a <emphasis>loop</emphasis> action, the newly created tasks will be named "T#1", "T#2", etc.
					  The number following the  <emphasis>#</emphasis> separator character represents the <emphasis>iteration index</emphasis>.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  The same scheme is used upon <emphasis>replicate</emphasis> actions: newly created tasks are named "T*1", "T*2", and so on.
					  The separator character  <emphasis>*</emphasis>, and the following number is the <emphasis>replication index</emphasis>.
					</para>
				  </listitem>
				  <listitem>
					<para>
					  When combining both of the above, the resulting task names are of the form: "T#1*1", "T#2*4", etc., in that precise order.
					</para>
				  </listitem>
				</itemizedlist>
				Note that these indexes can be safely extracted using the API :
				<programlisting language="java"><![CDATA[
JobResult jobResult = scheduler.getJobResult(jobId);
for (Entry<String, TaskResult> result : res.getAllResults().entrySet()) {
   int it = result.getValue().getTaskId().getIterationIndex();
   int dup = result.getValue().getTaskid().getReplicationIndex();
   ...
}			  ]]></programlisting>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_awareness_descriptor"><info><title>Iteration and replication indexes in task description</title></info>
			  <para>
				Those indexes are also available when creating a task. They can be obtained using a special string that will be substituted
				with the actual iteration or replication index at runtime: <emphasis>$IT</emphasis> for the iteration index, and <emphasis>$REP</emphasis>
				for the replication index. Those macro can be used in the following locations:
				<itemizedlist>
				  <listitem>
					<para>
					  <emphasis>Java Executable parameters:</emphasis>
					  <programlisting language="xml"><![CDATA[
<javaExecutable class="net.example.Executable">
  <parameters>
    <parameter name="images" value="/some/path/images/pic_$IT_$REP.jpg" />  ]]></programlisting>
					  <programlisting language="java"><![CDATA[
JavaTask t = new JavaTask();
t.setExecutableClassName("net.example.Executable");
t.addArgument("images","/some/path/images/pic_$IT_$REP.jpg");  ]]></programlisting>
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>Native Executable arguments:</emphasis>
					  <programlisting language="xml"><![CDATA[
<staticCommand value="/path/to/bin.sh">
  <arguments>
    <argument value="/some/path/$IT/$REP.dat" />  ]]></programlisting>
					  <programlisting language="java"><![CDATA[
NativeTask nt = new NativeTask();
nt.setCommandLine(new String[] { "/path/to/bin.sh", "/path/to/$ID/$REP.dat" });  ]]></programlisting>
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>Dataspace input and output:</emphasis>
					  <programlisting language="xml"><![CDATA[
<task name="t1" retries="2">
  <inputFiles>
    <files includes="foo_$IT_$REP.dat" accessMode="transferFromInputSpace"/>
  </inputFiles><outputFiles>
    <files includes="bar_$IT_$REP.res" accessMode="transferToOutputSpace"/>  ]]></programlisting>
					  <programlisting language="java"><![CDATA[
task.addInputFiles("foo_$IT_$REP.dat",OutputAccessMode.TransferToOutputSpace);
task.addOutputFiles("bar_$IT_$REP.res",OutputAccessMode.none);  ]]></programlisting>
					</para>
				  </listitem>
				  <listitem>
					<para>
					  <emphasis>Script :</emphasis>
					  <programlisting language="xml"><![CDATA[
<task>
  <pre><script><code language="javascript">
		var f = new java.io.File(".lock_$IT_$REP");
		f.createNewFile();
  </code></script></pre>  ]]></programlisting>
					  <programlisting language="java"><![CDATA[
task.setPreScript(new SimpleScript("var f = new java.io.File(\".lock_$ID_$REP\"); f.createNewFile();", "javascript"));  ]]></programlisting>
					  Scripts affected by the macro substitution are: Pre, Post, Command generation and Control Flow.
					  <emphasis>No substitution will occur in selection scripts.</emphasis>
					</para>
				  </listitem>
				</itemizedlist>
			  </para>
			</section>
			<section xml:id="scheduler_workflow_awareness_exec"><info><title>Iteration and replication indexes in executables</title></info>
			  <para>
				The iteration and replication indexes are available inside the executables launched by tasks.
			  </para>
			  <para>
				In Java tasks, the indexes are exported through the following Java properties: <emphasis>pas.task.iteration</emphasis> and <emphasis>pas.task.replication</emphasis>.
				<programlisting language="java"><![CDATA[
public Serializable execute(TaskResult... results) throws Throwable {
  int it  = System.getProperty("pas.task.iteration");
  int dup = System.getProperty("pas.task.replication");
} ]]></programlisting>
			  </para>
			  <para>
				In a similar fashion, environment variables are set when launching a native executable: <emphasis>PAS_TASK_ITERATION</emphasis> and <emphasis>PAS_TASK_REPLICATION</emphasis>:
				<programlisting language="sh"><![CDATA[
#!/bin/sh
/path/to/bin.sh /path/to/file/${PAS_TASK_ITERATION}/${PAS_TASK_REPLICATION}.dat
 ]]></programlisting>
			  </para>
			</section>
		  </section>
		</section>
		<section xml:id="Submit_a_job"><info><title>Submit a job to the Scheduler</title></info>
			<para>
				The submission will perform some verifications to ensure that a job is correctly formed.
				Then, the job is inserted in the pending queue and waits for executions until free resources
				become available. Once done, the job will be started on the resources deployed by the
				Resource Manager. Finally, once finished, the job goes to the queue of finished jobs and will wait until the user
				retrieves his result.
				Their are three ways to submit a job to the Scheduler described in the following sub-sections.
			</para>
			<section xml:id="Submit_a_job_GUI"><info><title>Submit a job using the Graphical User Interface (Scheduler Eclipse Plugin)</title></info>
				<para>
				To submit a job using the graphical tools, you have first to create a job XML Descriptor.
				Once done, please refer to
				<xref linkend="Scheduler_Eclipse_Plugin"/>.
				</para>
			</section>
			<section xml:id="Submit_a_job_sh"><info><title>Submit a job using the shell command</title></info>
				<para>
				  Use the provided shell script <emphasis>scheduler-client[.bat]</emphasis> to submit a job using command line.
					This script (bin/[os]/scheduler-client[.bat] used to submit a job) has 1 mandatory option and 2 optional :
					<itemizedlist>
						<listitem>
							<para>
								<emphasis>Job to schedule</emphasis> (mandatory) -
								It can be an XML Job descriptor, a simple flat file, or a path to a native command to launch :
								Use -submit followed by the path or the command to give, and :
								<itemizedlist>
									<listitem><para>To schedule an XML job file: use -submit followed by the path of an XML descriptor</para></listitem>
									<listitem><para>To schedule a flat file containing native commands: use -submit followed the by the path of a flat file containing native commands and -cmdf to specify that it is a command file.</para></listitem>
									<listitem><para>To schedule a path to a native command : use -submit followed by the path of the native command to launch, with its launching arguments. Here, it submits a job made of one native task.
									Then, use -cmd to specify that it is a command path.</para></listitem>
								</itemizedlist>
								For -cmd and -cmdf options, you can use aditional parameters. For instance, you can specify a log file that will contain all STDOUT and STDERR of job execution, with -o followed by the path of a file.
								This file is created (emptied if exits) at each beginning of job execution. You can specify a selection script with -s, followed by the path of a selection script file.
								You can specify a job name, with -jn followed by a string specifying a name. These three options (-s, -o and -jn) are not taken into account if -cmd or -cmdf are not specified option, because job name,
								selection scripts and log file are directly specified in the XML job descriptor.
							</para>
						</listitem>
						<listitem>
							<para>
								<emphasis>The URL of a started scheduler</emphasis> (optional) -
								To use this option, add a "-u URL" argument. If not mentioned,
								the script will connect to an existing local Scheduler.
							</para>
						</listitem>
						<listitem>
							<para>
								<emphasis>Your login</emphasis> (optional) -
								To use this option, add a "-l login" argument
								. If you use this option, only
								your password will be requested.
								Otherwise, both will be.
							</para>
						</listitem>
					</itemizedlist>
				</para>
				<para>
					Examples:
				</para>
				<para>
					<emphasis>
						scheduler-client[.bat] -submit ../../samples/jobs_descriptors/Job_with_dep.xml -l login -u //localhost:1099/
					</emphasis>
					will submit the <literal>Job_with_dep</literal> job to a local
					ProActive Scheduler on port 1099 with the username 'login', and only your password will be requested.
					Authorized username and password are defined by the administrator.
				</para>
				<para>
					<emphasis>
						scheduler-client[.bat] -submit ../../samples/jobs_descriptors/job_native_linux_cmd_file/cmds_file.cmd -cmdf -l demo //localhost/ -jn myJob -o myJob.log
					</emphasis>
					will submit a job defined in a flat file, containing 4 native commands. Job is named "myJob", and a log file named "myJob.log" will be created.
				</para>
				<para>
					<emphasis>
						scheduler-client[.bat] -submit ../../samples/jobs_descriptors/job_native_linux_cmd_file/myCmd.sh 4 -cmd -l demo -u //localhost -s ../../samples/scripts/selection/select.rb
					</emphasis>
					will submit the native command "myCmd.sh" with "4" as the only argument. A selection script is associated for this native command: "select.rb".
				</para>
				<para>
					For more information, use -h (or --help) option (i.e. "scheduler-client[.bat] -h").
				</para>
			</section>
			<section xml:id="Submit_a_job_java"><info><title>Submit a job using the Java API</title></info>
				<para>
					To connect the ProActive Scheduler and submit a Job using Java API, just proceed as follows :
				</para>
				<programlisting language="java">
//join an existing ProActive Scheduler retrieving an authentication interface.
try {
	SchedulerAuthenticationInterface auth = SchedulerConnection.waitAndJoin("protocol://host:port");
	//connect and log to the Scheduler. Valid username and password are defined by the administrator
	Scheduler scheduler = null;
	try {
	    // (1) preferred authentication method
	    scheduler = auth.login(Credentials.getCredentials());
	} catch (KeyException ke) {
	    try {
	        // (2) alternative authentication method
	        PublicKey pubKey = auth.getPublicKey();
	        if (pubKey == null) {
	             pubKey = Credentials.getPublicKey(Credentials.getPubKeyPath());
	        }
	        scheduler = auth.login(Credentials.createCredentials(new CredData("demo", "demo"), pubKey));
	    } catch (KeyException ke2) {
	        //cannot find public key !
	    }
	}
	// submitting a new job and get the associated id
	JobId myJobId = scheduler.submit(job);
} catch (ConnectionException e) {
	//cannot join scheduler !
	e.printStackTrace();
}
				</programlisting>
				<para>
				  Connecting to the Scheduler implicates using a keypair infrastructure to establish a secure channel on
				  which the credentials (username and password) will be sent securely. There are two ways to connect
				  to the Scheduler, as described in the example above:
				  <orderedlist>
				    <listitem><para>
					Retreive the Credentials from disk: supposes the script <emphasis>create-cred[.bat]</emphasis> was previously used to generate those credentials.
					It requires knowing the location of the public key corresponding to the private key that will be used for decryption on server side.
					To obtain the key, you can either have it on your local drive, or ask the remote Scheduler:
				      </para>
				      <para>
					<programlisting language="sh"><![CDATA[
# use local public key to generate credentials for user 'demo', password will be specified in interactive mode
/bin/unix $ ./create-cred -F $HOME/.proactive/scheduler_pubkey -o $HOME/.proactive/my_encrypted_credentials -l demo
# use rmi://example.com:1099/'s public key to generate credentials for user 'admin' with pass 'admin' in non-interactive mode
/bin/unix $ ./create-cred -S rmi://example.com:1099/ -o $HOME/.proactive/my_encrypted_credentials -l admin -p admin
# also store user ssh private key in credentials to be able to execute task under user ID
/bin/unix $ ./create-cred -S rmi://example.com:1099/ -o $HOME/.proactive/my_encrypted_credentials -l admin -p admin -k $HOME/.ssh/id_rsa
]]></programlisting>
					Credentials can now be retreived when properly designated by the <emphasis>pa.common.auth.credentials</emphasis> property; ie using
					<emphasis>java -Dpa.common.auth.credentials=$HOME/.proactive/my_encrypted_credentials</emphasis>. Please type <literal>create-cred -h</literal> to
					have the complete list of possible options.
				    </para></listitem>
				    <listitem><para>
					Create the encrypted Credentials on client side: as safe as the previous method, but requires user input, which prevents automation,
					or storing clear credentials on the disk, which can result to security breaches. This method also requires knowing the public key,
					which should be offered by the Scheduler through the Authentication object with the getPubKey() method.
					If the Scheduler doesn't know the public key, it can be stored locally on client side and designated by the
					<emphasis>pa.common.auth.pubkey</emphasis> Java property; ie using <emphasis>java -Dpa.common.auth.pubkey=$HOME/.proactive/pub.key</emphasis>.
				    </para></listitem>
				  </orderedlist>
				</para>
				<para>
					In any cases, you can create your own encrypted credentials using login/password and an optional ssh private key.
					The ssh private key (if specified) will only be used if the task property 'runAsMe' is true and if the node is configured to accept
					ssh key authentication.
				</para>
				<para>
					As you can see, submitting a job will return a Job ID. This is the identification code of
					the submitted Job. It is useful to save it in order to retrieve future information on this job.
				</para>
				<para>
					If you want to get a job from a XML job file descriptor, just add the following line before submitting :
				</para>
				<programlisting language="java">
//join an existing ProActive Scheduler as below
...
//create the job, 'filePath' is the path of the XML job descriptor
Job job = JobFactory.getFactory().createJob(filePath);
//then submit it
scheduler.submit(job);
				</programlisting>
			</section>
		</section>
		<section xml:id="get_result"><info><title>Get a job result</title></info>
			<para>
				Once a Job is terminated, it is possible to get its result. You can only get the result of the job that you own.
			</para>
			<section xml:id="get_result_GUI"><info><title>Get a job result using the Graphical User Interface (Scheduler Eclipse Plugin)</title></info>
				<para>
				To get a job result using the graphical tools, please refer to
				<xref linkend="Scheduler_Eclipse_Plugin"/>.
				</para>
			</section>
			<section xml:id="get_result_sh"><info><title>Get a job result using the shell command</title></info>
				<para>
					To get the result of you job using a command line, launch the command <emphasis>scheduler-client[.bat] -result jobID</emphasis> script in the bin/[os]/ directory.
					This script has 2 optional options:
					<itemizedlist>
						<listitem>
							<para>
								The URL of a started Scheduler ("-u URL" option). If you
								don't use this, it will try to connect to a started scheduler on
								the local host.
							</para>
						</listitem>
						<listitem>
							<para>
								Your login ("-l login" option). If you use this option,
								only your password will be requested. Otherwise, both will be requested.
							</para>
						</listitem>
					</itemizedlist>
				</para>
				<para>
					It will print the result on the screen as the
					toString() Java method could have done it.
				</para>
				<para>
					For more information, use -h (or --help) option (i.e. "scheduler-client[.bat] -h").
				</para>
			</section>
			<section xml:id="get_result_java"><info><title>Get a job result using the Java API</title></info>
				<para>
					To do it in Java, use the <emphasis role="bold">getJobResult(JobId)</emphasis> method in the
					<emphasis role="bold"> Scheduler </emphasis> interface and the job ID you got when you submitted it.
					A job result is in fact a list of task result ordered in three lists:
				</para>
				<itemizedlist>
					<listitem>
						<para>
							A full list that contains every result
							or exception of every tasks.
						</para>
					</listitem>
					<listitem>
						<para>
							A failed list that contains every result
							or exception returned by a task that
							failed.
						</para>
					</listitem>
					<listitem>
						<para>
							A precious result list that contains
							every result or exception returned by
							the task marked as precious.
						</para>
					</listitem>
				</itemizedlist>
				<para>
					This result will be given to you exactly like
					you returned it in your executable. To know
					when a job you have submitted has finished
					its execution, you can subscribe to the
					scheduler to be notified of some events. This
					will be explain in the next section.
				</para>
				<programlisting language="java">
// get the Scheduler interface
Scheduler scheduler = auth.login(Credentials.getCredentials());
// get the result of the job
JobResult myResult = scheduler.getJobResult(myJobId);
//look at inside the JobResult to retrieve TaskResult...
				</programlisting>
				<para>
					<emphasis>Note</emphasis> : The above example is useful when you kept a reference of myJobId. If you want to submit a job and disconnect, just keep
					the id as a string (using myJobId.value() ). Then when reconnecting the Scheduler to get the result,
					just use the getJobResult(String jobId) method.
				</para>
			</section>
		</section>
		<section xml:id="Register_events"><info><title>Register to ProActive Scheduler events</title></info>
			<para>
				If you are <emphasis>using the Java API</emphasis>, it is possible to get events from the Scheduler.
				In order to be notified about the scheduler activities, you can add a Scheduler listener
				that will inform you of some events, like job submitting, job or task finished, scheduling
				state changing... To add a listener, create your listener implementing the
				<emphasis>SchedulerEventListener</emphasis> interface and add it to the scheduler. You will
				then receive the scheduler state containing some information about the current
				scheduling state. See the ProActive Scheduler JAVADOC for more details.
			</para>
			<para>
				It is also possible to specify if you want to receive events concerning your jobs, or any job from any user in the Scheduler.
			</para>
			<programlisting language="java">
//make your listener
SchedulerEventListener mySchedulerEventListener = new SchedulerEventListener () {
	jobStateUpdatedEvent(NotificationData&lt;JobInfo&gt; notification){
		switch(notification.getEventType()){
			case JOB_RUNNING_TO_FINISHED :
				//if my job is finished
				if (notification.getData().getJobId().equals(myJobId)){
					//get its result
					JobResult myResult = scheduler.getJobResult(myJobId);
				}
				break;
		}
	}
	//Implement other methods...
}
//add the listener to the scheduler specified which events you want to receive.
scheduler.addEventListener(mySchedulerEventListener, true, SchedulerEvent.JOB_RUNNING_TO_FINISHED);
			</programlisting>
			<para>
				This example shows you how to listen to the scheduler events (only finished job event
				in the previous example). Yet, you can listen for every event you want contained in this interface.
			</para>
			<para>
				For more details and features on the user scheduler interface, please refer to the java Documentation.
			</para>
		</section>
		<section xml:id="scheduler_controller"><info><title>Using the Scheduler controller</title></info>
			<para>
				The Scheduler controller provides a way to interact with the Scheduler. Start it with the <emphasis>bin/[os]/scheduler-client[.bat]</emphasis>
				script. You can use it as a command line (as shown
				in some examples above, go to <xref linkend="scheduler_controller_non_interactive"/>) or in interactive mode (go to
				<xref linkend="scheduler_controller_interactive"/>).
			</para>
			<section xml:id="scheduler_controller_non_interactive"><info><title>Command line mode</title></info>
				<para>
					Here is the displayed help when using <emphasis>scheduler-client[.bat] -h</emphasis> command:
					<figure xml:id="scheduler_controller_help"><info><title>Scheduler controller help</title></info>
						<mediaobject>
							<imageobject>
								<imagedata width="100%" align="center" fileref="images/png/user_manual/scheduler-user-h.png" format="PNG"/>
							</imageobject>
						</mediaobject>
					</figure>
				</para>
				<para>
				To use the controller as a command line, just specify at least one 'ctl' option. Let's illustrate that with some examples:
				</para>
				<itemizedlist>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -l demo -submit path/to/job/xml/descriptor</emphasis>: tries to connect user demo, prompts for
							its password and submits the given XML descriptor file.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -l demo -cmd -jn test -submit ls -al</emphasis>: tries to connect user demo, prompts for
							its password and submits the given command line in a job named 'test'. In this case, the <emphasis role="italics">-cmd</emphasis> option forces
							the argument of <emphasis role="italics">-submit</emphasis> option to be a command line.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -cmdf -s path/to/a/selection/script -submit path/to/a/text/file</emphasis>: prompts for a username and
							its password and submits the given commands file. It also includes the given selection script file.
							In this case, the <emphasis role="italics">-cmdf</emphasis> option forces
							the argument of <emphasis role="italics">-submit</emphasis> option to be a flat text file that contains
							commands (One command per line, each line will be a task).
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -output 12</emphasis>: prompts for a username and
							its password and displays the output written by job 12 if it is finished.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -result 34</emphasis>: prompts for a username and
							its password and displays the result of job 34 if it is finished.
						</para>
					</listitem>
					<listitem>
						<para>
							<emphasis>scheduler-client[.bat] -priority 56 Lowest</emphasis>: prompts for a username and
							its password and requests the Scheduler to change job 56 priority to 'LOWEST'.
						</para>
					</listitem>
				</itemizedlist>
				<para>
				  To use the controller, you can either type your login and password in interactive mode, or use the <emphasis>--use-cred</emphasis> option
				  to attempt retreiving encrypted credentials from disk.
				  In both cases, the credentials need to be encrypted when transiting on the network: you need to have the Scheduler's public key, corresponding
				  to the private key that will be used to decrypt the credentials.
				  <orderedlist>
				    <listitem><para>
					In interactive mode, this public key will be asked by the controller to the remote Scheduler it is attempting to contact:
					if the Scheduler does not know it or is unable to forward it to the controller, is must be specified through the
					<emphasis>pa.common.auth.pubkey property</emphasis>, ie. using
					<emphasis>java -Dpa.common.auth.pubkey=$HOME/.proactive/my_encrypted_credentials</emphasis>.
				    </para></listitem>
				    <listitem><para>
					In batch mode, this public key will be used when encrypting the credentials with the bin/[os]/createCred[.bat] script:
					<programlisting language="sh"><![CDATA[
# use local public key to generate credentials for user 'demo'
/bin/unix $ ./create-cred -P $HOME/.proactive/scheduler_pubkey -o $HOME/.proactive/my_encrypted_credentials -l demo
# use rmi://example.com/SCHEDULER's public key to generate credentials for user 'admin' with pass 'admin' in non-interactive mode
/bin/unix $ ./create-cred -U rmi://example.com/SCHEDULER -o $HOME/.proactive/my_encrypted_credentials -l admin -p admin
]]></programlisting>
					When running the controller, Credentials will now be retreived when properly designated by the
					<emphasis>pa.common.auth.credentials</emphasis> property; ie. using
					<emphasis>java -Dpa.common.auth.pubkey=$HOME/.proactive/my_encrypted_credentials</emphasis>,
					or when using the <emphasis>--credentials PATH</emphasis> option.
				    </para></listitem>
				  </orderedlist>
				</para>
				<para>
					Once the command launched, it will terminate by displaying a successful message or the cause of
					a possible failure as an exception.
				</para>
			</section>
			<section xml:id="scheduler_controller_interactive"><info><title>Interactive mode</title></info>
				<para>
					Another way to interact with the Scheduler is using the interactive mode of the controller. To start it in this mode,
					just execute the bin/[os]/scheduler-client[.bat] command without specifying a 'ctl' option:
					<emphasis>scheduler-client[.bat] -l demo -u rmi://localhost:1313/</emphasis> is an example which connects the controller
					to a local Scheduler on the port 1313 with 'demo' login.
				</para>
				<para>
					Once connected, type <emphasis role="italics">?</emphasis> or <emphasis role="italics">help</emphasis> to get the list of
					provided functions:
					<figure xml:id="scheduler_controller_i_help"><info><title>Scheduler controller interactive help</title></info>
						<mediaobject>
							<imageobject>
								<imagedata width="100%" align="center" fileref="images/png/user_manual/scheduler-user-interactive-h.png" format="PNG"/>
							</imageobject>
						</mediaobject>
					</figure>
				</para>
				<para>
					The interactive controller is <emphasis role="bold">based on JavaScript language</emphasis> where some methods
					(describe in <xref linkend="scheduler_controller_i_help"/>) have been defined in order to facilitate its usage.
					Here is an example of what can be done with the console:
				</para>
				<programlisting>
  &gt; submit("../../samples/jobs_descriptors/Job_PI.xml");
Job successfully submitted ! (id=1)

  &gt; myId = submit("../../samples/jobs_descriptors/Job_PI.xml");
Job successfully submitted ! (id=2)

  &gt; pausejob(1);
Job 1 paused.

  &gt; resumejob(1);
Job 1 resumed.

  &gt; result(myId);
Job 2 result =&gt;

	 Average1 : 3.1414783733333334
	 Computation3 : 3.1414446
	 Computation4 : 3.14154732
	 Average2 : 3.141520226666667
	 Computation1 : 3.14146984
	 LastAverage : 3.1414993000000004
	 Computation5 : 3.14129996
	 Computation2 : 3.14152068
	 Computation6 : 3.1417134

  &gt; output(myId);
Job 2 output =&gt;

Average1 :
Parameters are :
3.14146984
3.14152068
3.1414446
Average is : 3.1414783733333334

Average2 :
Parameters are :
3.14154732
3.14129996
3.1417134
Average is : 3.141520226666667

LastAverage :
Parameters are :
3.1414783733333334
3.141520226666667
Average is : 3.1414993000000004


  &gt; myResult = result(1)
Job 1 result =&gt;

	 Average1 : 3.14164032
	 Computation4 : 3.14176412
	 Computation3 : 3.14162724
	 Average2 : 3.1416647466666667
	 Computation1 : 3.14182172
	 LastAverage : 3.1416525333333336
	 Computation5 : 3.1416124
	 Computation2 : 3.141472
	 Computation6 : 3.14161772

  &gt; println(myResult.getName());
job_PI
				</programlisting>
				<para>
					As you can see, the provided methods are useful to make basic actions. It is also possible to get
					instances from Scheduler API. As shown, the <emphasis role="italics">myResult = result(1)</emphasis> instruction
					leads to get an instance of JobResult in the 'myResult' variable. As in Java, use the method of the JobResult API
					to get other informations. Here is an example:
				</para>
				<programlisting>
  &gt; prio = myResult.getJobInfo().getPriority();

  &gt; status = myResult.getJobInfo().getStatus();

  &gt; nbfinished =  myResult.getJobInfo().getNumberOfFinishedTasks();

  &gt; duration = myResult.getJobInfo().getFinishedTime()-myResult.getJobInfo().getStartTime();

  &gt; println("priority : "+prio);  println("status : "+status); println("finished tasks : "+nbfinished); println("duration = "+duration+" ms");
priority : Normal
status : Finished
finished tasks : 9
duration = 94386 ms
				</programlisting>
				<para>
					The <emphasis role="italics">exec(...)</emphasis> function provides a way to evaluate a javascript file. For example,
					just insert the code below in a '.js' file with:
				</para>
				<programlisting>
myResult = result(1);
prio = myr.getJobInfo().getPriority();
status = myr.getJobInfo().getStatus();
nbfinished =  myr.getJobInfo().getNumberOfFinishedTasks();
duration = myr.getJobInfo().getFinishedTime()-myr.getJobInfo().getStartTime();
println("priority : "+prio);  println("status : "+status); println("finished tasks : "+nbfinished); println("duration = "+duration+" ms");
				</programlisting>
				<para>
					The result will be exactly the same as the one in the code shown in the previous example.
				</para>
				<para>
					When error occurred in a command, it is possible to show the stack trace on demand. Indeed, the execution stops
					and prompts the user to show the stackTrace or not.
					In order to script this interactive controller, you can disable stack trace on demand. To do so, use the
					<emphasis role="italics">exMode(...)</emphasis> function. The first parameter defines whether the stack trace will be
					displayed while the second one defines if the stack trace has to be displayed every time or on demand.
					Setting the first parameter to 'false' disables the second one.
				</para>
				<para>
					As an example, let's see the following script:
				</para>
				<programlisting>
  &gt; exMode(false);
Exception display mode changed : stack trace not displayed

  &gt; for (i=0;i&lt;5;i++){submit("../../samples/jobs_descriptors/Job_PI.xml")};
Job successfully submitted ! (id=3)
Job successfully submitted ! (id=4)
Job successfully submitted ! (id=5)
Job successfully submitted ! (id=6)
Job successfully submitted ! (id=7)

  &gt; for (i=0;i&lt;5;i++){result(i);}
Error on job 0 : The job represented by this ID is unknow !
Error on job 1 : The job represented by this ID is unknow !
Error on job 2 : The job represented by this ID is unknow !
Job 3 result =&gt;

	 Average1 : 3.1416381333333336
	 Computation4 : 3.14196316
	 Computation3 : 3.14175216
	 Average2 : 3.141720133333333
	 Computation1 : 3.14169736
	 LastAverage : 3.1416791333333336
	 Computation5 : 3.14180604
	 Computation2 : 3.14146488
	 Computation6 : 3.1413912
Job 4 is not finished or unknown !
				</programlisting>
				<para>
					In this case, we get some error messages but no exception and the script can terminate without prompting to view stack trace.
				</para>
				<para>
					<emphasis>Note :</emphasis>Interactive mode can also be started using a javascript environment.
					To do so, just put a file named <emphasis>scheduler-client.js</emphasis> in the [user.home]/.proactive directory OR
					just reference your own file when starting the controller :
					<itemizedlist>
						<listitem>
							<para>
								<emphasis>scheduler-client -uc -js myenv.js</emphasis> : This command will
								start the scheduler controller in interactive mode first loading the 'myenv.js' script !
							</para>
						</listitem>
					</itemizedlist>
				</para>
			</section>
		</section>		
</chapter>

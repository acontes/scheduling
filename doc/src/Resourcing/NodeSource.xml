<?xml version="1.0" encoding="utf-8"?>
<section xml:id="nodes_sources"><info><title>Organizing your nodes</title></info>
		<para>
			The ProActive Resource Manager supports nodes aggregation from heterogeneous
			environments. As a node is just a JVM running somewhere, the process of communication
			to such nodes is unified and defined by ProActive library. The only part which has to
			be defined is the procedure of nodes deployment which could be quite different
			depending on infrastructures and their limitations.

			After <link linkend="rm-install">installation</link> of the server and node parts
			it is possible to configure an automatic nodes deployment.
			Basically, you can say to the resource manager how to launch JVMs with
			ProActive nodes and when.
		</para>

		<note><para>
			Lets give an example here. You have a cluster of linux-x64 machines
			permanently at your disposal with ssh access to all hosts
			and a cluster running Windows HPC where you would like
			to run computations periodically (let us say from 12 to 14 every day).
			In order to describe such a kind of behavior, we create 2 node sources
			using GUI or command line interface. The first one is the node source
			with "ssh infrastructure" and static deployment policy. The command would be
			the following:

			<screen><![CDATA[$RM_HOME>./bin/unix/rm-client --createns "MyCluster" -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.SSHInfrastructure
rmURL sshOptions javaPath schedulingPath nodeTimeout attempt targetOS javaOptions rmCreds hostsList]]></screen>
			The semantic of this command is quite straight forward, namely the resource
			manager tries immediately to launch the command of JVM creation through ssh using a special
			class which creates ProActive nodes inside JVMs and register them in the resource manager.
			Static node acquisition is default and you do not have to explicitly specify it.
		</para>
		<para>
			The procedure of deployment on Windows HPC is more tricky because it involves the native scheduler
			and in order to take into account other users of the cluster, we have to go through it.
			Basically, what the resource manager does is contact the windows scheduler
			exposed as a web service (it requires additional configuration of windows cluster)
			and submit a job launching the JVM process with ProActive. Here we also describe
			when the deployment has to be triggered using time slot policy.
			<screen><![CDATA[$RM_HOME>./bin/unix/rm-client --createns "WindowsCluster" -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.WinHPCInfrastructure
rmURL maxNodes serviceUrl userName password trustStore trustStorePassword javaPath rmPath RMCredentialsPath javaOptions extraClassPath timeout
-policy org.ow2.proactive.resourcemanager.nodesource.policy.TimeSlotPolicy nodesAvailableTo administrator acquireTime releaseTime period preemptive]]></screen>
		</para>
		</note>

		<para>
			As you can see in the example above, in order to create a node source, you have to define two entities
			<emphasis>infrastructure manager</emphasis> and
			<emphasis>node source policy</emphasis>.
		</para>
		<para>
			<emphasis>Infrastructure manager</emphasis> is responsible for communicating with an infrastructure.
			When a new node has to be deployed, an infrastructure manager will launch new JVM or just
			request an already existing nodes running somewhere. All these details are specific to the
			infrastructure manager implementation.
		</para>

		<warning><para>
			ProActive Scheduling supports only one node per JVM. So that if you're configuring
			the resource manager to be used with scheduler take it into account.
			In the following, the term "node" always
			refers to a <emphasis>single node deployed in a dedicated JVM.</emphasis>
		</para></warning>

		<para>
			<emphasis>Node source policy</emphasis> is a set of rules and conditions which describes
			when and how many nodes have to be acquired or released. Policies use node source API to
			manage the node acquisition.
		</para>
		<para>
			Node sources were designed in a way that:
		</para>

		<itemizedlist>
			<listitem>
				<para>
					All logic related to node acquisition is encapsulated in the infrastructure manager.
				</para>
			</listitem>
			<listitem>
				<para>
					Conditions and rules of node acquisition is described in the node source policy.
				</para>
			</listitem>
			<listitem>
				<para>
					Permissions to the node source. Each policy has two parameters:
					<itemizedlist>
						<listitem>
							<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
							for computations from this node source. It has to take one of the following values:
								<itemizedlist>
									<listitem>
										<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
									</listitem>
									<listitem>
										<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
									</listitem>
									<listitem>
										<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
									</listitem>
								</itemizedlist>
							</para>
						</listitem>
						<listitem>
							<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
							It should take one of the following values:
								<itemizedlist>
									<listitem>
										<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
									</listitem>
									<listitem>
										<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
									</listitem>
									<listitem>
										<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
									</listitem>
								</itemizedlist>
							</para>
						</listitem>
					</itemizedlist>
					The user created the node source is the administrator of this node source. It can add and removed
					nodes to it, remove the node source itself, but cannot use nodes if usage policy is set to PROVIDER
					or PROVIDER_GROUPS (unless it's granted AllPermissions).
				</para>
			</listitem>
			<listitem>
				<para>
					New infrastructure manager or node source policy can be dynamically plugged into the Resource Manager.
					In order to do that, it is just required to add new implemented classes in the class path and update
					corresponding list in the configuration file (<literal>[RM_HOME]/config/rm/nodesource</literal>).
				</para>
			</listitem>
		</itemizedlist>

		<para>
			In the resource manager, there is always a default node source consisted of DefaultInfrastrucureManager and
			Static policy. It is not able to deploy nodes anywhere but makes it possible to add existing nodes
			to the RM.
		</para>

		<section xml:id="default"><info><title>Default infrastructure</title></info>
			<para>
				<emphasis>Default infrastructure manager</emphasis> is designed to be used with ProActive agent.
				It cannot perform an automatic deployment but any users (including an agent) can add already existing nodes
				into it. In order to create a node source with this infrastructure, run the following command:
				<screen>$RM_HOME>./bin/unix/rm-client --createns defaultns -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.DefaultInfrastructureManager rmURL</screen>
			</para>
			<para>The only parameter to provide is the following one:</para>
			<itemizedlist>
				<listitem>
					<para><emphasis role="bold">rmURL</emphasis> - the URL of the resource manager.</para>
				</listitem>
			</itemizedlist>
		</section>
		<section xml:id="LOCAL_im"><info><title>Local infrastructure</title></info>
				<para>
					<emphasis>Local Infrastructure Manager</emphasis> can be used to start nodes locally, i.e,
					on the host running the Resource Manager. In order to create a node source with this infrastructure, run the following command:
					<screen>$RM_HOME>./bin/unix/rm-client --createns localns -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.LocalInfrastructure RMUrl credentialsPath numberOfNodes timeout javaProperties </screen>
				</para>
				<itemizedlist>
					<listitem>
						<para><emphasis>RMUrl</emphasis> - Url of the resource manager server (can leave it empty to use default value, i.e, the url of the resource manager you connect to)</para>
					</listitem>
					<listitem>
						<para><emphasis>credentialsPath</emphasis> - The absolute path of the credentials file used to set the provider of the nodes.</para>
					</listitem>
					<listitem>
						<para><emphasis>numberOfNodes</emphasis> - The number of nodes to deploy.</para>
					</listitem>
					<listitem>
						<para><emphasis>timeout</emphasis> - The length in ms after which one a node is not expected anymore.</para>
					</listitem>
					<listitem>
						<para><emphasis>javaProperties</emphasis> - The java properties to setup the ProActive environment for the nodes</para>
					</listitem>
				</itemizedlist>
		</section>
		<section xml:id="GCM_customized"><info><title>GCM customized infrastructure</title></info>
				<para>
					<emphasis>GCM customized infrastructure</emphasis> can deploy/remove
					a single node to/from the infrastructure described in GCM descriptor.
					It makes possible to use this insfrastructure manager together with
					more precise policies such as "scheduler aware policy" (see below).
					In order to create such node source user has to specify GCMD
					and hosts list. GCMD has to define a deployment of
					a single node and does not have to have an explicit host names.
					Instead of this, ${HOST} variable must be used and at the
					moment of deployment the resource manager associates host
					to the gcmd (see <literal>$RM_HOME/config/rm/deployment/deployment_ssh_hosts_list_template.xml</literal>).
				</para>
				<screen>$RM_HOME>./bin/unix/rm-client --createns gcmns -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.GCMCustomisedInfrastructure rmURL config/rm/deployment/deployment_ssh_hosts_list_template.xml config/rm/deployment/hostslist nodeTimeout</screen>
				<para>This infrastructure needs 4 arguments, described hereafter:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">RMUrl</emphasis> - Url of the resource manager server</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">descriptor</emphasis> - path to a template GCM Deployment descriptor file where the <literal>${HOST}</literal> variable is used.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">hostsList</emphasis> - path to a file containing a list of hosts (one host per line).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">timeout</emphasis> - The length in ms after which one a node is not expected anymore.</para>
					</listitem>
				</itemizedlist>
				<para>
					Even if GCM and GCMCustomized infrastructures used the same GCM Application descriptor file, only GCM Customized makes an optimal usage of it. The
					main difference comes from the fact that the GCM Customized infrastructure manager predicts the deployment of the nodes by giving them a name.
					This name can directly be set by the infrastructure manager filling in a variable contract (name jvmargDefinedByIM) of the xml descriptor file.
				</para>
		</section>
		<section xml:id="SSH"><info><title>SSH infrastructure</title></info>
			<para>
				This infrastructure allows to deploy nodes over ssh. Having a list of hosts the resource manager
				construct the ssh command to launch remote JVMs. Java path and rm distribution path on remote hosts
				have to be specified together with other parameters. Example:
			</para>
			<para>This infrastructure needs 10 arguments, described hereafter:</para>
			<itemizedlist>
				<listitem>
					<para>
						<emphasis role="bold">Rm Url</emphasis> - The resource manager's url that will be used by the deployed nodes to register by themself.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">SSH Options</emphasis> - Options you can pass to the SSHClient executable ( -l inria to specify the user for instance )
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Java Path</emphasis> - Path to the java executable on the remote hosts.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Scheduling Path</emphasis> - Path to the Scheduling/RM installation directory on the remote hosts.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Node Time Out</emphasis> - A duration after which one the remote nodes are considered to be lost.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Attempt</emphasis> - The number of time the resource manager tries to acquire a node for which one the deployment fails before discarding it forever.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Target OS</emphasis> - One of 'LINUX', 'CYGWIN' or 'WINDOWS' depending on the machines' ( in Hosts List file ) operating system.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Java Options</emphasis> - Java options appended to the command used to start the node on the remote host.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Rm Credentials Path</emphasis> - The absolute path of the 'rm.cred' file to make the deployed nodes able to register to the resource manager ( config/authentication/rm.cred ).
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Hosts List</emphasis> - Path to a file containing the hosts on which resources should be acquired.
						This file should contain one host per line, described as a host name or a public IP address, optionally followed by a positive
						integer describing the number of runtimes to start on the related host (default to 1 if not specified). Example:
						<screen><![CDATA[rm.example.com
test.example.net 5
192.168.9.10 2]]></screen>
					</para>
				</listitem>
			</itemizedlist>
		</section>
		<section xml:id="CLI"><info><title>Command Line infrastructure</title></info>
			<para>
				This generic infrastructure allows to deploy nodes using deployment script written in arbitrary language.
				The infrastructure just launches this script and waits until the ProActive node is registered in the resource manager.
				Command line infrastructure could be used when you prefer to describe the deployment process using shell scripts
				instead of Java. Script examples could be found in RM_HOME/samples/scripts/deployment.
				The deployment script has 4 parameters: HOST_NAME, NODE_NAME, NODE_SOURCE_NAME, RM_URL.
				The removal script has 2 parameters: HOST_NAME and NODE_NAME.
			</para>
			<para>This infrastructure needs 7 arguments, described hereafter:</para>
			<itemizedlist>
				<listitem>
					<para>
						<emphasis role="bold">Rm Url</emphasis> - The resource manager's url that will be used by the deployed nodes to register by themself.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Interpreter</emphasis> - Path to the script interpreter (bash by default).
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Deployment Script</emphasis> - A script that launches a ProActive node and register it to the RM.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Removal Script</emphasis> - A script that removes the node from the resource manager.
					</para>
				</listitem>
				<listitem>
					<para>
						<emphasis role="bold">Hosts List</emphasis> - Path to a file containing the hosts on which resources should be acquired.
						This file should contain one host per line, described as a host name or a public IP address, optionally followed by a positive
						integer describing the number of runtimes to start on the related host (default to 1 if not specified). Example:
						<screen><![CDATA[rm.example.com
test.example.net 5
192.168.9.10 2]]></screen>
					</para>
				</listitem>
			    <listitem>
				    <para>
				      <emphasis role="bold">Node Time Out</emphasis> - The length in ms after which one a node is not expected anymore.
			        </para>
		        </listitem>
				<listitem>
					<para>
						<emphasis role="bold">Max Deployment Failure</emphasis> - the number of times the resource manager tries to relaunch the deployment script in case of failure.
					</para>
				</listitem>
			</itemizedlist>
		</section>
		<section xml:id="Win_HPC"><info><title>Windows HPC infrastructure</title></info>
				<para>
					The deployment through Windows HPC scheduler. In order to make it functional,
					the Windows HPC has to be configured according to
					<link xlink:href="http://technet.microsoft.com/en-us/library/cc972837(WS.10).aspx">this guide</link>.
					After exposing windows native scheduler as a web service it is possible to contact
					it from Java and submit any command. In our case, it is a command launching JVM on one of the
					cluster nodes.
				</para>
				<screen>$RM_HOME>./bin/unix/rm-client --createns winhpc -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.WinHPCInfrastructure rmURL 8 https://cluster_name/HPCBasicProfile username password trustStore trustStorePassword javaPath rmPath RMUrl RMCredentialsPath javaOptions extraClassPath nodeTimeout</screen>

				<para>This infrastructure needs 12 arguments, described hereafter:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">RMUrl</emphasis> - Url of the resource manager server</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">maxNodes</emphasis> - Maximum number of nodes to deploy.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">serviceUrl</emphasis> - Url of the WinHPC web service.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">userName</emphasis> - username for the web service connection</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">password</emphasis> - password for the web service connection</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">trustStore</emphasis> - name of the trustStore</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">trustStorePassword</emphasis> - password of the trustStore</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">javaPath</emphasis> - Path to the java executable on the WinHPC server.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">rmPath</emphasis> - Path to the Resource Manager directory on the WinHPC server.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">RMCredentialsPath</emphasis> - Path to the RM Credentials</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">javaOptions</emphasis> - Java options appended to the command used to start the node on WinHPC server.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">extraClassPath</emphasis> - Extra class path to be added.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">timeout</emphasis> - The length in ms after which one a node is not expected anymore.</para>
					</listitem>
				</itemizedlist>
		</section>

		<!-- AMAZON EC2 section -->
		&EC2;

		<section xml:id="LSF"><info><title>Load Sharing Facility (LSF) infrastructure</title></info>
				<para>
				This infrastructure knows how to acquire nodes from LSF by submitting a corresponding job.
				It will be submitted through SSH from the RM to the LSF server. As an alternative, you may consider
				using <link linkend="GCM_customized">the GCM Customized infrastructure</link> instead,
				which provides more control over the deployment, but requires more configuration.
				</para>
				<screen>$RM_HOME>./bin/unix/rm-client --createns lsf -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.LSFInfrastructure rmURL javaPath sshOptions schedulingPath javaOptions maxNodes nodeTimeout LSFServer RMCredentialsPath bsubOptions</screen>
				<para>where:</para>
			    <itemizedlist>
			      <listitem><para>
				  <emphasis role="bold">RMUrl</emphasis> - URL of the Resource Manager from the LSF nodes point of view -
				  this is the URL the nodes will try to lookup when attempting to register to the RM after their creation.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaPath</emphasis> - path to the java executable on the remote hosts (ie the LSF slaves).
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">SSH Options</emphasis> - Options you can pass to the SSHClient executable ( -l inria to specify the user for instance )
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">schedulingPath</emphasis> - path to the Scheduling/RM installation directory on the remote hosts.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaOptions</emphasis> - Java options appended to the command used to start the node
				  on the remote host.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">maxNodes</emphasis> - maximum number of nodes this infrastructure can simultaneously hold from the LSF server.
				  That is useful considering that LSF does not provide a mechanism to evaluate the number of currently available or idle cores on the cluster.
				  This can result to asking more resources than physically available, and waiting for the resources to come up for a very long time
				  as the request would be queued until satisfiable.
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">Node Time Out</emphasis> - The length in ms after which one a node is not expected anymore.
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Server Name</emphasis> - URL of the LSF server, which is responsible for acquiring LSF nodes.
				  This server will be contacted by the Resource Manager through an SSH connection.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">RM Credentials Path</emphasis> - Encrypted credentials file, as created by the create-cred[.bat] utility.
				  These credentials will be used by the nodes to authenticate on the Resource Manager.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Submit Job Opt</emphasis> - Options for the bsub command client when acquiring nodes on the LSF master.
				  Default value should be enough in most cases, if not, refer to the documentation of the LSF cluster.
			      </para></listitem>
			    </itemizedlist>
		</section>
		<section xml:id="PBS"><info><title>Portable Batch System (PBS) infrastructure</title></info>
				<para>
				This infrastructure knows how to acquire nodes from PBS (i.e. Torque) by submitting
				a corresponding job. It will be submitted through SSH from the RM to the PBS server.
				As an alternative, you may consider using <link linkend="GCM_customized">the GCM Customized infrastructure</link>
				instead, which provides more control over the deployment, but requires more configuration.
				</para>
				<screen>$RM_HOME>./bin/unix/rm-client --createns pbs -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.PBSInfrastructure rmURL javaPath sshOptions schedulingPath javaOptions maxNodes nodeTimeout PBSServer RMCredentialsPath qsubOptions</screen>
				<para>where:</para>
			    <itemizedlist>
			      <listitem><para>
				  <emphasis role="bold">RMUrl</emphasis> - URL of the Resource Manager from the PBS nodes point of view -
				  this is the URL the nodes will try to lookup when attempting to register to the RM after their creation.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaPath</emphasis> - path to the java executable on the remote hosts (ie the PBS slaves).
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">SSH Options</emphasis> - Options you can pass to the SSHClient executable ( -l inria to specify the user for instance )
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">schedulingPath</emphasis> - path to the Scheduling/RM installation directory on the remote hosts.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaOptions</emphasis> - Java options appended to the command used to start the node
				  on the remote host.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">maxNodes</emphasis> - maximum number of nodes this infrastructure can simultaneously hold from the PBS server.
				  That is useful considering that PBS does not provide a mechanism to evaluate the number of currently available or idle cores on the cluster.
				  This can result to asking more resources than physically available, and waiting for the resources to come up for a very long time
				  as the request would be queued until satisfiable.
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">Node Time Out</emphasis> - The length in ms after which one a node is not expected anymore.
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Server Name</emphasis> - URL of the PBS server, which is responsible for acquiring PBS nodes.
				  This server will be contacted by the Resource Manager through an SSH connection.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">RM Credentials Path</emphasis> - Encrypted credentials file, as created by the create-cred[.bat] utility.
				  These credentials will be used by the nodes to authenticate on the Resource Manager.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Submit Job Opt</emphasis> - Options for the qsub command client when acquiring nodes on the PBS master.
				  Default value should be enough in most cases, if not, refer to the documentation of the PBS cluster.
			      </para></listitem>
			    </itemizedlist>
		</section>
		<section xml:id="GENERIC_IM"><info><title>Generic Batch Job infrastructure</title></info>
				<para>
					<emphasis>Generic Batch Job infrastructure</emphasis> provides users with the capability to add the support of new batch job scheduler by providing a class extending
					org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure. Once you have written that implementation, you can create a node source which makes usage
					of this infrastructure by running the following command:
				</para>
				<screen>$RM_HOME>./bin/unix/rm-client --createns pbs -infrastructure org.ow2.proactive.resourcemanager.nodesource.infrastructure.GenericBatchJobInfrastructure rmURL javaPath sshOptions schedulingPath javaOptions maxNodes nodeTimeout BatchJobServer RMCredentialsPath subOptions implementationName implementationPath</screen>
				<para>where:</para>
			    <itemizedlist>
			      <listitem><para>
				  <emphasis role="bold">RMUrl</emphasis> - URL of the Resource Manager from the batch job scheduler nodes point of view -
				  this is the URL the nodes will try to lookup when attempting to register to the RM after their creation.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaPath</emphasis> - path to the java executable on the remote hosts (ie the slaves of the batch job scheduler).
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">SSH Options</emphasis> - Options you can pass to the SSHClient executable ( -l inria to specify the user for instance )
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">schedulingPath</emphasis> - path to the Scheduling/RM installation directory on the remote hosts.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">javaOptions</emphasis> - Java options appended to the command used to start the node on the remote host.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">maxNodes</emphasis> - maximum number of nodes this infrastructure can simultaneously hold from the batch job scheduler server.
			      </para></listitem>
				  <listitem><para>
				  <emphasis role="bold">Node Time Out</emphasis> - The length in ms after which one a node is not expected anymore.
				  </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Server Name</emphasis> - URL of the batch job scheduler server, which is responsible for acquiring nodes.
				  This server will be contacted by the Resource Manager through an SSH connection.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">RM Credentials Path</emphasis> - Encrypted credentials file, as created by the create-cred[.bat] utility.
				  These credentials will be used by the nodes to authenticate on the Resource Manager.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">Submit Job Opt</emphasis> - Options for the submit command client when acquiring nodes on the batch job scheduler master.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">implementationName</emphasis> - Fully qualified name of the implementation of org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure
				  provided by the end user.
			      </para></listitem>
			      <listitem><para>
				  <emphasis role="bold">implementationPath</emphasis> - The absolute path of the implementation of org.ow2.proactive.resourcemanager.nodesource.infrastructure.BatchJobInfrastructure.
			      </para></listitem>
			    </itemizedlist>
		</section>
		&Virtualization;
		<section xml:id="static"><info><title>Static policy</title></info>
				<para>
					<emphasis>Static node source policy</emphasis> starts node acquisition when nodes are added to
					the node source and never removes them. Nevertheless, nodes can be removed by user request.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
									<listitem>
										<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
									</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
									<listitem>
										<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
									</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
				</itemizedlist>
		</section>
		<section xml:id="time"><info><title>Time slot policy</title></info>
				<para>
					<emphasis>Time slot policy</emphasis> is aimed to acquire nodes for particular time with an ability to do it periodically.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">acquireTime</emphasis> - Absolute acquire date (e.g. "6/3/10 1:18:45 PM CEST").</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">releaseTime</emphasis> - Absolute releasing date (e.g. "6/3/10 2:18:45 PM CEST").</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">period</emphasis> - period time in millisecond (default is 86400000).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">preemptive</emphasis> - Preemptive parameter indicates the way of releasing nodes. If it is true, nodes will be released
						without waiting the end of jobs running on (default is false).</para>
					</listitem>
				</itemizedlist>

		</section>
		<section xml:id="cron"><info><title>Cron policy</title></info>
				<para>
					<emphasis>Cron policy</emphasis> is aimed to acquire and remove nodes at specific time defined in the cron syntax.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeAcquision</emphasis> - The time policy will trigger the deployment of all nodes (e.g. "0 12 * * *" every day at 12.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeRemoval</emphasis> - The time policy will trigger the removal of all nodes (e.g. "0 13 * * *" every day at 13.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">preemptive</emphasis> - Preemptive parameter indicates the way of releasing nodes. If it is true, nodes will be released
						without waiting the end of jobs running on (default is false).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">forceDeployment</emphasis> - If for the example above (the deployment starts every day at 12.00 and the removal starts at 13.00) you are creating the node
						source at 12.30 the next deployment will take place the next day. If you'd like to force the immediate deployment set this parameter to true.</para>
					</listitem>
				</itemizedlist>
		</section>
		<section xml:id="scheduler_idle"><info><title>"Remove nodes when scheduler is idle" policy</title></info>
				<para>
					<emphasis>"Remove nodes when scheduler is idle" policy</emphasis> removes all nodes from the infrastructure
					when the scheduler is idle and acquires them when a new job is submitted. This policy may be useful 
					if there is no need to keep nodes alive permanently. Nodes will be released after a specified "idle time". 
					This policy will use a listener of the scheduler, that is why its URL, its user name and its password have to be specified.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerUrl</emphasis> - Url of the Scheduler</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerCredentialsPath</emphasis> - Path to the credentials used for scheduler authentification.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">idleTime</emphasis> - idle time in millisecond to wait before removing all nodes (default is 60000).</para>
					</listitem>
				</itemizedlist>
				<note>
					<para>
						This policy is available only when using the <emphasis>ProActive Scheduler</emphasis>.
					</para>
				</note>
		</section>
		<section xml:id="scheduler_dynamic"><info><title>"Scheduler loading" policy</title></info>
				<para>
					<emphasis>"Scheduler loading" policy</emphasis> acquires/releases nodes
					according to the scheduler loading factor. This policy allows to configure the number of resources 
					which will be always enough for the scheduler. Nodes are acquired and released according to scheduler loading factor 
					which is a number of tasks per node. In the same manner as the previous policy, this one also requires scheduler URL, 
					user name and password. It is important to correctly configure maximum and minimum nodes that this policy will try to hold. 
					Maximum number should not be greater than potential nodes number which is possible to deploy to underlying infrastructure. 
					If there are more currently acquired nodes than necessary, policy will release them one by one after having waited for a "release period" delay. 
					This smooth release procedure is implemented because deployment time is greater than the release one. 
					Thus, this waiting time deters policy from spending all its time trying to deploy nodes.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerUrl</emphasis> - Url of the Scheduler</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerCredentialsPath</emphasis> - Path to the credentials used for scheduler authentification.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">refreshTime</emphasis> - time between each calculation of the number of needed nodes.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">minNodes</emphasis> - Minimum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">maxNodes</emphasis> - Maximum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">loadFactor</emphasis> - number of tasks per node. Actually, if this number is <emphasis role="italics">N</emphasis>,
						it does not means that there will be exactly <emphasis role="italics">N</emphasis> tasks
						executed on each node. This factor is just used to compute the total number of nodes. For instance, let us assume that this factor is 3 and that we schedule 100
						tasks. In that case, we will have 34 (= upper bound of 100/3) started nodes. Once one task finished and the refresh time passed,
						one node will be removed since 99 divided by 3 is 33. When there will remain 96 tasks (asuming that no other tasks are scheduled meanwhile),
						an other node will be removed at the next calculation time, and so on and so forth... </para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeDeploymentTimeout</emphasis> - The node deployment timeout.</para>
					</listitem>
				</itemizedlist>
				<note>
					<para>
						This policy is available only when using the <emphasis>ProActive Scheduler</emphasis>.
					</para>
				</note>
		</section>
		<section xml:id="cron_load_based"><info><title>"Cron load based" policy</title></info>
				<para>
					The <emphasis>"Cron load based" policy</emphasis> triggers new nodes acquisition when scheduler is overloaded (exactly like with <emphasis>"Scheduler loading" policy</emphasis>) only within a time slot defined using crontab syntax.
					All other time the nodes are removed from the resource manager.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerUrl</emphasis> - Url of the Scheduler</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerCredentialsPath</emphasis> - Path to the credentials used for scheduler authentification.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">refreshTime</emphasis> - time between each calculation of the number of needed nodes.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">minNodes</emphasis> - Minimum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">maxNodes</emphasis> - Maximum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">loadFactor</emphasis> - number of tasks per node. Actually, if this number is <emphasis role="italics">N</emphasis>,
						it does not means that there will be exactly <emphasis role="italics">N</emphasis> tasks
						executed on each node. This factor is just used to compute the total number of nodes. For instance, let us assume that this factor is 3 and that we schedule 100
						tasks. In that case, we will have 34 (= upper bound of 100/3) started nodes. Once one task finished and the refresh time passed,
						one node will be removed since 99 divided by 3 is 33. When there will remain 96 tasks (asuming that no other tasks are scheduled meanwhile),
						an other node will be removed at the next calculation time, and so on and so forth... </para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeDeploymentTimeout</emphasis> - The node deployment timeout.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">acquisionAllowed</emphasis> - The time when the policy starts to work as the <emphasis>"scheduler loading" policy</emphasis> (e.g. "0 12 * * *" every day at 12.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">acquisionForbidden</emphasis> - The time policy removes all the nodes  from the resource manager (e.g. "0 13 * * *" every day at 13.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">preemptive</emphasis> - Preemptive parameter indicates the way of releasing nodes. If it is true, nodes will be released
						without waiting the end of jobs running on (default is false).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">allowed</emphasis> - If true acquisition will be immediately allowed.</para>
					</listitem>
				</itemizedlist>
				<note>
					<para>
						This policy is available only when using the <emphasis>ProActive Scheduler</emphasis>.
					</para>
				</note>
		</section>
		<section xml:id="cron_slot_load_based"><info><title>"Cron slot load based" policy</title></info>
				<para>
					The <emphasis>"Cron slot load based" policy</emphasis> triggers new nodes acquisition when scheduler is overloaded (exactly like with <emphasis>"Scheduler loading" policy</emphasis>) only within a time slot defined using crontab syntax.
					The other time it holds all the available nodes.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerUrl</emphasis> - Url of the Scheduler</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerCredentialsPath</emphasis> - Path to the credentials used for scheduler authentification.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">refreshTime</emphasis> - time between each calculation of the number of needed nodes.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">minNodes</emphasis> - Minimum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">maxNodes</emphasis> - Maximum number of nodes to deploy</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">loadFactor</emphasis> - number of tasks per node. Actually, if this number is <emphasis role="italics">N</emphasis>,
						it does not means that there will be exactly <emphasis role="italics">N</emphasis> tasks
						executed on each node. This factor is just used to compute the total number of nodes. For instance, let us assume that this factor is 3 and that we schedule 100
						tasks. In that case, we will have 34 (= upper bound of 100/3) started nodes. Once one task finished and the refresh time passed,
						one node will be removed since 99 divided by 3 is 33. When there will remain 96 tasks (asuming that no other tasks are scheduled meanwhile),
						an other node will be removed at the next calculation time, and so on and so forth... </para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeDeploymentTimeout</emphasis> - The node deployment timeout.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">acquisionAllowed</emphasis> - The time when the policy starts to work as the <emphasis>"scheduler loading" policy</emphasis> (e.g. "0 12 * * *" every day at 12.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">acquisionForbidden</emphasis> - The time policy removes all the nodes  from the resource manager (e.g. "0 13 * * *" every day at 13.00).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">preemptive</emphasis> - Preemptive parameter indicates the way of releasing nodes. If it is true, nodes will be released
						without waiting the end of jobs running on (default is false).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">allowed</emphasis> - If true acquisition will be immediately allowed.</para>
					</listitem>
				</itemizedlist>
				<note>
					<para>
						This policy is available only when using the <emphasis>ProActive Scheduler</emphasis>.
					</para>
				</note>
		</section>
		<section xml:id="ec2_policy"><info><title>Amazon EC2 policy</title></info>
				<para>
					Allocates resources according to the Scheduler loading factor,
					releases resources considering that EC2 instances are paid by the hour.
				</para>
				<para>For using this policy, you have to precise the following parameters:</para>
				<itemizedlist>
					<listitem>
						<para><emphasis role="bold">nodeUsers</emphasis> - utilization permission defined who can get nodes
						for computations from this node source. It has to take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">nodeProviders</emphasis> - Provider permission defines who can add nodes to this node source.
						It should take one of the following values:
							<itemizedlist>
								<listitem>
									<para><emphasis role="bold">"ME"</emphasis> - Only the node source creator </para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"users=user1,user2;groups=group1,group2"</emphasis> - Only specific users or groups (for our example user1, user2, group1 and group2). It is possible to specify only groups or only users.</para>
								</listitem>
								<listitem>
									<para><emphasis role="bold">"ALL"</emphasis> - Everybody</para>
								</listitem>
							</itemizedlist>
						</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerUrl</emphasis> - Url of the Scheduler</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">schedulerCredentialsPath</emphasis> - Path to the credentials used for scheduler authentification.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">preemptive</emphasis> - Preemptive parameter indicates the way of releasing nodes. If it is true, nodes will be released
						without waiting the end of jobs running on (default is false).</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">refreshTime</emphasis> - time between each calculation of the number of needed nodes.</para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">loadFactor</emphasis> - number of tasks per node. Actually, if this number is <emphasis role="italics">N</emphasis>,
						it does not means that there will be exactly <emphasis role="italics">N</emphasis> tasks
						executed on each node. This factor is just used to compute the total number of nodes. For instance, let us assume that this factor is 3 and that we schedule 100
						tasks. In that case, we will have 34 (= upper bound of 100/3) started nodes. Once one task finished and the refresh time passed,
						one node will be removed since 99 divided by 3 is 33. When there will remain 96 tasks (asuming that no other tasks are scheduled meanwhile),
						an other node will be removed at the next calculation time, and so on and so forth... </para>
					</listitem>
					<listitem>
						<para><emphasis role="bold">releaseDelay</emphasis> - Delay between each node release. This time is useful since the deploying time is important.
						Let us assume that a node has to be removed. If this releaseDelay did not exist (or if it was set to 0),
						this node would be removed instantaneously. Let us assume assume that right after this
						removal, another task is scheduled, requiring a new node. In that case, we would lose a lot of time removing the previous node and deploying another one
						whereas the task could have been scheduled on the same node. This releaseDelay therefore represents the time to wait before effectively removing a node.</para>
					</listitem>
				</itemizedlist>
				<note>
					<para>
						This policy is available only when using the <emphasis>ProActive Scheduler</emphasis>.
					</para>
				</note>
		</section>
		<section xml:id="customizaed_inf_policy"><info><title>Custom infrastructure/policy</title></info>
				<para>
					The resource manager provides the way to create your own custom policy or infrastructure.
					In order to do it:
				</para>
				<itemizedlist>
					<listitem>
						<para>First implement you policy extending from <emphasis role="bold">org.ow2.proactive.resourcemanager.nodesource.policy.NodeSourcePolicy</emphasis>
						or infrastructure extending from <emphasis role="bold">org.ow2.proactive.resourcemanager.nodesource.infrastructure.InfrastructureManager</emphasis>.
						To add the parameter which will be visible in GUI/CLI just put <emphasis role="bold">@Configurable</emphasis> annotation to the corresponding field.</para>
					</listitem>
					<listitem>
						<para>Second put you classes into <emphasis role="bold">$RMHOME/addons</emphasis> directory so that the resource manager will find them.</para>
					</listitem>
					<listitem>
						<para>And finally update the configuration file. For newly created policy put the name into
						<emphasis role="bold">$RMHOME/config/rm/nodesource/policies</emphasis>. For the infrastructure do the same
						in  <emphasis role="bold">$RMHOME/config/rm/nodesource/infrastructures</emphasis>.</para>
					</listitem>
				</itemizedlist>
				<para>
					When you start the resource manager your infrastructure/policy will be in the list of supported ones.
				</para>
		</section>
</section>

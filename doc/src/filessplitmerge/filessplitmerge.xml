<?xml version="1.0" encoding="utf-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" version="5.0"
	xml:id="Files_Split_Merge">
	<info>
		<title>ProActive Scheduler's Files Split-Merge Extension</title>
	</info>

	<section xml:id="Files_SplitMerge_Overwiew">
		<info>
			<title>Presentation</title>
		</info>

		<para>
			The
			<emphasis>"Files Split Merge"</emphasis>
			generic framework provides an easy way to develop a
			distribution layer for a native application in order to run
			it on a ProActive managed infrastructure through the
			ProActive Scheduler and Resource Manager.Here is a short
			description of this framework: A distribution layer can be
			implemented, with this framework, for native
			applicationsthat meet these requirements:

			<itemizedlist>
				<listitem>
					<para>
						the input data can be split into slices so that
						an instance of the application can be run
						against each slice of data
					</para>
				</listitem>
				<listitem>
					<para>
						there is a way to merge the outputs of all runs
						(each output corresponding to one slice of the
						input data) in order to obtain the same final
						output as the one generated by the application
						using the entire input data
					</para>
				</listitem>
			</itemizedlist>
		</para>

		<para>
			The framework implements the «split input data/ execute
			multiple instances/merge results» pipeline, so that the
			applications built over this framework provide features
			like:
		</para>
		<itemizedlist>
			<listitem>
				<para>
					disconnected mode: the user can disconnect from the
					application (close the application) during the
					execution of his "run" by the ProActive Scheduler
					Server. Once the application restarted, it will ask
					the server for the results and perform the merging
					operation
				</para>
			</listitem>
			<listitem>
				<para>
					fault tolerance: the entire system is fault tolerant
					- the application itself and the ProActive Scheduler
					and Resource Manager servers. The granularity of the
					fault tolerance is a task (an instance of the native
					application running against a slice of data) which
					means that, if a failure occurs into the system,
					only the tasks affected by this failure will be
					rerun.
				</para>
			</listitem>
			<listitem>
				<para>
					keep track of the advancement of the "run", notify
					the user when the results are available
				</para>
			</listitem>
			<listitem>
				<para>
					manage the pushing of the input slices to the remote
					compute resources and pulling of the results
					(several copy protocols are available)
				</para>
			</listitem>
			<listitem>
				<para>
					a textual user interface for the distribution layer
					application
				</para>
			</listitem>
			<listitem>
				<para>
					a graphical user interface, provided as plugin for
					the Scheduler User Interface
				</para>
			</listitem>
		</itemizedlist>

		<para>
			The framework provides an API which allows the developer of
			the distribution layer application to specify the split and
			merge operations, define specific post treatment of data
			results, define the scripts that will be used for data copy
			as well as their arguments, specify the generation of the
			command which launches the native application, depending on
			the type of the remote computing resource (i.e. the remote
			operating system).
		</para>
	</section>


	<section xml:id="How_To">
		<info>
			<title>
				How-To – what you need to implement to make it work
			</title>
		</info>
		<para>
			Using the framework is straight-forward. Several abstract
			classes are to be extended in order to define
			application-specific implementation. A quick overview is
			presented below.
		</para>

		<para>
			<emphasis>
				Implement MyJobCreator class by extending JobCreator
				class
			</emphasis>
		</para>

		<para>
			Initiate your Jobcreator: provide an init() method or a
			constructor which takes in argument the data you need for
			creating the job (i.e. input files, input parameters, etc.)
		</para>
		<para>
			Implement the split data operation: implement the method:
			<programlisting language="java">
				protected abstract List &lt;File&gt;splitData() throws
				IOException;
			</programlisting>
		</para>
		<para>
			The method is responsible with splitting the input data for
			a job in n "slices", one for each task. The size of the
			returned list will determine the number of tasks that will
			be created. This list could contain, for instance, one input
			file for each task, or one folder per task, containing a set
			of input files for that task. Note that, each element of
			this list will be sent as argument, during the task creation
			process, to these methods (see details bellow):
		</para>
		<programlisting language="java">
			getGenerationScriptArgs(..),createCommandLineForTask(..),
			getPreScriptArgs(..), getPostScriptArgs(..),
			getCleanScriptArgs(..)
		</programlisting>

		<para>
			Define what command should be executed on the remote
			machines. You can implement this method
			<programlisting language="java">
				protected abstract String createCommandLineForTask(File
				file, int taskNb);
			</programlisting>
			and provide the command line to be executed as return of
			this method. If the command line to be executed depends on
			the remote operating system (or some remote parameters), you
			can override the methods
			<programlisting language="java">
				protected String getGenerationScriptFilePath()
			</programlisting>
			and
			<programlisting language="java">
				protected List&lt;String&gt; getGenerationScriptArgs(int
				taskNb, File inputFile)
			</programlisting>
			in order to provide the file path for the script that will
			generate the command and its arguments.
		</para>
		<para>
			Define the file transfer in your application. The file
			transfer is to be performed by pre and post scripts. These
			scripts run on the remote nodes, before and respectively
			after the execution of the task itself. The pre script will
			usually be used for copying files from their initial
			location to the node and the post script to copy results
			from the node to a result folder accessible by the
			application. Several file transfer helpers (java
			implementation for several file transfer protocols) are
			provided in the Scheduler release 1.0, as well as sample
			java scripts for file transfer. You must implement the
			methods
			<programlisting language="java">
				protected abstract String getPreScriptFilePath();
			</programlisting>
			and
			<programlisting language="java">
				protected abstract String getPostScriptFilePath();
			</programlisting>
			in order to specify the files containing your pre and post
			scripts, as well as the methods
			<programlisting language="java">
				protected abstract List &lt;String&gt;
				getPreScriptArgs(int taskNb, File taskInputDirOnServer);
			</programlisting>
			<programlisting language="java">
				protected abstract List&lt;String&gt;
				getPostScriptArgs(int taskNb, File
				taskWorkingDirOnServer);
			</programlisting>
			in order to provide the input arguments for the scripts.
			These methods will be called when the tasks are created.
		</para>
		<para>
			Provide a script and arguments for cleaning the remote
			resources after use, by implementing the methods
			<programlisting language="java">
				protected abstract String getCleanScriptFilePath();
			</programlisting>
			and
			<programlisting language="java">
				protected abstract List &lt;String&gt;
				getCleanScriptArgs(int taskNb, File
				taskWorkingDirOnServer);
			</programlisting>
		</para>



		<para>
			<emphasis>
				Implement the JobConfiguration interface
			</emphasis>
		</para>
		<para>
			A JobConfiguration object will be attached to a job when
			submitted to the Scheduler. This object should contain all
			the information needed in order to merge the results in the
			post- treatment process. This object should be implemented
			as a bean, with all attributes of type String: provide
			getters and setters methods for all attributes, by
			respecting the template
			<programlisting language="java">
				public String getAttribute()/ public void
				setAttribute(String val)
			</programlisting>
			The JobConfiguration object will be passed as argument for
			the mergeResults(..) method in the PostTreatmentManager. The
			JobConfiguration object should provide all the information
			necessary to the merging of results.
		</para>

		<para>
			<emphasis>
				Implement MyPostTreatmentManager class by extending
				JobPostTreatmentManager
			</emphasis>
		</para>

		<para>
			Implement the method:
			<programlisting language="java">
				protected abstract void mergeResults(JobConfiguration
				jc, int numberOfTasks);
			</programlisting>
			The JobConfiguration object should contain all the
			information needed to merge the results (result file names
			and locations, parameters, output file names, etc ..)
		</para>
		<para>
			<emphasis>(Optional) Write a ResultPreviw class</emphasis>
		</para>

		<para>
			extend org.ow2.proactive.scheduler.common.task.ResultPreview
			in order to define how the partial results will be displayed
			in the Scheduler User Interface.
		</para>
		<para>
			<emphasis>(Optional) Write a MenuCreator class</emphasis>
		</para>
		<para>
			extend GeneralMenuCreator class in order to define a menu
			for the Textual User Interface (if you need one). Also write
			command classes (extend Command) and add them to the
			MenuCreator (i.e. SubmitJobCommand).

			Once you have implemented the classes described above, you
			have to
			<emphasis>initialize your application</emphasis>
			by calling:
		</para>
		<programlisting language="java">
			EmbarrasinglyParrallelApplication.instance().initApplication(url,userName,passwd,Go
			ldMenuCreator.class, GoldJobPostTreatmentManager.class,
			GoldJobConfiguration.class);
		</programlisting>
		<para>
			If you don't need a textual user interface, just pass null
			for the MenuCreatorClass argument. In order to submit a job
			(from your main class or from a command in the textual user
			interface) you will only have to create a MyJobConfiguration
			object, initiate a MyJobCreator object and call the
			MyJobCreator#submitJob() method.
		</para>
	</section>

	<section xml:id="The_framework_functioning">
		<info>
			<title>
				The framework functioning – what you don't need to
				implement because it's already there
			</title>
		</info>

		<para>
			When the Application is initiated
			(EmbarrassinglyParallelApplication.#initApplication(..)
			method is called) these steps are performed:
		</para>
		<itemizedlist>
			<listitem>
				<para>an application Logger is created.</para>
			</listitem>
			<listitem>
				<para>
					the Textual UI is created (if needed) and attached
					as an appender to the Logger, so the user can see
					logged messages on the textual UI.
				</para>
			</listitem>
			<listitem>
				<para>
					a proxy to the scheduler (SchedulerProxy) is
					created, which is an active object which keeps a
					connection to the Scheduler and plays the Scheduler
					role for the local application.
				</para>
			</listitem>
			<listitem>
				<para>
					the ProstTreatmentManager object is initiated; it
					reads a file on system to find out if there are any
					jobs submitted in previous sessions that need post
					treatment operations. If there are any, it will
					start the post treatment process in asynchronous
					way.
				</para>
			</listitem>
			<listitem>
				<para>
					a SchedulerEventListener is created which is an
					active object that will listen for events from the
					scheduler. It will notify the PostTreatmentManager
					and the user interface when results are available on
					the Scheduler.
				</para>
			</listitem>
			<listitem>
				<para>the user interface (if any) is started</para>
			</listitem>
		</itemizedlist>

		<para>
			When a job is submitted by calling method, these steps are
			performed: MyJobCreator.submitJob(..)
		</para>
		<itemizedlist>
			<listitem>
				<para>a TaskFlowJob is created</para>
			</listitem>

			<listitem>
				<para>
					the splitData() method is called – the return is a
					list of File objects, of size n
				</para>
			</listitem>

			<listitem>
				<para>
					n native tasks are created. During the creation of
					each task, these methods are called:
					getPreScriptFilePath(), getPreScriptArgs(..),
					getPostScriptFilePath(), getPostScriptArgs(..),
					getCleanScriptFilePath(), getCleanScriptArgs(..),
					createCommandLineForTask(..),
					getGenerationScriptFilePath(),
					getGenerationScriptArgs(...).
				</para>
			</listitem>

			<listitem>
				<para>
					the JobConfiguration object is attached to the job
					as generic information.
				</para>
			</listitem>

			<listitem>
				<para>
					the job is submitted to the Scheduler (through the
					local Scheduler Proxy)
				</para>
			</listitem>

			<listitem>
				<para>
					the PostTreatment Manager is informed that results
					are awaited for this job
				</para>
			</listitem>
			<listitem>
				<para>
					the Post Treatment Manager will save its new state
					to a file so that it can recover in case of
					shut-down or failure.
				</para>
			</listitem>
		</itemizedlist>
		<para>When a job is finished these steps are performed:</para>
		<itemizedlist>
			<listitem>
				<para>
					the Post Treatment Manager will receive an event
					from the Scheduler Local Listener
				</para>
			</listitem>
			<listitem>
				<para>
					if the job succeed the Post Treatment Manager will
					get the results from the Scheduler, recreate the
					JobConfiguration object (that has been attached to
					the job) and merge the results in an asynchronous
					way.
				</para>
			</listitem>
		</itemizedlist>
	</section>
</chapter>